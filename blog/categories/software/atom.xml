<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: software | Themis_Sword's Blog]]></title>
  <link href="http://www.aprilzephyr.com/blog/categories/software/atom.xml" rel="self"/>
  <link href="http://www.aprilzephyr.com/"/>
  <updated>2014-04-03T13:52:18+08:00</updated>
  <id>http://www.aprilzephyr.com/</id>
  <author>
    <name><![CDATA[Themis_Sword]]></name>
    <email><![CDATA[licong0419@outlook.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Software Testing]]></title>
    <link href="http://www.aprilzephyr.com/blog/04012014/software-testing/"/>
    <updated>2014-04-01T16:24:56+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/04012014/software-testing</id>
    <content type="html"><![CDATA[<h3>1. Overview</h3>

<p>Software testing provide an objective, independent view to allow the business to appreciate and understand the risks of software, product or service implementation. Test techniques include, but are not limited to the process of executing a program or application with the intent of finding software bugs (errors or other defects).<!--more--></p>

<p>Software testing can be stated as the process of validating and verifying that a computer program/application/product:<br/>
* meets the requirements that guided its design and development,<br/>
* works as expected,<br/>
* can be implemented with the same characteristics,
and satisfies the needs of stakeholders.</p>

<p>Software testing, depending on the testing method employed, can be implemented at any time in the software development process.</p>

<p>Testing can never completely identify all the defects within software. Instead, it furnishes a criticism or comparison that compares the state and behavior of the product against oracles—principles or mechanisms by which someone might recognize a problem. These oracles may include (but are not limited to) specifications, contracts, comparable products, past versions of the same product, inferences about intended or expected purpose, user or customer expectations, relevant standards, applicable laws, or other criteria.</p>

<p>A primary purpose of testing is to detect software failures so that defects may be discovered and corrected. Testing cannot establish that a product functions properly under all conditions but can only establish that it does not function properly under specific conditions. The scope of software testing often includes examination of code as well as execution of that code in various environments and conditions as well as examining the aspects of code: does it do what it is supposed to do and do what it needs to do. A testing organization may be separate from the development team. There are various roles for testing team members. Information derived from software testing may be used to correct the process by which software is developed.</p>

<p>Software testing is the process of attempting to make the assessment that whether the software product will be acceptable to its end users, its target audience, its purchasers and other stakeholders..</p>

<h4>A Defects and failures</h4>

<p>Not all software defects are caused by coding errors. One common source of expensive defects is requirement gaps, e.g., unrecognized requirements which result in errors of omission by the program designer. Requirement gaps can often be non-functional requirements such as testability, scalability, maintainability, usability, performance, and security.</p>

<h4>B Input combinations and preconditions</h4>

<p>A fundamental problem with software testing is that testing under all combinations of inputs and preconditions (initial state) is not feasible. More significantly, non-functional dimensions of quality (how it is supposed to be versus what it is supposed to do)—usability, scalability, performance, compatibility, reliability—can be highly subjective; something that constitutes sufficient value to one person may be intolerable to another.</p>

<p>Software developers can&rsquo;t test everything, but they can use combinatorial test design to identify the minimum number of tests needed to get the coverage they want.</p>

<h3>2. Testing methods</h3>

<h4>A Static vs. dynamic testing</h4>

<p>Reviews, walkthroughs, or inspections are referred to as static testing, whereas actually executing programmed code with a given set of test cases is referred to as dynamic testing.</p>

<p>Static testing involves verification, whereas dynamic testing involves validation.</p>

<h4>B The box approach</h4>

<p><em>1) White-box testing</em><br/>
White-box testing (also known as clear box testing, glass box testing, transparent box testing and structural testing) tests internal structures or workings of a program, as opposed to the functionality exposed to the end-user. In white-box testing an internal perspective of the system, as well as programming skills, are used to design test cases. The tester chooses inputs to exercise paths through the code and determine the appropriate outputs. This is analogous to testing nodes in a circuit.</p>

<p>While white-box testing can be applied at the unit, integration and system levels of the software testing process, it is usually done at the unit level. It can test paths within a unit, paths between units during integration, and between subsystems during a system–level test. Though this method of test design can uncover many errors or problems, it might not detect unimplemented parts of the specification or missing requirements.</p>

<p>Techniques used in white-box testing include:<br/>
* API testing (application programming interface) – testing of the application using public and private APIs<br/>
* Code coverage – creating tests to satisfy some criteria of code coverage (e.g., the test designer can create tests to cause all statements in the program to be executed at least once)<br/>
* Fault injection methods – intentionally introducing faults to gauge the efficacy of testing strategies<br/>
* Mutation testing methods<br/>
* Static testing methods</p>

<p>Code coverage tools can evaluate the completeness of a test suite that was created with any method, including black-box testing. This allows the software team to examine parts of a system that are rarely tested and ensures that the most important function points have been tested. Code coverage as a software metric can be reported as a percentage for:<br/>
* Function coverage, which reports on functions executed<br/>
* Statement coverage, which reports on the number of lines executed to complete the test</p>

<p>100% statement coverage ensures that all code paths, or branches (in terms of control flow) are executed at least once. This is helpful in ensuring correct functionality, but not sufficient since the same code may process different inputs correctly or incorrectly.</p>

<p><em>2) Black-box testing</em><br/>
Black-box testing treats the software as a &ldquo;black box&rdquo;, examining functionality without any knowledge of internal implementation. The testers are only aware of what the software is supposed to do, not how it does it. Black-box testing methods include: equivalence partitioning, boundary value analysis, all-pairs testing, state transition tables, decision table testing, fuzz testing, model-based testing, use case testing, exploratory testing and specification-based testing.</p>

<p>One advantage of the black box technique is that no programming knowledge is required. Whatever biases the programmers may have had, the tester likely has a different set and may emphasize different areas of functionality.</p>

<p>This method of test can be applied to all levels of software testing: unit, integration, system and acceptance. It typically comprises most if not all testing at higher levels, but can also dominate unit testing as well.</p>

<p><em>3) Grey-box testing</em><br/>
Grey-box testing involves having knowledge of internal data structures and algorithms for purposes of designing tests, while executing those tests at the user, or black-box level. The tester is not required to have full access to the software&rsquo;s source code. Manipulating input data and formatting output do not qualify as grey-box, because the input and output are clearly outside of the &ldquo;black box&rdquo; that we are calling the system under test. This distinction is particularly important when conducting integration testing between two modules of code written by two different developers, where only the interfaces are exposed for test.</p>

<p>Typically, a grey-box tester will be permitted to set up an isolated testing environment with activities such as seeding a database. The tester can observe the state of the product being tested after performing certain actions such as executing SQL statements against the database and then executing queries to ensure that the expected changes have been reflected. Grey-box testing implements intelligent test scenarios, based on limited information. This will particularly apply to data type handling, exception handling, and so on.</p>

<h3>3. Testing levels</h3>

<h4>A Unit testing</h4>

<p>Unit testing, also known as component testing, refers to tests that verify the functionality of a specific section of code, usually at the function level. In an object-oriented environment, this is usually at the class level, and the minimal unit tests include the constructors and destructors.</p>

<p>Unit testing aims to eliminate construction errors before code is promoted to QA; this strategy is intended to increase the quality of the resulting software as well as the efficiency of the overall development and QA process.</p>

<p>Depending on the organization&rsquo;s expectations for software development, unit testing might include static code analysis, data flow analysis metrics analysis, peer code reviews, code coverage analysis and other software verification practices.</p>

<h4>B Integration testing</h4>

<p>Integration testing is any type of software testing that seeks to verify the interfaces between components against a software design. Software components may be integrated in an iterative way or all together.</p>

<p>Integration testing works to expose defects in the interfaces and interaction between integrated components (modules). Progressively larger groups of tested software components corresponding to elements of the architectural design are integrated and tested until the software works as a system.</p>

<h4>C Component interface testing</h4>

<p>The practice of component interface testing can be used to check the handling of data passed between various units, or subsystem components, beyond full integration testing between those units. The data being passed can be considered as &ldquo;message packets&rdquo; and the range or data types can be checked, for data generated from one unit, and tested for validity before being passed into another unit. Tests can include checking the handling of some extreme data values while other interface variables are passed as normal values. Unusual data values in an interface can help explain unexpected performance in the next unit. Component interface testing is a variation of black-box testing, with the focus on the data values beyond just the related actions of a subsystem component.</p>

<h4>D System testing</h4>

<p>System testing, or end-to-end testing, tests a completely integrated system to verify that it meets its requirements. For example, a system test might involve testing a logon interface, then creating and editing an entry, plus sending or printing results, followed by summary processing or deletion (or archiving) of entries, then logoff.</p>

<p>In addition, the software testing should ensure that the program, as well as working as expected, does not also destroy or partially corrupt its operating environment or cause other processes within that environment to become inoperative (this includes not corrupting shared memory, not consuming or locking up excessive resources and leaving any parallel processes unharmed by its presence).</p>

<h4>E Acceptance testing</h4>

<p>At last the system is delivered to the user for Acceptance testing.</p>

<h3>4. Testing types</h3>

<h4>A Installation testing</h4>

<p>An installation test assures that the system is installed correctly and working at actual customer&rsquo;s hardware.</p>

<h4>B Compatibility testing</h4>

<p>A common cause of software failure (real or perceived) is a lack of its compatibility with other application software, operating systems (or operating system versions), or target environments that differ greatly from the original (such as a terminal or GUI application intended to be run on the desktop now being required to become a web application, which must render in a web browser).  This results in the unintended consequence that the latest work may not function on earlier versions of the target environment, or on older hardware that earlier versions of the target environment was capable of using.</p>

<h4>C Smoke and sanity testing</h4>

<p>Sanity testing determines whether it is reasonable to proceed with further testing. Smoke testing consists of minimal attempts to operate the software, designed to determine whether there are any basic problems that will prevent it from working at all. Such tests can be used as build verification test.</p>

<h4>D Regression testing</h4>

<p>Regression testing focuses on finding defects after a major code change has occurred. Specifically, it seeks to uncover software regressions, as degraded or lost features, including old bugs that have come back. Such regressions occur whenever software functionality that was previously working, correctly, stops working as intended. Typically, regressions occur as an unintended consequence of program changes, when the newly developed part of the software collides with the previously existing code.</p>

<h4>E Acceptance testing</h4>

<h4>F Alpha testing</h4>

<p>Alpha testing is simulated or actual operational testing by potential users/customers or an independent test team at the developers' site. Alpha testing is often employed for off-the-shelf software as a form of internal acceptance testing, before the software goes to beta testing.</p>

<h4>G Beta testing</h4>

<p>Beta testing comes after alpha testing and can be considered a form of external user acceptance testing. Beta versions, of software are released to a limited audience outside of the programming team.</p>

<h4>H Functional vs non-functional testing</h4>

<p>Functional testing refers to activities that verify a specific action or function of the code. These are usually found in the code requirements documentation, although some development methodologies work from use cases or user stories.
Non-functional testing refers to aspects of the software that may not be related to a specific function or user action, such as scalability or other performance, behavior under certain constraints, or security. Testing will determine the breaking point, the point at which extremes of scalability or performance leads to unstable execution. Non-functional requirements tend to be those that reflect the quality of the product, particularly in the context of the suitability perspective of its users.</p>

<h4>I Destructive testing</h4>

<p>Destructive testing attempts to cause the software or a sub-system to fail. It verifies that the software functions properly even when it receives invalid or unexpected inputs, thereby establishing the robustness of input validation and error-management routines.</p>

<h4>J Software performance testing####</h4>

<p>Performance testing is generally executed to determine how a system or sub-system performs in terms of responsiveness and stability under a particular workload. It can also serve to investigate, measure, validate or verify other quality attributes of the system, such as scalability, reliability and resource usage.</p>

<p>Load testing is primarily concerned with testing that the system can continue to operate under a specific load, whether that be large quantities of data or a large number of users. This is generally referred to as software scalability. The related load testing activity of when performed as a non-functional activity is often referred to as endurance testing. Volume testing is a way to test software functions even when certain components (for example a file or database) increase radically in size. Stress testing is a way to test reliability under unexpected or rare workloads. Stability testing (often referred to as load or endurance testing) checks to see if the software can continuously function well in or above an acceptable period.</p>

<p>The terms load testing, performance testing, scalability testing, and volume testing, are often used interchangeably. Real-time software systems have strict timing constraints.</p>

<h4>K Usability testing</h4>

<p>Usability testing is needed to check if the user interface is easy to use and understand. It is concerned mainly with the use of the application.</p>

<h4>L Accessibility testing</h4>

<h4>M Security testing</h4>

<h4>N Other testings</h4>

<h3>5. Testing process</h3>

<h4>A Traditional waterfall development model</h4>

<p>A common practice of software testing is that testing is performed by an independent group of testers after the functionality is developed, before it is shipped to the customer. This practice often results in the testing phase being used as a project buffer to compensate for project delays, thereby compromising the time devoted to testing.</p>

<p>Another practice is to start software testing at the same moment the project starts and it is a continuous process until the project finishes.</p>

<h4>B Agile or Extreme development model</h4>

<p>In contrast, some emerging software disciplines such as extreme programming and the agile software development movement, adhere to a &ldquo;test-driven software development&rdquo; model. In this process, unit tests are written first, by the software engineers (often with pair programming in the extreme programming methodology). Of course these tests fail initially; as they are expected to. Then as code is written it passes incrementally larger portions of the test suites. The test suites are continuously updated as new failure conditions and corner cases are discovered, and they are integrated with any regression tests that are developed. Unit tests are maintained along with the rest of the software source code and generally integrated into the build process (with inherently interactive tests being relegated to a partially manual build acceptance process). The ultimate goal of this test process is to achieve continuous integration where software updates can be published to the public frequently.</p>

<p>This methodology increases the testing effort done by development, before reaching any formal testing team. In some other development models, most of the test execution occurs after the requirements have been defined and the coding process has been completed.</p>

<h4>C Top-down and bottom-up</h4>

<p>Bottom Up Testing is an approach to integrated testing where the lowest level components (modules, procedures, and functions) are tested first, then integrated and used to facilitate the testing of higher level components. After the integration testing of lower level integrated modules, the next level of modules will be formed and can be used for integration testing. The process is repeated until the components at the top of the hierarchy are tested. This approach is helpful only when all or most of the modules of the same development level are ready. This method also helps to determine the levels of software developed and makes it easier to report testing progress in the form of a percentage.</p>

<p>Top Down Testing is an approach to integrated testing where the top integrated modules are tested and the branch of the module is tested step by step until the end of the related module.</p>

<h4>D A sample testing cycle</h4>

<ul>
<li>Requirement analysis</li>
<li>Test planning</li>
<li>Test development</li>
<li>Test execution</li>
<li>Test reporting</li>
<li>Test result analysis</li>
<li>Defect retesting</li>
<li>Regression testing</li>
<li>Test closure</li>
</ul>


<h3>6. Automated testing</h3>

<h4>A Testing tools</h4>

<ul>
<li>Program monitors, permitting full or partial monitoring of program code including:

<ul>
<li>Instruction set simulator, permitting complete instruction level monitoring and trace facilities</li>
<li>Program animation, permitting step-by-step execution and conditional breakpoint at source level or in machine code</li>
<li>Code coverage reports</li>
</ul>
</li>
<li>Formatted dump or symbolic debugging, tools allowing inspection of program variables on error or at chosen points</li>
<li>Automated functional GUI testing tools are used to repeat system-level tests through the GUI</li>
<li>Benchmarks, allowing run-time performance comparisons to be made</li>
<li>Performance analysis (or profiling tools) that can help to highlight hot spots and resource usage</li>
</ul>


<h4>B Measurement in software testing</h4>

<p>Usually, quality is constrained to such topics as correctness, completeness, security, but can also include more technical requirements as described under the ISO standard ISO/IEC 9126, such as capability, reliability, efficiency, portability, maintainability, compatibility, and usability.</p>

<p>There are a number of frequently used software metrics, or measures, which are used to assist in determining the state of the software or the adequacy of the testing.</p>

<h3>7. Testing artifacts</h3>

<ul>
<li>Test plan</li>
<li>Traceability matrix</li>
<li>Test case</li>
<li>Test script</li>
<li>Test suite</li>
<li>Test fixture or test data</li>
<li>Test harness</li>
</ul>


<h3>8. Related process</h3>

<h4>A Software verification and validation</h4>

<ul>
<li>Verification: Have we built the software right? (i.e., does it implement the requirements).</li>
<li>Validation: Have we built the right software? (i.e., do the requirements satisfy the customer).</li>
</ul>


<p>According to the IEEE Standard Glossary of Software Engineering Terminology:<br/>
* Verification is the process of evaluating a system or component to determine whether the products of a given development phase satisfy the conditions imposed at the start of that phase.<br/>
* Validation is the process of evaluating a system or component during or at the end of the development process to determine whether it satisfies specified requirements.</p>

<p>According to the ISO 9000 standard:<br/>
* Verification is confirmation by examination and through provision of objective evidence that specified requirements have been fulfilled.
* Validation is confirmation by examination and through provision of objective evidence that the requirements for a specific intended use or application have been fulfilled.</p>

<h4>B Software quality assurance</h4>

<p>Software testing is a part of the software quality assurance (SQA) process. In SQA, software process specialists and auditors are concerned for the software development process rather than just the artifacts such as documentation, code and systems. They examine and change the software engineering process itself to reduce the number of faults that end up in the delivered software: the so-called &ldquo;defect rate&rdquo;. What constitutes an &ldquo;acceptable defect rate&rdquo; depends on the nature of the software; A flight simulator video game would have much higher defect tolerance than software for an actual airplane. Although there are close links with SQA, testing departments often exist independently, and there may be no SQA function in some companies.</p>

<p>Software testing is a task intended to detect defects in software by contrasting a computer program&rsquo;s expected results with its actual results for a given set of inputs. By contrast, QA (quality assurance) is the implementation of policies and procedures intended to prevent defects from occurring in the first place.</p>

<p><a href="http://en.wikipedia.org/wiki/Software_testing">Origin</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[100 Interview Questions for Software Developers(轉)]]></title>
    <link href="http://www.aprilzephyr.com/blog/02202014/100-interview-questions-for-software-developers/"/>
    <updated>2014-02-20T15:46:36+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/02202014/100-interview-questions-for-software-developers</id>
    <content type="html"><![CDATA[<p>1月13日，著名博客作者<a href="http://www.noop.nl">Jurgen Appelo</a>寫了一篇博文：<a href="http://www.noop.nl/2009/01/100-interview-questions-for-software-developers.html">“軟件開發者面試百問”</a>。該文甚受讀者歡迎，15日便登上了delicious，Popurls.com，Reddit的首頁。InfoQ中文站在得到作者許可之後，将其全文翻譯爲中文，希望可以對國內讀者有所助益。</br>
</br>
以下爲文章全文：</br>
</br>
想雇到搞軟件開發的聰明人可不容易。萬一一不小心，就會搞到一堆低能大狒狒。我去年就碰到这種事了。你肯定不想這樣吧。聽我的，没錯。在樹上開站立會議門都没有。</br>
</br>
問點有難度的問題能幫你把聰明人跟狒狒們分開。我决定把我自己整理出來的軟件開發者面視百問發出来，希望能幫到你們的忙。<!--more--></br>
</br>
這個列表涵蓋了軟件工程知識體系中定義的大多數知識域。當然，如果你只想找出類拔萃的程序員，便只需涉及結構、算法、數據結構、測試这幾個話題。如果想雇架構師，也可以只考慮需求、功能設計、技術設計这些地方。</br>
</br>
不過不管你怎麼做，都要牢記一點：</br>
</br>
這裡大多數問題的答案都没有對错之分！</br>
</br>
你可以把我的這些問題作為引子，展開討論。例如下面有個問題是使用静態方法或是單例的缘由。如果那個面試者就此展開長篇大論，那他很有可能是個聰明能幹的家伙！如果他一臉茫然的看著你，發出這種聲音，很明顯這就是只狒狒了。同樣，想知道一個數是不是2的乘方也有很多方法，不過要是面試的人想用mod運算符，嗯……你知道我的意思吧。（你不知道也没關係，來根香蕉？）</br>
</br>
<strong>需求</strong></br>
</br>
1) 你能給出一些非功能性（或者質量）需求的例子么？</br>
2) 如果客户需要高性能、使用极其方便而又高度安全，你會给他什麼建議？</br>
3) 你能給出一些用來描述需求的不同技術么？它們各自適用於什麼場景？</br>
4) 需求跟蹤是什麼意思？什麼是向前追溯，什麼是向後追溯？</br>
5) 你喜歡用什麼工具跟蹤需求？</br>
6) 你怎麼看待需求變化？它是好是壞？給出你的理由。</br>
7) 你怎樣研究需求，發現需求？有哪些資源可以用到？</br>
8) 你怎麼給需求製定優先級？有哪些技術？</br>
9) 在需求過程中，用户、客户、開發人員各自的職責是什麼？</br>
10) 你怎麼對待不完整或是令人費解的需求？</br>
</br>
<strong>功能設計</strong></br>
</br>
1) 在功能設計中有哪些隱喻？給出幾個成功的例子。</br>
2) 如果有些功能的執行時間很长，怎麼能讓用户感觉不到太長的等待？</br>
3) 如果用户必須要在一個很小的區域内，從一個常常的列表中選擇多个條目，你會用什么控件？</br>
4) 有哪些方法可以保证數據項的完整？</br>
5) 建立系統原型有哪些技術？</br>
6) 应用程序怎樣建立對用户行为的预期？給出一些例子。</br>
7) 如何入手設計一組數量龐大而又複雜的特性，你能舉出一些設計思路吗？</br>
8) 有一個列表，其中有10個元素，每個元素都有20個字段可以編輯，你怎樣設計這種情况？如果是1000個元素，每個元素有3個字段呢？</br>
9) 用不同的顏色對一段文本中的文字標記高亮，這種做法有什麼問題？</br>
10) Web環境和Windows環境各有些什么限制？</br>
</br>
<strong>技術設計</strong></br>
</br>
1) 什麼是低耦合和高聚合？封裝原則又是什麼意思？</br>
2) 在Web應用中，你怎樣避免几個人編輯同一段數據所造成的衝突？</br>
3) 你知道設計模式吗？你用过哪些設計模式？在什麼场合下用的？</br>
4) 是否了解什麼是無狀態的業務層？長事物如何與之相適應？</br>
5) 在搭建一個架構，或是技術設計時，你用過幾種圖？</br>
6) 在N層架構中都有哪些層？它們各自的職責是什麼？</br>
7) 有哪些方法可以確保架構中數據的正確和健壮？</br>
8) 面向对象設計和面向組件設計有哪些不同之處？</br>
9) 怎樣在數據庫中對用户授權、用户配置、權限管理這幾項功能建模？</br>
10) 怎樣按照等級制度給动物王國（包括各種物種和各自的行爲）建模？</br>
</br>
<strong>程序設計</strong></br>
</br>
1) 你怎樣保證你的代碼可以處理各種錯誤事件？</br>
2) 解釋一下什麼是測試驅動開發，舉出極限編程中的一些原則。</br>
3) 看别人代碼的時候，你最關心什麼地方？</br>
4) 什麼時候使用抽象類，什麼時候使用接口？</br>
5) 除了IDE以外，你還喜歡哪些必不可少的工具？</br>
6) 你怎麼保證代碼執行速度快，而又不出問題？</br>
7) 什麼時候用多態，什麼時候用委派？</br>
8) 什麼時候使用帶有靜態成員的類，什麼時候使用單例？</br>
9) 你在代碼裏面怎麼提前處理需求的變化？給一些例子。</br>
10) 描述一下實現一段代碼的過程，從需求到最终交付。</br>
</br>
<strong>算法</strong></br>
</br>
1) 怎樣知道一個數字是不是2的乘方？怎樣判斷一個数是不是奇數？</br>
2) 怎樣找出鏈表中間的元素？</br>
3) 怎樣改變10,000個靜態HTML頁面中所有電話號碼的格式？</br>
4) 舉出一個你所用過的遞歸的例子。</br>
5) 在散列表和排序後的列表中找一個元素，哪個查找速度最快？</br>
6) 不管是書、雜誌还是網絡，你從中所學到的最後一點算法知識是什麼？</br>
7) 怎樣把字符串反轉？你能不用臨時的字符串么？</br>
8) 你願意用什么類型的語言來編寫複雜的算法？</br>
9) 有一個數組，裏面是從1到1,000,000的整数，其中有一個數字出現了两次，你怎麼找出那個重複的數字？</br>
10) 你知道“旅行商問題（Traveling Salesman Problem）”么？</br>
</br>
<strong>數據結構</strong></br>
</br>
1) 怎樣在内存中實現倫敦地鐵的結構？</br>
2) 怎樣以最有效的方式在數據庫中存儲顏色值？</br>
3) 队列和堆棧區別是什麼？</br>
4) 用堆或者棧存儲數據的區別是什麼？</br>
5) 怎樣在數據庫中存儲N維向量？</br>
6) 你倾向於用哪种類型的語言編寫複雜的數據結構？</br>
7) 21的二進製值是什么？十六進製值呢？</br>
8) 不管是書、雜誌还是網絡，你從中所學到的最後一點數據結構的知識是什麼？</br>
9) 怎樣在XML文檔中存儲足球比赛結果（包括队伍和比分）？</br>
10) 有哪些文本格式可以保存Unicode字符？</br>
</br>
<strong>測試</strong></br>
</br>
1) 什麼是回歸測試？怎樣知道新引入的變化没有給現有的功能造成破壞？</br>
2) 如果業務層和數據層之間有依赖關係，你該怎麼寫單元測試？</br>
3) 你用哪些工具測試代碼質量？</br>
4) 在產品部署之後，你最常碰到的是什麼類型的問题？</br>
5) 什麼是代碼覆蓋率？有多少種代碼覆盖率？</br>
6) 功能測試和探索性測試的區別是什麼？你怎麼對網站進行測試？</br>
7) 測試套件、測試用例、測試計劃，這三者之間的區別是什麼？你怎麼組織測試？</br>
8) 要對電子商務網站做冒煙測試，你會做哪些類型的測試？</br>
9) 客户在驗收測試中會發現不满意的東西，怎樣减少這種情况的發生？</br>
10) 你去年在測試和質量保證方面學到了哪些東西？</br>
</br>
<strong>維護</strong></br>
</br>
1) 你用哪些工具在維護階段對產品進行監控？</br>
2) 要想對一個正在產品環境中被使用的產品進行升級，該注意哪些重要事項？</br>
3) 如果在一个龐大的文件中有錯誤，而代碼又無法逐步跟蹤，你怎麼找出錯誤？</br>
4) 你怎樣保證代碼中的變化不會影響產品的其他部分？</br>
5) 你怎樣爲產品編寫技術文檔？</br>
6) 你用过哪些方式保證軟件產品容易維護？</br>
7) 怎樣在產品運行的環境中進行系統調試？</br>
8) 什麼是負載均衡？負載均衡的方式有哪些？</br>
9) 為什麼在應用程序的生命週期中，軟件維護費用所佔的份額最高？</br>
10) 再造工程（re-engineering）和逆向工程（reverse engineering）的區別是什麼？</br>
</br>
<strong>配置管理</strong></br>
</br>
1) 你知道配置管理中基線的含義麼？怎樣把項目中某個重要的時刻凍結？</br>
2) 你一般會把哪些東西纳入版本控制？</br>
3) 怎樣可以保證團隊中每個人都知道誰改變了哪些東西？</br>
4) Tag和Branch的區別是什么？在什麼情况下该使用tag，什麼時候用branch？</br>
5) 怎樣管理技術文檔——如產品架構文檔——的變化？</br>
6) 你用什麼工具管理項目中所有數字信息的狀態？你最喜歡哪种工具？</br>
7) 如果客户想要對一款已經發佈的產品做出變動，你怎麼處理？</br>
8) 版本管理和發佈管理有什麼差異？</br>
9) 對文本文件的變化和二進製文件的變化進行管理，這二者有什麼不同？</br>
10) 同時處理多個變更請求，或是同時進行增量開發和維護，這種事情你怎麼看待？</br>
</br>
<strong>項目管理</strong></br>
</br>
1) 範圍、時間、成本，这三項中哪些是可以由客户控制的？</br>
2) 誰該對項目中所要付出的一切做出估算？誰有權設置最後期限？</br>
3) 减少交付的次數，或是减少每個交付中的工作量，你喜歡哪種做法？</br>
4) 你喜歡用哪種圖來跟蹤項目進度？</br>
5) 迭代和增量的區別在哪里？</br>
6) 試著解释一下風險管理中用到的實踐。風險該如何管理？</br>
7) 你喜歡任務分解还是滾動式計劃？</br>
8) 你需要哪些东西幫助你判斷項目是否符合時間要求，在預算範圍内運作？</br>
9) DSDM、Prince2、Scrum，这三者之間有哪些區别？</br>
10) 如果客户想要的東西太多，你在範圍和時間上怎樣跟他達成一致呢？</br>
</br>
閱讀英文原文：<a href="http://www.noop.nl/2009/01/100-interview-questions-for-software-developers.html">100 Interview Questions for Software Developers</a></br>
</br>
<a href="http://www.infoq.com/cn/articles/programmer-interview">Origin</a></p>
]]></content>
  </entry>
  
</feed>
