<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Themis_Sword's Blog]]></title>
  <link href="http://www.aprilzephyr.com/atom.xml" rel="self"/>
  <link href="http://www.aprilzephyr.com/"/>
  <updated>2015-04-30T18:06:30+08:00</updated>
  <id>http://www.aprilzephyr.com/</id>
  <author>
    <name><![CDATA[Themis_Sword]]></name>
    <email><![CDATA[licong0419@outlook.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[機器學習&amp;深度學習資料]]></title>
    <link href="http://www.aprilzephyr.com/blog/04302015/ji-qi-xue-xi-and-shen-du-xue-xi-zi-liao/"/>
    <updated>2015-04-30T15:31:50+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/04302015/ji-qi-xue-xi-and-shen-du-xue-xi-zi-liao</id>
    <content type="html"><![CDATA[<p><strong><a href="http://ml.memect.com">機器學習日報__好東西傳送門</a></strong><!--more--></p>

<p>*<a href="http://www.erogol.com/brief-history-machine-learning/">《Brief History of Machine Learning》</a><br/>
介紹:這是一篇介紹機器學習歷史的文章，介紹很全面，從感知機、神經網絡、決策樹、SVM、Adaboost到隨機森林、Deep Learning.</p>

<p>*<a href="http://www.idsia.ch/%7Ejuergen/DeepLearning15May2014.pdf">《Deep Learning in Neural Networks: An Overview》</a><br/>
介紹:這是瑞士人工智能實驗室Jurgen Schmidhuber寫的最新版本《神經網絡與深度學習綜述》本綜述的特點是以時間排序，從1940年開始講起，到60-80年代，80-90年代，一直講到2000年後及最近幾年的進展。涵蓋了deep learning裏各種tricks，引用非常全面.</p>

<p>*<a href="http://machinelearningmastery.com/a-gentle-introduction-to-scikit-learn-a-python-machine-learning-library/">《A Gentle Introduction to Scikit-Learn: A Python Machine Learning Library》</a><br/>
介紹:這是一份python機器學習庫,如果您是一位python工程師而且想深入的學習機器學習.那麽這篇文章或許能夠幫助到你.</p>

<p>*<a href="http://machinelearningmastery.com/how-to-layout-and-manage-your-machine-learning-project/">《How to Layout and Manage Your Machine Learning Project》</a><br/>
介紹:這一篇介紹如果設計和管理屬於你自己的機器學習項目的文章，裏面提供了管理模版、數據管理與實踐方法.</p>

<p>*<a href="https://medium.com/code-poet/80ea3ec3c471">《Machine Learning is Fun!》</a><br/>
介紹:如果你還不知道什麽是機器學習，或則是剛剛學習感覺到很枯燥乏味。那麽推薦一讀。這篇文章已經被翻譯成中文,如果有興趣可以移步<a href="http://blog.jobbole.com/67616/">http://blog.jobbole.com/67616/</a></p>

<p>*<a href="http://cran.r-project.org/doc/contrib/Liu-R-refcard.pdf">《R語言參考卡片》</a><br/>
介紹:R語言是機器學習的主要語言,有很多的朋友想學習R語言，但是總是忘記一些函數與關鍵字的含義。那麽這篇文章或許能夠幫助到你</p>

<p>*<a href="http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/">《Choosing a Machine Learning Classifier》</a><br/>
介紹:我該如何選擇機器學習算法，這篇文章比較直觀的比較了Naive Bayes，Logistic Regression，SVM，決策樹等方法的優劣，另外討論了樣本大小、Feature與Model權衡等問題。此外還有<a href="http://www.52ml.net/15063.html">已經翻譯了的版本。</a></p>

<p>*<a href="http://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks">《An Introduction to Deep Learning: From Perceptrons to Deep Networks》</a><br/>
介紹：深度學習概述：從感知機到深度網絡，作者對於例子的選擇、理論的介紹都很到位，由淺入深。<a href="http://www.cnblogs.com/xiaowanyer/p/3701944.html">翻譯版本</a></p>

<p>*<a href="http://vdisk.weibo.com/s/ayG13we2vxyKl">《The LION Way: Machine Learning plus Intelligent Optimization》</a><br/>
介紹:&lt;機器學習與優化>這是一本機器學習的小冊子, 短短300多頁道盡機器學習的方方面面. 圖文並茂, 生動易懂, 沒有一坨坨公式的煩惱. 適合新手入門打基礎, 也適合老手溫故而知新. 比起MLAPP/PRML等大部頭, 也許這本你更需要!具體內容<a href="http://intelligent-optimization.org/LIONbook/">推薦閱讀</a></p>

<p>*<a href="http://1.guzili.sinaapp.com/?p=174">《深度學習與統計學習理論》</a><br/>
介紹:作者是來自百度，不過他本人已經在2014年4月份申請離職了。但是這篇文章很不錯如果你不知道深度學習與支持向量機/統計學習理論有什麽聯系？那麽應該立即看看這篇文章.</p>

<p>*<a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2010/readings/MIT6_042JF10_notes.pdf">《計算機科學中的數學》</a><br/>
介紹:這本書是由谷歌公司和MIT共同出品的計算機科學中的數學：<a href="https://github.com/ty4z2008/Qix/blob/master/Mathematics%20for%20Computer%20Science">Mathematics for Computer Science</a>，Eric Lehman et al 2013 。分為5大部分：1）證明，歸納。2）結構，數論，圖。3）計數，求和，生成函數。4）概率，隨機行走。5）遞歸。等等</p>

<p>*<a href="http://research.microsoft.com/en-US/people/kannan/book-no-solutions-aug-21-2014.pdf">《信息時代的計算機科學理論(Foundations of Data Science)》</a><br/>
介紹：信息時代的計算機科學理論,目前國內有紙質書購買，<a href="https://itunes.apple.com/us/book/introduction-to-data-science/id529088127">iTunes購買</a></p>

<p>*<a href="http://vdisk.weibo.com/s/ayG13we2vx5qg">《Data Science with R》</a><br/>
介紹:這是一本由雪城大學新編的第二版《數據科學入門》教材：偏實用型，淺顯易懂，適合想學習R語言的同學選讀。</p>

<p>*<a href="http://www.informit.com/articles/article.aspx?p=2213858">《Twenty Questions for Donald Knuth》</a><br/>
介紹:這並不是一篇文檔或書籍。這是篇向圖靈獎得主Donald Knuth提問記錄稿： 近日， Charles Leiserson, Al Aho, Jon Bentley等大神向Knuth提出了20個問題，內容包括TAOCP，P/NP問題，圖靈機，邏輯，以及為什麽大神不用電郵等等。</p>

<p>*<a href="http://arxiv.org/pdf/1402.4304v2.pdf">《Automatic Construction and Natural-Language Description of Nonparametric Regression Models》</a><br/>
介紹：不會統計怎麽辦？不知道如何選擇合適的統計模型怎麽辦？那這篇文章你的好好讀一讀了麻省理工Joshua B. Tenenbaum和劍橋Zoubin Ghahramani合作，寫了一篇關於automatic statistician的文章。可以自動選擇回歸模型類別，還能自動寫報告&hellip;</p>

<p>*<a href="http://openreview.net/venue/iclr2014">《ICLR 2014論文集》</a><br/>
介紹:對深度學習和representation learning最新進展有興趣的同學可以了解一下</p>

<p>*<a href="http://www-nlp.stanford.edu/IR-book/">《Introduction to Information Retrieval》</a><br/>
介紹：這是一本信息檢索相關的書籍，是由斯坦福Manning與谷歌副總裁Raghavan等合著的Introduction to Information Retrieval一直是北美最受歡迎的信息檢索教材之一。最近作者增加了該課程的幻燈片和作業。<a href="http://www-nlp.stanford.edu/IR-book/information-retrieval.html">IR相關資源</a></p>

<p>*<a href="http://www.denizyuret.com/2014/02/machine-learning-in-5-pictures.html">《Machine learning in 10 pictures》</a><br/>
介紹:Deniz Yuret用10張漂亮的圖來解釋機器學習重要概念：1. Bias/Variance Tradeoff 2. Overfitting 3. Bayesian / Occam&rsquo;s razor 4. Feature combination 5. Irrelevant feature 6. Basis function 7. Discriminative / Generative 8. Loss function 9. Least squares 10. Sparsity.很清晰</p>

<p>*<a href="http://webscope.sandbox.yahoo.com/catalog.php?datatype=l">《雅虎研究院的數據集匯總》</a><br/>
介紹：雅虎研究院的數據集匯總： 包括語言類數據，圖與社交類數據，評分與分類數據，計算廣告學數據，圖像數據，競賽數據，以及系統類的數據。</p>

<p>*<a href="http://www-bcf.usc.edu/%7Egareth/ISL/">《An Introduction to Statistical Learning with Applications in R》</a><br/>
介紹：這是一本斯坦福統計學著名教授Trevor Hastie和Robert Tibshirani的新書，並且在2014年一月已經<a href="https://class.stanford.edu/courses/HumanitiesScience/StatLearning/Winter2014/about">開課</a></p>

<p>*<a href="http://machinelearningmastery.com/best-machine-learning-resources-for-getting-started/">Best Machine Learning Resources for Getting Started</a><br/>
介紹：機器學習最佳入門學習資料匯總是專為機器學習初學者推薦的優質學習資源，幫助初學者快速入門。而且這篇文章的介紹已經被翻譯成<a href="http://article.yeeyan.org/view/22139/410514">中文版</a>。如果你不怎麽熟悉，那麽我建議你先看一看中文的介紹。</p>

<p>*<a href="http://blog.sina.com.cn/s/blog_bda0d2f10101fpp4.html">My deep learning reading list</a><br/>
介紹:主要是順著Bengio的PAMI review的文章找出來的。包括幾本綜述文章，將近100篇論文，各位山頭們的Presentation。全部都可以在google上找到。</p>

<p>*<a href="http://www.morganclaypool.com/doi/abs/10.2200/S00266ED1V01Y201005HLT008?journalCode=hlt">Cross-Language Information Retrieval</a><br/>
介紹：這是一本書籍，主要介紹的是跨語言信息檢索方面的知識。理論很多</p>

<p>*<a href="http://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy1/index.html?ca=drs-">探索推薦引擎內部的秘密，第 1 部分: 推薦引擎初探</a><br/>
<a href="http://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy2/index.html?ca=drs-">探索推薦引擎內部的秘密，第 2 部分: 深度推薦引擎相關算法 &ndash; 協同過濾</a><br/>
<a href="http://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy3/index.html?ca=drs-">探索推薦引擎內部的秘密，第 3 部分: 深度推薦引擎相關算法 &ndash; 聚類</a><br/>
介紹:本文共有三個系列，作者是來自IBM的工程師。它主要介紹了推薦引擎相關算法，並幫助讀者高效的實現這些算法。</p>

<p>*<a href="http://mimno.infosci.cornell.edu/b/articles/ml-learn/">《Advice for students of machine learning》</a><br/>
介紹：康奈爾大學信息科學系助理教授David Mimno寫的《對機器學習初學者的一點建議》， 寫的挺實際，強調實踐與理論結合，最後還引用了馮 • 諾依曼的名言: &ldquo;Young man, in mathematics you don&rsquo;t understand things. You just get used to them.&rdquo;</p>

<p>*<a href="http://web.stanford.edu/group/pdplab/pdphandbook/">分布式並行處理的數據</a><br/>
介紹：這是一本關於分布式並行處理的數據《Explorations in Parallel Distributed Processing: A Handbook of Models, Programs, and Exercises》,作者是斯坦福的James L. McClelland。著重介紹了各種神級網絡算法的分布式實現,做Distributed Deep Learning 的童鞋可以參考下</p>

<p>*<a href="http://blogs.technet.com/b/machinelearning/archive/2014/07/01/what-is-machine-learning.aspx">《“機器學習”是什麽？》</a><br/>
介紹:【“機器學習”是什麽？】John Platt是微軟研究院傑出科學家，17年來他一直在機器學習領域耕耘。近年來機器學習變得炙手可熱，Platt和同事們遂決定開設<a href="http://blogs.technet.com/b/machinelearning/">博客</a>，向公眾介紹機器學習的研究進展。機器學習是什麽，被應用在哪裏？來看Platt的<a href="http://blogs.technet.com/b/machinelearning/archive/2014/07/01/what-is-machine-learning.aspx">這篇博文</a></p>

<p>*<a href="http://icml.cc/2014/index/article/15.htm">《2014年國際機器學習大會ICML 2014 論文》</a><br/>
介紹：2014年國際機器學習大會（ICML）已經於6月21-26日在國家會議中心隆重舉辦。本次大會由微軟亞洲研究院和清華大學聯手主辦，是這個有著30多年歷史並享譽世界的機器學習領域的盛會首次來到中國，已成功吸引海內外1200多位學者的報名參與。幹貨很多，值得深入學習下</p>

<p>*<a href="http://blogs.technet.com/b/machinelearning/archive/2014/07/11/machine-learning-for-industry-a-case-study.aspx">《Machine Learning for Industry: A Case Study》</a><br/>
介紹：這篇文章主要是以Learning to Rank為例說明企業界機器學習的具體應用，RankNet對NDCG之類不敏感，加入NDCG因素後變成了LambdaRank，同樣的思想從神經網絡改為應用到Boosted Tree模型就成就了LambdaMART。<a href="http://research.microsoft.com/en-us/people/cburges/?WT.mc_id=Blog_MachLearn_General_DI">Chirs Burges</a>，微軟的機器學習大神，Yahoo 2010 Learning to Rank Challenge第一名得主，排序模型方面有RankNet，LambdaRank，LambdaMART，尤其以LambdaMART最為突出，代表論文為： <a href="http://research.microsoft.com/en-us/um/people/cburges/tech_reports/msr-tr-2010-82.pdf">From RankNet to LambdaRank to LambdaMART: An Overview</a> 此外，Burges還有很多有名的代表作，比如：<a href="http://research.microsoft.com/pubs/67119/svmtutorial.pdf">A Tutorial on Support Vector Machines for Pattern Recognition</a>,<a href="http://research.microsoft.com/en-us/um/people/cburges/tech_reports/tr-2004-56.pdf">Some Notes on Applied Mathematics for Machine Learning</a></p>

<p>*<a href="http://meta-guide.com/software-meta-guide/100-best-github-deep-learning/">100 Best GitHub: Deep Learning</a><br/>
介紹:100 Best GitHub: Deep Learning</p>

<p>*<a href="http://www.52ml.net/12019.html">《UFLDL-斯坦福大學Andrew Ng教授“Deep Learning”教程》</a><br/>
介紹:本教程將闡述無監督特征學習和深度學習的主要觀點。通過學習，你也將實現多個功能學習/深度學習算法，能看到它們為你工作，並學習如何應用/適應這些想法到新問題上。本教程假定機器學習的基本知識（特別是熟悉的監督學習，邏輯回歸，梯度下降的想法），如果你不熟悉這些想法，我們建議你去這裏<a href="http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=MachineLearning">機器學習課程</a>，並先完成第II，III，IV章（到邏輯回歸）。此外這關於這套教程的源代碼在github上面已經有python版本了 <a href="https://github.com/jatinshah/ufldl_tutorial">UFLDL Tutorial Code</a></p>

<p>*<a href="http://research.microsoft.com/pubs/217165/ICASSP_DeepTextLearning_v07.pdf">《Deep Learning for Natural Language Processing and Related Applications》</a><br/>
介紹:這份文檔來自微軟研究院,精髓很多。如果需要完全理解，需要一定的機器學習基礎。不過有些地方會讓人眼前一亮,毛塞頓開。</p>

<p>*<a href="https://colah.github.io/posts/2014-07-Understanding-Convolutions/">Understanding Convolutions</a><br/>
介紹:這是一篇介紹圖像卷積運算的文章，講的已經算比較詳細的了</p>

<p>*<a href="http://mlss2014.com/">《Machine Learning Summer School》</a><br/>
介紹：<a href="https://www.youtube.com/user/smolix">每天請一個大牛來講座，主要涉及機器學習，大數據分析，並行計算以及人腦研究</a></p>

<p>*<a href="https://github.com/josephmisiti/awesome-machine-learning">《Awesome Machine Learning》</a><br/>
介紹：一個超級完整的機器學習開源庫總結，如果你認為這個碉堡了，那後面這個列表會更讓你驚訝：【Awesome Awesomeness】,國內已經有熱心的朋友進行了翻譯<a href="http://blog.jobbole.com/73806/">中文介紹</a>，<a href="https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md">機器學習數據挖掘免費電子書</a></p>

<p>*<a href="http://see.stanford.edu/see/lecturelist.aspx?coll=63480b48-8819-4efd-8412-263f1a472f5a">斯坦福《自然語言處理》課程視頻</a><br/>
介紹:ACL候任主席、斯坦福大學計算機系Chris Manning教授的《自然語言處理》課程所有視頻已經可以在斯坦福公開課網站上觀看了（如Chrome不行，可用IE觀看） 作業與測驗也可以下載。</p>

<p>*<a href="http://freemind.pluskid.org/machine-learning/deep-learning-and-shallow-learning/">《Deep Learning and Shallow Learning》</a><br/>
介紹:對比 Deep Learning 和 Shallow Learning 的好文，來著浙大畢業、MIT 讀博的 Chiyuan Zhang 的博客。</p>

<p>*<a href="http://benanne.github.io/2014/08/05/spotify-cnns.html">《Recommending music on Spotify with deep learning》</a><br/>
介紹:利用卷積神經網絡做音樂推薦。</p>

<p>*<a href="http://neuralnetworksanddeeplearning.com/index.html">《Neural Networks and Deep Learning》</a><br/>
介紹：神經網絡的免費在線書，已經寫了三章了，還有<a href="https://github.com/mnielsen/neural-networks-and-deep-learning">對應的開源代碼</a>，愛好者的福音。</p>

<p>*<a href="http://machinelearningmastery.com/java-machine-learning/">《Java Machine Learning》</a><br/>
介紹：Java機器學習相關平臺和開源的機器學習庫，按照大數據、NLP、計算機視覺和Deep Learning分類進行了整理。看起來挺全的，Java愛好者值得收藏。</p>

<p>*<a href="http://www.oschina.net/translate/6-tips-for-writing-better-code">《Machine Learning Theory: An Introductory Primer》</a><br/>
介紹：機器學習最基本的入門文章，適合零基礎者</p>

<p>*<a href="http://www.ctocio.com/hotnews/15919.html">《機器學習常見算法分類匯總》</a><br/>
介紹：機器學習的算法很多。很多時候困惑人們都是，很多算法是一類算法，而有些算法又是從其他算法中延伸出來的。這裏，我們從兩個方面來給大家介紹，第一個方面是學習的方式，第二個方面是算法的類似性。</p>

<p>*<a href="http://suanfazu.com/discussion/68/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87survey%E5%90%88%E9%9B%86">《機器學習經典論文/survey合集》</a><br/>
介紹：看題目你已經知道了是什麽內容,沒錯。裏面有很多經典的機器學習論文值得仔細與反復的閱讀。</p>

<p>*<a href="http://work.caltech.edu/library/">《機器學習視頻庫》</a><br/>
介紹：視頻由加州理工學院（Caltech）出品。需要英語底子。</p>

<p>*<a href="http://suanfazu.com/discussion/109/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E4%B9%A6%E7%B1%8D">機器學習經典書籍</a><br/>
介紹：總結了機器學習的經典書籍，包括數學基礎和算法理論的書籍，可做為入門參考書單。</p>

<p>*<a href="http://efytimes.com/e1/fullnews.asp?edid=121516">16 Free eBooks On Machine Learning</a><br/>
介紹:16本機器學習的電子書，可以下載下來在pad，手機上面任意時刻去閱讀。不多我建議你看完一本再下載一本。</p>

<p>*<a href="http://www.erogol.com/large-set-machine-learning-resources-beginners-mavens/">《A Large set of Machine Learning Resources for Beginners to Mavens》</a><br/>
介紹:標題很大，從新手到專家。不過看完上面所有資料。肯定是專家了</p>

<p>*<a href="http://article.yeeyan.org/view/22139/410514">機器學習最佳入門學習資料匯總</a><br/>
介紹：入門的書真的很多，而且我已經幫你找齊了。</p>

<p>*<a href="http://users.soe.ucsc.edu/%7Eniejiazhong/slides/chandra.pdf">Sibyl</a><br/>
介紹：Sibyl 是一個監督式機器學習系統，用來解決預測方面的問題，比如 YouTube 的視頻推薦。</p>

<p>*<a href="http://www.iro.umontreal.ca/%7Ebengioy/dlbook/">《Deep Learning》</a><br/>
介紹：Yoshua Bengio, Ian Goodfellow, Aaron Courville著</p>

<p>*<a href="http://www.slideshare.net/ssuser9cc1bd/piji-li-dltm">《Neural Network &amp; Text Mining》</a><br/>
介紹:關於(Deep) Neural Networks在 NLP 和 Text Mining 方面一些paper的總結</p>

<p>*<a href="http://www.cnblogs.com/lxy2017/p/3927226.html">《前景目標檢測1（總結）》</a><br/>
介紹:計算機視覺入門之前景目標檢測1（總結）</p>

<p>*<a href="http://www.52ml.net/17004.html">《行人檢測》</a><br/>
介紹:計算機視覺入門之行人檢測</p>

<p>*<a href="http://www.kdnuggets.com/2014/08/deep-learning-important-resources-learning-understanding.html">《Deep Learning – important resources for learning and understanding》</a><br/>
介紹:Important resources for learning and understanding . Is awesome</p>

<p>*<a href="http://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer">《Machine Learning Theory: An Introductory Primer》</a><br/>
介紹:這又是一篇機器學習初學者的入門文章。值得一讀</p>

<p>*<a href="http://neuralnetworksanddeeplearning.com/">《Neural Networks and Deep Learning》</a><br/>
介紹:在線Neural Networks and Deep Learning電子書</p>

<p>*<a href="http://www.52nlp.cn/python-%E7%BD%91%E9%A1%B5%E7%88%AC%E8%99%AB-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86-%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98">《Python 網頁爬蟲 &amp; 文本處理 &amp; 科學計算 &amp; 機器學習 &amp; 數據挖掘兵器譜》</a><br/>
介紹:python的17個關於機器學習的工具</p>

<p>*<a href="http://www.flickering.cn/%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/2014/06/%E7%A5%9E%E5%A5%87%E7%9A%84%E4%BC%BD%E7%8E%9B%E5%87%BD%E6%95%B0%E4%B8%8A/">《神奇的伽瑪函數(上)》</a><br/>
<a href="http://www.flickering.cn/%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/2014/06/%E7%A5%9E%E5%A5%87%E7%9A%84%E4%BC%BD%E7%8E%9B%E5%87%BD%E6%95%B0%E4%B8%8A/">神奇的伽瑪函數(下)</a></p>

<p>*<a href="http://cxwangyi.github.io/2014/01/20/distributed-machine-learning/">《分布式機器學習的故事》</a><br/>
介紹:作者王益目前是騰訊廣告算法總監，王益博士畢業後在google任研究。這篇文章王益博士7年來從谷歌到騰訊對於分布機器學習的所見所聞。值得細讀</p>

<p>*<a href="http://metacademy.org/roadmaps/cjrd/level-up-your-ml">《機器學習提升之道（Level-Up Your Machine Learning）》</a><br/>
介紹:把機器學習提升的級別分為0~4級，每級需要學習的教材和掌握的知識。這樣，給機器學習者提供一個上進的路線圖，以免走彎路。另外，整個網站都是關於機器學習的，資源很豐富。</p>

<p>*<a href="http://www.mlsurveys.com/">Machine Learning Surveys</a><br/>
介紹:機器學習各個方向綜述的網站</p>

<p>*<a href="http://deeplearning.net/reading-list/">Deep Learning Reading list</a><br/>
介紹:深度學習閱資源列表</p>

<p>*<a href="http://research.microsoft.com/pubs/219984/DeepLearningBook_RefsByLastFirstNames.pdf">《Deep Learning: Methods and Applications》</a><br/>
介紹：這是一本來自微的研究員 li Peng和Dong Yu所著的關於深度學習的方法和應用的電子書</p>

<p>*<a href="http://pan.baidu.com/s/1pJ0ok7T">《Machine Learning Summer School 2014》</a><br/>
介紹:2014年七月CMU舉辦的機器學習夏季課剛剛結束 有近50小時的視頻、十多個PDF版幻燈片，覆蓋 深度學習，貝葉斯，分布式機器學習，伸縮性 等熱點話題。所有13名講師都是牛人：包括大牛Tom Mitchell （他的［機器學習］是名校的常用教材），還有CMU李沐 .（1080P高清喲）</p>

<p>*<a href="http://users.soe.ucsc.edu/%7Eniejiazhong/slides/chandra.pdf">《Sibyl: 來自Google的大規模機器學習系統》</a><br/>
介紹:在今年的IEEE/IFIP可靠系統和網絡（DSN）國際會議上，Google軟件工程師Tushar Chandra做了一個關於Sibyl系統的主題演講。 Sibyl是一個監督式機器學習系統，用來解決預測方面的問題，比如YouTube的視頻推薦。詳情請閱讀<a href="http://www.infoq.com/cn/news/2014/07/google-sibyl">google sibyl</a></p>

<p>*<a href="http://googleresearch.blogspot.com/2014/09/building-deeper-understanding-of-images.html">《Building a deeper understanding of images》</a><br/>
介紹:谷歌研究院的Christian Szegedy在谷歌研究院的博客上簡要地介紹了他們今年參加ImageNet取得好成績的GoogLeNet系統.是關於圖像處理的。</p>

<p>*<a href="https://github.com/memect/hao/blob/master/awesome/bayesian-network-python.md">《Bayesian network 與python概率編程實戰入門》</a><br/>
介紹:貝葉斯學習。如果不是很清可看看<a href="http://www.infoq.com/cn/news/2014/07/programming-language-bayes">概率編程語言與貝葉斯方法實踐</a></p>

<p>*<a href="http://www.reddit.com/r/MachineLearning/comments/2fxi6v/ama_michael_i_jordan/">《AMA: Michael I Jordan》</a><br/>
介紹:網友問伯克利機器學習大牛、美國雙料院士Michael I. Jordan：&#8221;如果你有10億美金，你怎麽花？Jordan: &ldquo;我會用這10億美金建造一個NASA級別的自然語言處理研究項目。&rdquo;</p>

<p>*<a href="http://www.cnblogs.com/tornadomeet/p/3395593.html">《機器學習&amp;數據挖掘筆記_16（常見面試之機器學習算法思想簡單梳理）》</a><br/>
介紹:常見面試之機器學習算法思想簡單梳理,此外作者還有一些其他的<a href="http://www.cnblogs.com/tornadomeet/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">機器學習與數據挖掘文章</a>和<a href="http://www.cnblogs.com/tornadomeet/tag/Deep%E3%80%80Learning/">深度學習文章</a>,不僅是理論還有源碼。</p>

<p>*<a href="http://www.kdnuggets.com/2014/09/most-viewed-web-mining-lectures-videolectures.html">《文本與數據挖掘視頻匯總》</a><br/>
介紹：Videolectures上最受歡迎的25個文本與數據挖掘視頻匯總</p>

<p>*<a href="http://timdettmers.wordpress.com/2014/08/14/which-gpu-for-deep-learning/">《怎麽選擇深度學習的GPUs》</a><br/>
介紹:<a href="http://t.cn/RhpuD1G">在Kaggle上經常取得不錯成績的Tim Dettmers介紹了他自己是怎麽選擇深度學習的GPUs, 以及個人如何構建深度學習的GPU集群:</a></p>

<p>*<a href="http://www.infoq.com/cn/news/2014/09/depth-model">《對話機器學習大神Michael Jordan：深度模型》</a><br/>
介紹:對話機器學習大神Michael Jordan</p>

<p>*<a href="http://blog.sina.com.cn/s/blog_46d0a3930101fswl.html">《Deep Learning 和 Knowledge Graph 引爆大數據革命》</a><br/>
介紹:還有<a href="http://blog.sina.com.cn/s/blog_46d0a3930101gs5h.html">２，３部分</a></p>

<p>*<a href="http://blog.sina.com.cn/s/blog_46d0a3930101h6nf.html">《Deep Learning 教程翻譯》</a><br/>
介紹:是Stanford 教授 Andrew Ng 的 Deep Learning 教程，國內的機器學習愛好者很熱心的把這個教程翻譯成了中文。如果你英語不好，可以看看這個</p>

<p>*<a href="http://markus.com/deep-learning-101/">《Deep Learning 101》</a><br/>
介紹:因為近兩年來，深度學習在媒體界被炒作很厲害（就像大數據）。其實很多人都還不知道什麽是深度學習。這篇文章由淺入深。告訴你深度學究竟是什麽！</p>

<p>*<a href="http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial">《UFLDL Tutorial》</a><br/>
介紹:這是斯坦福大學做的一免費課程（很勉強），這個可以給你在深度學習的路上給你一個學習的思路。裏面提到了一些基本的算法。而且告訴你如何去應用到實際環境中。<a href="http://ufldl.stanford.edu/wiki/index.php/UFLDL%E6%95%99%E7%A8%8B">中文版</a></p>

<p>*<a href="http://deeplearning.cs.toronto.edu/">《Toronto Deep Learning Demos》</a><br/>
介紹:這是多倫多大學做的一個深度學習用來識別圖片標簽／圖轉文字的demo。是一個實際應用案例。有源碼</p>

<p>*<a href="http://metacademy.org/roadmaps/rgrosse/deep_learning">《Deep learning from the bottom up》</a><br/>
介紹:機器學習模型，閱讀這個內容需要有一定的基礎。</p>

<p>*<a href="http://cran.r-project.org/web/views/">《R工具包的分類匯總》</a><br/>
介紹: (CRAN Task Views, 34種常見任務,每個任務又各自分類列舉若幹常用相關工具包) 例如: 機器學習，自然語言處理，時間序列分析，空間信息分析，多重變量分析，計量經濟學，心理統計學，社會學統計，化學計量學，環境科學，藥物代謝動力學 等</p>

<p>*<a href="http://www.ctocio.com/hotnews/15919.html">《機器學習常見算法分類匯總》</a><br/>
介紹: 機器學習無疑是當前數據分析領域的一個熱點內容。很多人在平時的工作中都或多或少會用到機器學習的算法。本文為您總結一下常見的機器學習算法，以供您在工作和學習中參考.</p>

<p>*<a href="http://blog.csdn.net/zouxy09/article/details/8775360">《Deep Learning（深度學習）學習筆記整理系列》</a><br/>
介紹: 很多幹貨，而且作者還總結了好幾個系列。另外還作者還了一個<a href="http://blog.csdn.net/zouxy09/article/details/14222605">文章導航</a>.非常的感謝作者總結。</p>

<p>*<a href="http://research.microsoft.com/apps/video/default.aspx?id=206976&amp;l=i">《Tutorials Session A &ndash; Deep Learning for Computer Vision》</a><br/>
介紹:傳送理由：Rob Fergus的用深度學習做計算機是覺的NIPS 2013教程。有mp4, mp3, pdf各種<a href="http://msrvideo.vo.msecnd.net/rmcvideos/206976/dl/206976.pdf">下載</a>他是紐約大學教授，目前也在Facebook工作，他2014年的8篇<a href="http://cs.nyu.edu/%7Efergus/pmwiki/pmwiki.php?n=PmWiki.Publications">論文</a></p>

<p>*<a href="https://github.com/xpqiu/fnlp/">《FudanNLP》</a><br/>
介紹:FudanNLP，這是一個復旦大學計算機學院開發的開源中文自然語言處理（NLP）工具包 Fudan NLP裏包含中文分詞、關鍵詞抽取、命名實體識別、詞性標註、時間詞抽取、語法分析等功能，對搜索引擎 文本分析等極為有價值。</p>

<p>*<a href="http://engineering.linkedin.com/large-scale-machine-learning/open-sourcing-ml-ease">《Open Sourcing ml-ease》</a><br/>
介紹:LinkedIn 開源的機器學習工具包,支持單機, Hadoop cluster，和 Spark cluster 重點是 logistic regression 算法</p>

<p>*<a href="http://ztl2004.github.io/MachineLearningWeekly/index.html">《機器學習周刊》</a><br/>
介紹:對於英語不好，但又很想學習機器學習的朋友。是一個大的福利。機器學習周刊目前主要提供中文版，還是面向廣大國內愛好者，內容涉及機器學習、數據挖掘、並行系統、圖像識別、人工智能、機器人等等。謝謝作者</p>

<p>*<a href="http://v.163.com/special/opencourse/daishu.html">《線性代數》</a><br/>
介紹：《線性代數》是《機器學習》的重要數學先導課程。其實《線代》這門課講得淺顯易懂特別不容易，如果一上來就講逆序數及羅列行列式性質，很容易讓學生失去學習的興趣。我個人推薦的最佳《線性代數》課程是麻省理工Gilbert Strang教授的課程。 <a href="http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/">課程主頁</a></p>

<p>*<a href="http://blog.andreamostosi.name/big-data/">《Big-data》</a><br/>
介紹:大數據數據處理資源、工具不完備列表，從框架、分布式編程、分布式文件系統、鍵值數據模型、圖數據模型、數據可視化、列存儲、機器學習等。很贊的資源匯總。</p>

<p>*<a href="http://yahoolabs.tumblr.com/post/97839313996/machine-learning-for-smart-dummies">《machine learning for smart dummies》</a><br/>
介紹:雅虎邀請了一名來自本古裏安大學的訪問學者，制作了一套關於機器學習的系列視頻課程。本課程共分為7期，詳細講解了有關SVM, boosting, nearest neighbors, decision trees 等常規機器學習算法的理論基礎知識。</p>

<p>*<a href="http://arxiv.org/abs/1409.7770">《Entanglement-Based Quantum Machine Learning》</a><br/>
介紹:應對大數據時代，量子機器學習的第一個實驗<a href="http://arxiv-web3.library.cornell.edu/pdf/1409.7770.pdf">paper下載</a></p>

<p>*<a href="http://www.wired.com/2014/01/how-to-hack-okcupid/all/">《How a Math Genius Hacked OkCupid to Find True Love》</a><br/>
介紹:Wired雜誌報道了UCLA數學博士Chris McKinlay （圖1）通過大數據手段+機器學習方法破解婚戀網站配對算法找到真愛的故事,通過Python腳本控制著12個賬號，下載了婚戀網站2萬女用戶的600萬問題答案，對他們進行了統計抽樣及聚類分析（圖2，3），最後終於收獲了真愛。科技改變命運！</p>

<p>*<a href="https://www.edx.org/course/mitx/mitx-6-832x-underactuated-robotics-3511">《Underactuated Robotics》</a><br/>
介紹:MIT的Underactuated Robotics於 2014年10月1日開課，該課屬於MIT研究生級別的課程，對機器人和非線性動力系統感興趣的朋友不妨可以挑戰一下這門課程！</p>

<p>*<a href="http://yanbohappy.sinaapp.com/?p=498">《mllib實踐經驗(1)》</a><br/>
介紹:mllib實踐經驗分享</p>

<p>*<a href="http://www.seobythesea.com/2014/09/google-turns-deep-learning-classification-fight-web-spam/">《Google Turns To Deep Learning Classification To Fight Web Spam》</a><br/>
介紹:Google用Deep Learning做的antispam(反垃圾郵件)</p>

<p>*<a href="https://github.com/memect/hao/blob/master/awesome/nlp.md">NLP常用信息資源</a><br/>
介紹:NLP常用信息資源</p>

<p>*<a href="https://github.com/soulmachine/machine-learning-cheat-sheet">《機器學習速查表》</a><br/>
介紹:機器學習速查表</p>

<p>*<a href="http://arnetminer.org/conferencebestpapers">《Best Papers vs. Top Cited Papers in Computer Science》</a><br/>
介紹：從1996年開始在計算機科學的論文中被引用次數最多的論文</p>

<p>*<a href="http://mmcheng.net/zh/itam/">《InfiniTAM: 基於深度圖像的體數據集成框架》</a><br/>
介紹：把今年的一個ACM Trans. on Graphics (TOG)論文中的代碼整理為一個開源的算法框架，共享出來了。歡迎大家使用。可以實時的采集3D數據、重建出三維模型。Online learning，GPU Random forest，GPU CRF也會後續公開。</p>

<p>*<a href="http://karpathy.github.io/neuralnets/">《Hacker&rsquo;s guide to Neural Networks》</a><br/>
介紹：【神經網絡黑客指南】現在，最火莫過於深度學習（Deep Learning），怎樣更好學習它？可以讓你在瀏覽器中，跑起深度學習效果的超酷開源項目convnetjs作者karpathy告訴你，最佳技巧是，當你開始寫代碼，一切將變得清晰。他剛發布了一本圖書，不斷在線更新</p>

<p>*<a href="http://machinelearningmastery.com/building-a-production-machine-learning-infrastructure/">《Building a Production Machine Learning Infrastructure》</a><br/>
介紹：前Google廣告系統工程師Josh Wills 講述工業界和學術界機器學習的異同,大實話</p>

<p>*<a href="http://neo4j.com/blog/deep-learning-sentiment-analysis-movie-reviews-using-neo4j/">《Deep Learning Sentiment Analysis for Movie Reviews using Neo4j》</a><br/>
介紹：使用<a href="http://www.neo4j.org/">Neo4j</a>做電影評論的情感分析。</p>

<p>*<a href="http://memkite.com/deep-learning-bibliography/">《DeepLearning.University – An Annotated Deep Learning Bibliography》</a><br/>
介紹：不僅是資料，而且還對有些資料做了註釋。</p>

<p>*<a href="http://www.datarobot.com/blog/a-primer-on-deep-learning/">《A primer on deeping learning》</a><br/>
介紹：深度學習入門的初級讀本</p>

<p>*<a href="https://news.ycombinator.com/item?id=8379571">《Machine learning is teaching us the secret to teaching 》</a><br/>
介紹：機器學習教會了我們什麽？</p>

<p>*<a href="http://scikit-learn.org/stable/documentation.html">《scikit-learn：用於機器學習的Python模塊</a><br/>
介紹：scikit-learn是在SciPy基礎上構建的用於機器學習的Python模塊。</p>

<p>*<a href="http://www.infoq.com/cn/news/2014/10/interview-michael-jordan">《對話機器學習大神Michael Jordan：解析領域中各類模型》</a><br/>
介紹：喬丹教授（Michael I. Jordan）教授是機器學習領域神經網絡的大牛，他對深度學習、神經網絡有著很濃厚的興趣。因此，很多提問的問題中包含了機器學習領域的各類模型，喬丹教授對此一一做了解釋和展望。</p>

<p>*<a href="http://www.redblobgames.com/pathfinding/a-star/introduction.html">《A*搜索算法的可視化短教程》</a><br/>
介紹：A*搜索是人工智能基本算法，用於高效地搜索圖中兩點的最佳路徑, 核心是 g(n)+h(n): g(n)是從起點到頂點n的實際代價，h(n)是頂點n到目標頂點的估算代價。<a href="https://github.com/memect/hao/issues/256">合集</a></p>

<p>*<a href="http://code.csdn.net/news/2822123">《基於雲的自然語言處理開源項目FudanNLP》</a><br/>
介紹：本項目利用了Microsoft Azure，可以在幾分種內完成NLP on Azure Website的部署，立即開始對FNLP各種特性的試用，或者以REST API的形式調用FNLP的語言分析功能</p>

<p>*<a href="http://www.youku.com/playlist_show/id_22935176.html">《吳立德《概率主題模型&amp;數據科學基礎》》</a><br/>
介紹：現任復旦大學首席教授、計算機軟件博士生導師。計算機科學研究所副所長.內部課程</p>

<p>*<a href="http://ml.memect.com/article/machine-learning-guide.html">機器學習入門資源不完全匯總</a><br/>
介紹：好東西的幹貨真的很多</p>

<p>*<a href="http://memkite.com/deep-learning-bibliography/">收集從2014年開始深度學習文獻</a><br/>
介紹：從硬件、圖像到健康、生物、大數據、生物信息再到量子計算等，Amund Tveit等維護了一個DeepLearning.University小項目：收集從2014年開始深度學習文獻，相信可以作為深度學習的起點,<a href="https://github.com/memkite/DeepLearningBibliography">github</a></p>

<p>*<a href="http://emnlp2014.org/papers/pdf/EMNLP2014148.pdf">EMNLP上兩篇關於股票趨勢的應用論文</a><br/>
介紹：EMNLP上兩篇關於<a href="http://emnlp2014.org/papers/pdf/EMNLP2014148.pdf">stock trend</a>用到了deep model組織特征； <a href="http://emnlp2014.org/papers/pdf/EMNLP2014120.pdf">Exploiting Social Relations and Sentiment for Stock Prediction</a>用到了stock network。</p>

<p>*<a href="http://deeplearning.net/tutorial/deeplearning.pdf">《Bengio組（蒙特利爾大學LISA組）深度學習教程》</a><br/>
介紹：作者是深度學習一線大牛Bengio組寫的教程，算法深入顯出，還有實現代碼，一步步展開。</p>

<p>*<a href="http://arxiv.org/pdf/1410.5401v1.pdf">《學習算法的Neural Turing Machine》</a><br/>
介紹：許多傳統的機器學習任務都是在學習function，不過谷歌目前有開始學習算法的趨勢。谷歌另外的這篇學習Python程序的<a href="http://arxiv.org/pdf/1410.4615v1.pdf">Learning to Execute</a>也有相似之處</p>

<p>*<a href="http://www.morganclaypool.com/doi/abs/10.2200/S00607ED2V01Y201410HLT026">《Learning to Rank for Information Retrieval and Natural Language Processing》</a><br/>
介紹：作者是華為技術有限公司，諾亞方舟實驗室，首席科學家的李航博士寫的關於信息檢索與自然語言處理的文章</p>

<p>*<a href="http://www.aclweb.org/anthology/D11-1147">《Rumor has it: Identifying Misinformation in Microblogs》</a><br/>
介紹：利用機用器學習在謠言的判別上的應用,此外還有兩個。一個是識別垃圾與虛假信息的<a href="http://digital.cs.usu.edu/%7Ekyumin/tutorial/www-tutorial.pdf">paper</a>.還有一個是<a href="http://www.datatang.com/news/details_1319.htm">網絡輿情及其分析技術</a></p>

<p>*R機器學習實踐](<a href="http://study.163.com/course/introduction/854064.htm">http://study.163.com/course/introduction/854064.htm</a>)<br/>
介紹：該課程是網易公開課的收費課程，不貴，超級便宜。主要適合於對利用R語言進行機器學習，數據挖掘感興趣的人。</p>

<p>*<a href="http://ifeve.com/bigdataanalyticsbeyondhadoop_evolutionofmlrealizaton/">《大數據分析：機器學習算法實現的演化》</a><br/>
介紹：本章中作者總結了三代機器學習算法實現的演化：第一代非分布式的， 第二代工具如Mahout和Rapidminer實現基於Hadoop的擴展，第三代如Spark和Storm實現了實時和叠代數據處理。<a href="http://ifeve.com/wp-content/uploads/2014/05/big-data-analytics-beyond-hadoop.pdf">BIG DATA ANALYTICS BEYOND HADOOP</a></p>

<p>*<a href="http://book.douban.com/subject/5921462/">《圖像處理，分析與機器視覺》</a><br/>
介紹：講計算機視覺的四部奇書（應該叫經典吧）之一，另外三本是Hartley的《多圖幾何》、Gonzalez的《數字圖像處理》、Rafael C.Gonzalez / Richard E.Woods的<a href="http://book.douban.com/subject/1106342/">《數字圖像處理》</a></p>

<p>*<a href="http://pan.baidu.com/s/1sjFeLTN">《LinkedIn最新的推薦系統文章Browsemaps》</a><br/>
介紹：裏面基本沒涉及到具體算法，但作者介紹了CF在LinkedIn的很多應用，以及他們在做推薦過程中獲得的一些經驗。最後一條經驗是應該監控log數據的質量，因為推薦的質量很依賴數據的質量！</p>

<p>*<a href="http://blog.sina.com.cn/s/blog_574a437f01019poo.html">《初學者如何查閱自然語言處理（NLP）領域學術資料》</a><br/>
介紹：初學者如何查閱自然語言處理（NLP）領域學術資料</p>

<p>*<a href="http://www.open-electronics.org/raspberry-pi-and-the-camera-pi-module-face-recognition-tutorial/">《樹莓派的人臉識別教程》</a><br/>
介紹：用樹莓派和相機模塊進行人臉識別</p>

<p>*<a href="http://www.hangli-hl.com/uploads/3/1/6/8/3168008/short_text_conversation_mla.pdf">《利用深度學習與大數據構建對話系統》</a><br/>
介紹：如何利用深度學習與大數據構建對話系統</p>

<p>*<a href="http://lear.inrialpes.fr/people/mairal/resources/pdf/review_sparse_arxiv.pdf">《經典論文Leo Breiman：Statistical Modeling: The Two Cultures》</a><br/>
介紹：Francis Bach合作的有關稀疏建模的新綜述(書)：Sparse Modeling for Image and Vision Processing，內容涉及Sparsity, Dictionary Learning, PCA, Matrix Factorization等理論，以及在圖像和視覺上的應用，而且第一部分關於Why does the l1-norm induce sparsity的解釋也很不錯。</p>

<p>*<a href="http://www.umiacs.umd.edu/%7Ehal/docs/daume04rkhs.pdf">《Reproducing Kernel Hilbert Space》</a><br/>
介紹：RKHS是機器學習中重要的概念，其在large margin分類器上的應用也是廣為熟知的。如果沒有較好的數學基礎，直接理解RKHS可能會不易。本文從基本運算空間講到Banach和Hilbert空間，深入淺出，一共才12頁。</p>

<p>*<a href="http://karpathy.github.io/neuralnets/">《Hacker&rsquo;s guide to Neural Networks》</a><br/>
介紹：許多同學對於機器學習及深度學習的困惑在於，數學方面已經大致理解了，但是動起手來卻不知道如何下手寫代碼。斯坦福深度學習博士Andrej Karpathy寫了一篇實戰版本的深度學習及機器學習教程，手把手教你用Javascript寫神經網絡和SVM.</p>

<p>*<a href="http://blog.csdn.net/pandalibaba/article/details/17409395">《【語料庫】語料庫資源匯總》</a><br/>
介紹：【語料庫】語料庫資源匯總</p>

<p>*<a href="http://blog.jobbole.com/60809/">《機器學習算法之旅》</a><br/>
介紹：本文會過一遍最流行的機器學習算法，大致了解哪些方法可用，很有幫助。</p>

<p>*<a href="http://www.csee.wvu.edu/%7Exinl/source.html">《Reproducible Research in Computational Science》</a><br/>
介紹：這個裏面有很多關於機器學習、信號處理、計算機視覺、深入學習、神經網絡等領域的大量源代碼（或可執行代碼）及相關論文。科研寫論文的好資源</p>

<p>*<a href="http://cilvr.nyu.edu/doku.php?id=deeplearning:slides:start">NYU 2014年的深度學習課程資料</a><br/>
介紹：NYU 2014年的深度學習課程資料，有視頻</p>

<p>*<a href="https://github.com/memect/hao/blob/master/awesome/computer-vision-dataset.md">《計算機視覺數據集不完全匯總》</a><br/>
介紹：計算機視覺數據集不完全匯總</p>

<p>*<a href="http://mloss.org/software/">《Machine Learning Open Source Software》</a><br/>
介紹：機器學習開源軟件</p>

<p>*<a href="http://www.csie.ntu.edu.tw/%7Ecjlin/libsvm/">《LIBSVM》</a><br/>
介紹：A Library for Support Vector Machines</p>

<p>*<a href="http://www.support-vector-machines.org/index.html">《Support Vector Machines》</a><br/>
介紹：<a href="https://github.com/ty4z2008/Qix/blob/master/files.cnblogs.com/tekson/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B9%8B%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95.doc">數據挖掘十大經典算法</a>之一</p>

<p>*<a href="http://meta-guide.com/software-meta-guide/100-best-github-deep-learning/">《100 Best GitHub: Deep Learning》</a><br/>
介紹：github上面100個非常棒的項目</p>

<p>*<a href="http://archive.ics.uci.edu/ml">《加州大學歐文分校(UCI)機器學習數據集倉庫》</a><br/>
介紹：當前加州大學歐文分校為機器學習社區維護著306個數據集。<a href="http://archive.ics.uci.edu/ml/datasets.html">查詢數據集</a></p>

<p>*<a href="http://cs.stanford.edu/people/karpathy/">Andrej Karpathy個人主頁</a><br/>
介紹：Andrej Karpathy 是斯坦福大學Li Fei-Fei的博士生，使用機器學習在圖像、視頻語義分析領域取得了科研和工程上的突破，發的文章不多，但每個都很紮實，在每一個問題上都做到了state-of-art.</p>

<p>*<a href="http://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html">《Andrej Karpathy的深度強化學習演示》</a><br/>
介紹：Andrej Karpathy的深度強化學習演示，<a href="http://arxiv.org/pdf/1312.5602v1.pdf">論文在這裏</a></p>

<p>*<a href="http://www.52nlp.cn/cikm-competition-topdata">《CIKM數據挖掘競賽奪冠算法-陳運文》</a><br/>
介紹：CIKM Cup(或者稱為CIKM Competition)是ACM CIKM舉辦的國際數據挖掘競賽的名稱。</p>

<p>*<a href="http://www.cs.toronto.edu/%7Ehinton/">Geoffrey E. Hinton</a><br/>
介紹：傑弗裏·埃弗裏斯特·辛頓 FRS是一位英國出生的計算機學家和心理學家，以其在神經網絡方面的貢獻聞名。辛頓是反向傳播算法和對比散度算法的發明人之一，也是深度學習的積極推動者.</p>

<p>*<a href="http://cikm2014.fudan.edu.cn/cikm2014/Tpl/Public/slides/CIKM14_tutorial_slides_6.pdf">《自然語言處理的深度學習理論與實際》</a><br/>
介紹：微軟研究院深度學習技術中心在CIKM2014 上關於《自然語言處理的深度學習理論與實際》教學講座的幻燈片</p>

<p>*<a href="http://eugenezhulenev.com/blog/2014/11/14/stock-price-prediction-with-big-data-and-machine-learning/">《用大數據和機器學習做股票價格預測》</a><br/>
介紹： 本文基於&lt;支持向量機的高頻限價訂單的動態建模>采用了 Apache Spark和Spark MLLib從紐約股票交易所的訂單日誌數據構建價格運動預測模型。(股票有風險，投資謹慎)<a href="https://github.com/ezhulenev/orderbook-dynamics">GitHub源代碼托管地址.</a></p>

<p>*<a href="http://dataunion.org/?p=2011">《關於機器學習的若幹理論問題》</a><br/>
介紹：徐宗本 院士將於熱愛機器學習的小夥伴一起探討有關於機器學習的幾個理論性問題，並給出一些有意義的結論。最後通過一些實例來說明這些理論問題的物理意義和實際應用價值。</p>

<p>*<a href="http://vdisk.weibo.com/s/D2szyg_bBVM0">《深度學習在自然語言處理的應用》</a><br/>
介紹：作者還著有《這就是搜索引擎：核心技術詳解》一書，主要是介紹應用層的東西</p>

<p>*<a href="http://www.cs.ubc.ca/%7Enando/340-2012/index.php">《Undergraduate machine learning at UBC》</a><br/>
介紹：機器學習課程</p>

<p>*<a href="http://blog.sina.com.cn/s/blog_6ae183910101h4jr.html">《人臉識別必讀的N篇文章》</a><br/>
介紹：人臉識別必讀文章推薦</p>

<p>*<a href="http://semocean.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E6%96%87%E7%8C%AE%E5%8F%8A%E8%B5%84%E6%96%99/">《推薦系統經典論文文獻及業界應用》</a><br/>
介紹：推薦系統經典論文文獻</p>

<p>*<a href="http://ocw.sjtu.edu.cn/G2S/OCW/cn/CourseDetails.htm?Id=398">《統計機器學習》</a><br/>
介紹：統計學習是關於計算機基於數據構建的概率統計模型並運用模型對數據進行預測和分析的一門科學，統計學習也成為統計機器學習。課程來自上海交通大學</p>

<p>*<a href="http://ocw.sjtu.edu.cn/G2S/OCW/cn/CourseDetails.htm?Id=397">《機器學習導論》</a><br/>
介紹：機器學習的目標是對計算機編程，以便使用樣本數據或以往的經驗來解決給定的問題.</p>

<p>*<a href="http://deeplearning.net/software_links/">人工智能和機器學習領域有趣的開源項目</a><br/>
介紹：<a href="http://code.csdn.net/news/2822818">部分中文列表</a></p>

<p>*<a href="http://blog.csdn.net/suipingsp/article/details/41645779">《機器學習經典算法詳解及Python實現&mdash;基於SMO的SVM分類器》</a><br/>
介紹:此外作者還有一篇<a href="http://blog.csdn.net/suipingsp/article/details/41722435">元算法、AdaBoost　python實現文章</a></p>

<p>*<a href="http://aria42.com/blog/2014/12/understanding-lbfgs/">《Numerical Optimization: Understanding L-BFGS》</a><br/>
介紹:加州伯克利大學博士Aria Haghighi寫了一篇超贊的數值優化博文，從牛頓法講到擬牛頓法，再講到BFGS以及L-BFGS, 圖文並茂，還有偽代碼。強烈推薦。</p>

<p>*<a href="http://www.goldencui.org/2014/12/02/%E7%AE%80%E6%98%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0%EF%BC%88%E4%B8%80%EF%BC%89/">《簡明深度學習方法概述（一）》</a><br/>
<a href="http://www.goldencui.org/2014/12/06/%E7%AE%80%E6%98%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0%EF%BC%88%E4%BA%8C%EF%BC%89/">《簡明深度學習方法概述（二）》</a></p>

<p>*<a href="http://www.johndcook.com/blog/r_language_for_programmers/">《R language for programmers》</a><br/>
介紹:Ｒ語言程序員私人定制版</p>

<p>*<a href="http://www.cheyun.com/content/news/4051">《谷歌地圖解密：大數據與機器學習的結合》</a><br/>
介紹:谷歌地圖解密</p>

<p>*<a href="http://blog.csdn.net/u012690204/article/details/41853731">《空間數據挖掘常用方法》</a><br/>
介紹:空間數據挖掘常用方法</p>

<p>*<a href="https://www.kaggle.com/c/word2vec-nlp-tutorial">《Use Google&rsquo;s Word2Vec for movie reviews》</a><br/>
介紹:Kaggle新比賽 ”When bag of words meets bags of popcorn“ aka ”邊學邊用word2vec和deep learning做NLP“ 裏面全套教程教一步一步用python和gensim包的word2vec模型，並在實際比賽裏面比調參數和清數據。 如果已裝過gensim不要忘升級</p>

<p>*<a href="http://pynlpir.readthedocs.org/en/latest/">《PyNLPIR》</a><br/>
介紹:PyNLPIR提供了NLPIR/ICTCLAS漢語分詞的Python接口,此外<a href="http://zhon.readthedocs.org/en/latest/">Zhon</a>提供了常用漢字常量，如CJK字符和偏旁，中文標點，拼音，和漢字正則表達式（如找到文本中的繁體字）</p>

<p>*<a href="http://www.technologyreview.com/view/533496/why-neural-networks-look-set-to-thrash-the-best-human-go-players-for-the-first-time/">《深度卷積神經網絡下圍棋》</a><br/>
介紹:這文章說把最近模型識別上的突破應用到圍棋軟件上，打16萬張職業棋譜訓練模型識別功能。想法不錯。訓練後目前能做到不用計算，只看棋盤就給出下一步，大約10級棋力。但這篇文章太過樂觀，說什麽人類的最後一塊堡壘馬上就要跨掉了。話說得太早。不過，如果與別的軟件結合應該還有潛力可挖。@萬精油墨綠</p>

<p>*<a href="http://mrtz.org/blog/the-nips-experiment/">《NIPS審稿實驗》</a><br/>
介紹:UT Austin教授Eric Price關於今年NIPS審稿實驗的詳細分析,他表示，根據這次實驗的結果，如果今年NIPS重新審稿的話，會有一半的論文被拒。</p>

<p>*<a href="http://www.kdnuggets.com/2014/12/top-kdnuggets-2014-analytics-big-data-science-stories.html">《2014年最佳的大數據，數據科學文章》</a><br/>
介紹:KDNuggets分別總結了2014年14個閱讀最多以及分享最多的文章。我們從中可以看到多個主題——深度學習，數據科學家職業，教育和薪酬，學習數據科學的工具比如R和Python以及大眾投票的最受歡迎的數據科學和數據挖掘語言</p>

<p>*<a href="http://blog.csdn.net/suipingsp/article/details/42101139">《機器學習經典算法詳解及Python實現&mdash;線性回歸（Linear Regression）算法》</a><br/>
介紹:Python實現線性回歸,作者還有其他很棒的文章推薦可以看看</p>

<p>*<a href="http://download.csdn.net/album/detail/1367/1/1">《2014中國大數據技術大會33位核心專家演講PDF》</a><br/>
介紹：2014中國大數據技術大會33位核心專家演講PDF下載</p>

<p>*<a href="http://arxiv.org/abs/1412.5335">《使用RNN和Paragraph Vector做情感分析》</a><br/>
介紹：這是T. Mikolov &amp; Y. Bengio最新論文Ensemble of Generative and Discriminative Techniques for Sentiment Analysis of Movie Reviews ，使用RNN和PV在情感分析效果不錯，<a href="https://github.com/mesnilgr/iclr15">項目代碼</a>公布在github(目前是空的)。這意味著Paragraph Vector終於揭開面紗了嘛。</p>

<p>*<a href="http://pan.baidu.com/s/1o6I9S18">《NLPIR/ICTCLAS2015分詞系統大會上的技術演講 》</a><br/>
介紹:NLPIR/ICTCLAS2015分詞系統發布與用戶交流大會上的演講，請更多朋友檢閱新版分詞吧。</p>

<p>*<a href="https://medium.com/code-poet/80ea3ec3c471">《Machine Learning is Fun!》</a><br/>
介紹:Convex Neural Networks 解決維數災難</p>

<p>*<a href="http://dataunion.org/?p=5395">《CNN的反向求導及練習》</a><br/>
介紹:介紹CNN參數在使用bp算法時該怎麽訓練，畢竟CNN中有卷積層和下采樣層，雖然和MLP的bp算法本質上相同，但形式上還是有些區別的，很顯然在完成CNN反向傳播前了解bp算法是必須的。此外作者也做了一個<a href="http://www.cnblogs.com/tornadomeet/archive/2012/05/24/2515980.html">資源集:機器學習，深度學習，視覺，數學等</a></p>

<p>*<a href="https://github.com/cloudflare/ahocorasick">《正則表達式優化成Trie樹 》</a><br/>
介紹:如果要在一篇文章中匹配十萬個關鍵詞怎麽辦？<a href="https://github.com/cloudflare/ahocorasick">Aho-Corasick</a>算法利用添加了返回邊的Trie樹，能夠在線性時間內完成匹配。 但如果匹配十萬個正則表達式呢 ？ 這時候可以用到把多個正則優化成Trie樹的方法，如日本人寫的<a href="http://search.cpan.org/%7Edankogai/Regexp-Trie-0.02/">Regexp::Trie</a></p>

<p>*<a href="http://jmozah.github.io/links/">《Deep learning Reading List》</a><br/>
介紹:深度學習閱讀清單</p>

<p>*<a href="http://caffe.berkeleyvision.org/">Caffe</a><br/>
介紹:Caffe是一個開源的深度學習框架，作者目前在google工作，作者主頁<a href="http://daggerfs.com/index.html">Yangqing Jia (賈揚清)</a></p>

<p>*<a href="https://github.com/BVLC/caffe/blob/master/models/bvlc_googlenet/readme.md">《GoogLeNet深度學習模型的Caffe復現》</a><br/>
介紹:2014 ImageNet冠軍GoogLeNet深度學習模型的Caffe復現模型,<a href="http://arxiv.org/abs/1409.4842">GoogleNet論文</a>.</p>

<p>*<a href="https://github.com/jbarrow/LambdaNet">《LambdaNet，Haskell實現的開源人工神經網絡庫》</a><br/>
介紹:LambdaNetLambdaNet是由Haskell實現的一個開源的人工神經網絡庫，它抽象了網絡創建、訓練並使用了高階函數。該庫還提供了一組預定義函數，用戶可以采取多種方式組合這些函數來操作現實世界數據。</p>

<p>*<a href="http://wenku.baidu.com/course/view/49e8b8f67c1cfad6195fa705">《百度余凱&amp;張潼機器學習視頻》</a><br/>
介紹:如果你從事互聯網搜索，在線廣告，用戶行為分析，圖像識別，自然語言理解，或者生物信息學，智能機器人，金融預測，那麽這門核心課程你必須深入了解。</p>

<p>*<a href="http://v.youku.com/v_show/id_XODQzNDM4MDg0.html">楊強在TEDxNanjing談智能的起源</a><br/>
介紹:&ldquo;人工智能研究分許多流派。其中之一以IBM為代表，認為只要有高性能計算就可得到智能，他們的‘深藍’擊敗了世界象棋冠軍；另一流派認為智能來自動物本能；還有個很強的流派認為只要找來專家，把他們的思維用邏輯一條條寫下，放到計算機裏就行……&rdquo; 楊強在TEDxNanjing談智能的起源</p>

<p>*<a href="http://www.machinelearning.org/proceedings/icml2006/047_Connectionist_Tempor.pdf">《深度RNN/LSTM用於結構化學習 0)序列標註Connectionist Temporal ClassificationICML06》</a><br/>
介紹:1)機器翻譯<a href="http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf">Sequence to Sequence NIPS14</a> 2)成分句法<a href="http://arxiv.org/pdf/1412.7449v1.pdf">GRAMMAR AS FOREIGN LANGUAGE</a></p>

<p>*<a href="http://techblog.youdao.com/?p=915">《Deep Learning實戰之word2vec》</a><br/>
介紹:網易有道的三位工程師寫的word2vec的解析文檔，從基本的詞向量/統計語言模型->NNLM->Log-Linear/Log-Bilinear->層次化Log-Bilinear，到CBOW和Skip-gram模型，再到word2vec的各種tricks，公式推導與代碼，基本上是網上關於word2vec資料的大合集，對word2vec感興趣的朋友可以看看</p>

<p>*<a href="http://mloss.org/software/">《Machine learning open source software》</a><br/>
介紹:機器學習開源軟件,收錄了各種機器學習的各種編程語言學術與商業的開源軟件．與此類似的還有很多例如:<a href="http://www.dmoz.org/Computers/Artificial_Intelligence/Machine_Learning/Software/">DMOZ &ndash; Computers: Artificial Intelligence: Machine Learning: Software</a>, <a href="http://www.csie.ntu.edu.tw/%7Ecjlin/libsvm/">LIBSVM &mdash; A Library for Support Vector Machines</a>,　<a href="http://www.cs.waikato.ac.nz/ml/weka/">Weka 3: Data Mining Software in Java</a>,　<a href="http://scikit-learn.org/stable/">scikit-learn:Machine Learning in Python</a>,　<a href="https://github.com/ty4z2008/Qix/blob/master/www.nltk.org">Natural Language Toolkit:NLTK</a>,　<a href="http://mallet.cs.umass.edu/">MAchine Learning for LanguagE Toolkit</a>,　<a href="http://orange.biolab.si/">Data Mining &ndash; Fruitful and Fun</a>,　<a href="http://opencv.willowgarage.com/wiki/">Open Source Computer Vision Library</a></p>

<p>*<a href="http://www.guokr.com/post/512037/">《機器學習入門者學習指南》</a><br/>
介紹:作者是計算機研二(寫文章的時候，現在是2015年了應該快要畢業了)，專業方向自然語言處理．這是一點他的經驗之談．對於入門的朋友或許會有幫助</p>

<p>*<a href="http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/">《A Tour of Machine Learning Algorithms》</a><br/>
介紹:這是一篇關於機器學習算法分類的文章，非常好</p>

<p>*<a href="http://ml.memect.com/download/2014.zip">2014年的《機器學習日報》大合集</a><br/>
介紹:機器學習日報裏面推薦很多內容，在這裏有一部分的優秀內容就是來自機器學習日報．</p>

<p>*<a href="http://blog.csdn.net/abcjennifer/article/details/42493493">《Image classification with deep learning常用模型》</a><br/>
介紹:這是一篇關於圖像分類在深度學習中的文章</p>

<p>*<a href="http://research.microsoft.com/en-us/people/deng/">《自動語音識別：深度學習方法》</a><br/>
介紹:作者與Bengio的兄弟Samy 09年合編《自動語音識別：核方法》 3）李開復1989年《自動語音識別》專著，其博導、94年圖靈獎得主Raj Reddy作序</p>

<p>*<a href="http://blog.csdn.net/heiyeshuwu/article/details/42554903">《NLP中的中文分詞技術》</a><br/>
介紹: 作者是360電商技術組成員,這是一篇NLP在中文分詞中的應用</p>

<p>*<a href="http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/">《Using convolutional neural nets to detect facial keypoints tutorial》</a><br/>
介紹: 使用deep learning的人臉關鍵點檢測，此外還有一篇<a href="https://www.kaggle.com/c/facial-keypoints-detection/details/deep-learning-tutorial">AWS部署教程</a></p>

<p>*<a href="http://www.amazon.cn/Advanced-Structured-Prediction-Nowozin-Sebastian/dp/0262028379">《書籍推薦:Advanced Structured Prediction》</a><br/>
介紹: 由Sebastian Nowozin等人編纂MIT出版的新書<a href="http://t.cn/RZxipKG">《Advanced Structured Prediction》</a>，匯集了結構化預測領域諸多牛文，涉及CV、NLP等領域，值得一讀。網上公開的幾章草稿:<a href="http://www2.informatik.hu-berlin.de/%7Ekloftmar/publications/strucBook.pdf">一</a>,<a href="http://mlg.eng.cam.ac.uk/yutian/Publications/ChenGelfandWelling14-HerdingBookChapter.pdf">二</a>,<a href="http://web.engr.oregonstate.edu/%7Esinisa/research/publications/StructPredictionChapter14.pdf">三</a>,<a href="http://ttic.uchicago.edu/%7Emeshi/papers/smoothCD_chapter.pdf">四</a>,<a href="http://www.cs.ox.ac.uk/Stanislav.Zivny/homepage/publications/zwp14mit-draft.pdf">五</a></p>

<p>*<a href="http://arxiv.org/pdf/1501.01571v1.pdf">《An Introduction to Matrix Concentration Inequalities》</a><br/>
介紹: Tropp把數學家用高深裝逼的數學語言寫的矩陣概率不等式用初等的方法寫出來，是非常好的手冊，領域內的paper各種證明都在用裏面的結果。雖說是初等的，但還是非常的難</p>

<p>*<a href="https://agenda.weforum.org/2014/12/the-free-big-data-sources-you-should-know/">《The free big data sources you should know》</a><br/>
介紹: 不容錯過的免費大數據集，有些已經是耳熟能詳，有些可能還是第一次聽說，內容跨越文本、數據、多媒體等，讓他們伴你開始數據科學之旅吧，具體包括：Data.gov、US Census Bureau、European Union Open Data Portal、Data.gov.uk等</p>

<p>*<a href="http://yyue.blogspot.com/2015/01/a-brief-overview-of-deep-learning.html">《A Brief Overview of Deep Learning》</a><br/>
介紹: 谷歌科學家、Hinton親傳弟子Ilya Sutskever的深度學習綜述及實際建議</p>

<p>*<a href="http://nikhilbuduma.com/2015/01/11/a-deep-dive-into-recurrent-neural-networks/">《A Deep Dive into Recurrent Neural Nets》</a><br/>
介紹: 非常好的討論遞歸神經網絡的文章，覆蓋了RNN的概念、原理、訓練及優化等各個方面內容，強烈推薦！本文作者Nikhil Buduma還有一篇<a href="http://nikhilbuduma.com/2014/12/29/deep-learning-in-a-nutshell/">Deep Learning in a Nutshell</a>值得推薦</p>

<p>*<a href="http://qianjiye.de/2014/11/machine-learning-resources/">機器學習：學習資源</a><br/>
介紹:裏面融合了很多的資源，例如競賽，在線課程，demo，數據整合等。有分類</p>

<p>*<a href="https://www.otexts.org/book/sfml">《Statistical foundations of machine learning》</a><br/>
介紹:《機器學習的統計基礎》在線版，該手冊希望在理論與實踐之間找到平衡點，各主要內容都伴有實際例子及數據，書中的例子程序都是用R語言編寫的。</p>

<p>*<a href="http://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks">《A Deep Learning Tutorial: From Perceptrons to Deep Networks》</a><br/>
介紹:IVAN VASILEV寫的深度學習導引：從淺層感知機到深度網絡。高可讀</p>

<p>*<a href="http://futureoflife.org/static/data/documents/research_priorities.pdf">《Research priorities for robust and beneficial artificial intelligence》</a><br/>
介紹:魯棒及有益的人工智能優先研究計劃：一封公開信,目前已經有Stuart Russell, Tom Dietterich, Eric Horvitz, Yann LeCun, Peter Norvig, Tom Mitchell, Geoffrey Hinton, Elon Musk等人簽署<a href="http://futureoflife.org/misc/open_letter">The Future of Life Institute (FLI)</a>.這封信的背景是最近霍金和Elon Musk提醒人們註意AI的潛在威脅。公開信的內容是AI科學家們站在造福社會的角度，展望人工智能的未來發展方向，提出開發AI系統的Verification，Validity, Security, Control四點要求，以及需要註意的社會問題。畢竟當前AI在經濟領域，法律，以及道德領域相關研究較少。其實還有一部美劇<a href="http://tv.sohu.com/20120925/n353925789.shtml">《疑犯追蹤》</a>,介紹了AI的演進從一開始的自我學習，過濾，圖像識別，語音識別等判斷危險，到第四季的時候出現了機器通過學習成長之後想控制世界的狀態。說到這裏推薦收看。</p>

<p>*<a href="http://metacademy.org/">《Metacademy》</a><br/>
介紹:裏面根據詞條提供了許多資源，還有相關知識結構，路線圖，用時長短等。號稱是”機器學習“搜索引擎</p>

<p>*<a href="https://research.facebook.com/blog/879898285375829/fair-open-sources-deep-learning-modules-for-torch/">《FAIR open sources deep-learning modules for Torch》</a><br/>
介紹:Facebook人工智能研究院（FAIR）開源了一系列軟件庫，以幫助開發者建立更大、更快的深度學習模型。開放的軟件庫在 Facebook 被稱作模塊。用它們替代機器學習領域常用的開發環境 Torch 中的默認模塊，可以在更短的時間內訓練更大規模的神經網絡模型。</p>

<p>*<a href="http://www.cnblogs.com/ello/archive/2012/04/28/2475419.html">《淺析人臉檢測之Haar分類器方法》</a><br/>
介紹:本文雖然是寫於2012年，但是這篇文章完全是作者的經驗之作。</p>

<p>*<a href="http://www.ituring.com.cn/article/55994">《如何成為一位數據科學家》</a><br/>
介紹:本文是對《機器學習實戰》作者Peter Harrington做的一個訪談。包含了書中部分的疑問解答和一點個人學習建議</p>

<p>*<a href="http://www.metacademy.org/roadmaps/rgrosse/deep_learning">《Deep learning from the bottom up》</a><br/>
介紹:非常好的深度學習概述，對幾種流行的深度學習模型都進行了介紹和討論</p>

<p>*<a href="http://onepager.togaware.com/TextMiningO.pdf">《Hands-On Data Science with R Text Mining》</a><br/>
介紹:主要是講述了利用R語言進行數據挖掘</p>

<p>*<a href="http://colah.github.io/posts/2014-07-Understanding-Convolutions/">《Understanding Convolutions》</a><br/>
介紹:幫你理解卷積神經網絡，講解很清晰，此外還有兩篇<a href="http://colah.github.io/posts/2014-07-Conv-Nets-Modular/">Conv Nets: A Modular Perspective</a>，<a href="http://colah.github.io/posts/2014-12-Groups-Convolution/">Groups &amp; Group Convolutions</a>. 作者的其他的關於神經網絡文章也很棒</p>

<p>*<a href="http://www.iro.umontreal.ca/%7Epift6266/H10/notes/deepintro.html#introduction-to-deep-learning-algorithms">《Introduction to Deep Learning Algorithms》</a><br/>
介紹:Deep Learning算法介紹，裏面介紹了06年3篇讓deep learning崛起的論文</p>

<p>*<a href="http://www.iro.umontreal.ca/%7Ebengioy/papers/ftml_book.pdf">《Learning Deep Architectures for AI》</a><br/>
介紹:一本學習人工智能的書籍，作者是Yoshua Bengio，<a href="http://www.infoq.com/cn/articles/ask-yoshua-bengio">相關國內報道</a></p>

<p>*<a href="http://www.cs.toronto.edu/%7Ehinton/">Geoffrey E. Hinton個人主頁</a><br/>
介紹:Geoffrey Hinton是Deep Learning的大牛，他的主頁放了一些介紹性文章和課件值得學習</p>

<p>*<a href="http://omega.albany.edu:8008/JaynesBook.html">《PROBABILITY THEORY: THE LOGIC OF SCIENCE》</a><br/>
介紹:概率論：數理邏輯書籍</p>

<p>*<a href="https://github.com/h2oai/h2o">《H2O》</a><br/>
介紹:一個用來快速的統計，機器學習並且對於數據量大的數學庫</p>

<p>*<a href="http://www.iclr.cc/doku.php?id=iclr2015:main">《ICLR 2015會議的arXiv稿件合集》</a><br/>
介紹:在這裏你可以看到最近深度學習有什麽新動向。</p>

<p>*<a href="http://www-nlp.stanford.edu/IR-book/">《Introduction to Information Retrieval》</a><br/>
介紹:此書在信息檢索領域家喻戶曉， 除提供該書的免費電子版外，還提供一個<a href="http://www-nlp.stanford.edu/IR-book/information-retrieval.html">IR資源列表</a>，收錄了信息檢索、網絡信息檢索、搜索引擎實現等方面相關的圖書、研究中心、相關課程、子領域、會議、期刊等等，堪稱全集，值得收藏</p>

<p>*<a href="http://yosinski.com/mlss12/MLSS-2012-Amari-Information-Geometry/">《Information Geometry and its Applications to Machine Learning》</a><br/>
介紹:信息幾何學及其在機器學習中的應用</p>

<p>*<a href="http://computationallegalstudies.com/2015/01/legal-analytics-introduction-course-professors-daniel-martin-katz-michael-j-bommarito/">《Legal Analytics – Introduction to the Course》</a><br/>
介紹:課程《法律分析》介紹幻燈片。用機器學習解決法律相關分析和預測問題，相關的法律應用包括預測編碼、早期案例評估、案件整體情況的預測，定價和工作人員預測，司法行為預測等。法律領域大家可能都比較陌生，不妨了解下。</p>

<p>*<a href="https://github.com/yanxionglu/text_pdf">《文本上的算法》</a><br/>
介紹: 文中提到了最優，模型，最大熵等等理論，此外還有應用篇。推薦系統可以說是一本不錯的閱讀稿，關於模型還推薦一篇<a href="http://blog.sina.com.cn/s/blog_6742eecd0100iqcv.html">Generative Model 與 Discriminative Model</a></p>

<p>*<a href="https://github.com/karpathy/neuraltalk">《NeuralTalk》</a><br/>
介紹: NeuralTalk is a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences.NeuralTalk是一個Python的從圖像生成自然語言描述的工具。它實現了Google (Vinyals等，卷積神經網絡CNN + 長短期記憶LSTM) 和斯坦福 (Karpathy and Fei-Fei， CNN + 遞歸神經網絡RNN)的算法。NeuralTalk自帶了一個訓練好的動物模型，你可以拿獅子大象的照片來試試看</p>

<p>*<a href="https://www.paypal-engineering.com/2015/01/12/deep-learning-on-hadoop-2-0-2/">《Deep Learning on Hadoop 2.0》</a><br/>
介紹:本文主要介紹了在Hadoop2.0上使用深度學習,文章來自paypal</p>

<p>*<a href="http://arxiv.org/abs/1206.5533">《Practical recommendations for gradient-based training of deep architectures》</a><br/>
介紹:用基於梯度下降的方法訓練深度框架的實踐推薦指導,作者是<a href="http://www.iro.umontreal.ca/%7Ebengioy/yoshua_en/research.html">Yoshua Bengio</a></p>

<p>*<a href="http://machinelearningmastery.com/machine-learning-statistical-causal-methods/">《Machine Learning With Statistical And Causal Methods》</a><br/>
介紹: 用統計和因果方法做機器學習（視頻報告）</p>

<p>*<a href="https://www.youtube.com/playlist?list=PLD0F06AA0D2E8FFBA">《Machine Learning Course 160’》</a><br/>
介紹: 一個講機器學習的Youtube視頻教程。160集。系統程度跟書可比擬。</p>

<p>*<a href="http://www.cnblogs.com/LeftNotEasy/archive/2010/12/05/mathmatic_in_machine_learning_1_regression_and_gradient_descent.html">《回歸(regression)、梯度下降(gradient descent)》</a><br/>
介紹: 機器學習中的數學，作者的研究方向是機器學習，並行計算如果你還想了解一點其他的可以看看他<a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/05/02/recommended-blogspots.html">博客</a>的其他文章</p>

<p>*<a href="http://tech.meituan.com/mt-recommend-practice.html">《美團推薦算法實踐》</a><br/>
介紹: 美團推薦算法實踐，從框架，應用，策略，查詢等分析</p>

<p>*<a href="http://arxiv.org/abs/1412.1632">《Deep Learning for Answer Sentence Selection》</a><br/>
介紹: 深度學習用於問答系統答案句的選取</p>

<p>*<a href="http://www.iro.umontreal.ca/%7Elisa/pointeurs/WWW2014.pdf">《Learning Semantic Representations Using Convolutional Neural Networks for Web Search》</a><br/>
介紹: CNN用於WEB搜索，深度學習在文本計算中的應用</p>

<p>*<a href="https://github.com/caesar0301/awesome-public-datasets">《Awesome Public Datasets》</a><br/>
介紹: Awesome系列中的公開數據集</p>

<p>*<a href="http://www.academics.io/">《Search Engine &amp; Community》</a><br/>
介紹: 一個學術搜索引擎</p>

<p>*<a href="http://honnibal.github.io/spaCy/">《spaCy》</a><br/>
介紹: 用Python和Cython寫的工業級自然語言處理庫，號稱是速度最快的NLP庫，快的原因一是用Cython寫的，二是用了個很巧妙的hash技術，加速系統的瓶頸，NLP中稀松特征的存取</p>

<p>*<a href="http://fr.slideshare.net/MrChrisJohnson/collaborative-filtering-with-spark">《Collaborative Filtering with Spark》</a><br/>
介紹: <a href="http://www.fields.utoronto.ca/video-archive/event/323/2014">Fields</a>是個數學研究中心,上面的這份ppt是來自Fields舉辦的活動中Russ Salakhutdinov帶來的《大規模機器學習》分享</p>

<p>*<a href="http://www.7300days.com/index.php/stds/topic/list/id/27/name/Topic%20modeling">《Topic modeling 的經典論文》</a><br/>
介紹: Topic modeling 的經典論文,標註了關鍵點</p>

<p>*<a href="http://arxiv.org/abs/1412.6564">《Move Evaluation in Go Using Deep Convolutional Neural Networks》</a><br/>
介紹: 多倫多大學與Google合作的新論文，深度學習也可以用來下圍棋，據說能達到六段水平</p>

<p>*<a href="http://ztl2004.github.io/MachineLearningWeekly/issue2.html">《機器學習周刊第二期》</a>
介紹: 新聞，paper,課程，book，system,CES,Roboot，此外還推薦一個<a href="http://blog.newitfarmer.com/ai/deep-learning/15302/repost-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E4%B8%8E%E7%BB%BC%E8%BF%B0%E8%B5%84%E6%96%99">深度學習入門與綜述資料</a></p>

<p>*<a href="http://www.bigdata-madesimple.com/learning-more-like-a-human-18-free-ebooks-on-machine-learning/">《Learning more like a human: 18 free eBooks on Machine Learning》</a><br/>
介紹: 18 free eBooks on Machine Learning</p>

<p>*<a href="http://www.hangli-hl.com/">《Recommend :Hang Li Home》</a><br/>
介紹:Chief scientist of Noah&rsquo;s Ark Lab of Huawei Technologies.He worked at the Research Laboratories of NEC Corporation during 1990 and 2001 and Microsoft Research Asia during 2001 and 2012. <a href="http://www.hangli-hl.com/recent-publications.html">Paper</a></p>

<p>*<a href="http://memkite.com/deep-learning-bibliography/">《DEEPLEARNING.UNIVERSITY – AN ANNOTATED DEEP LEARNING BIBLIOGRAPHY》</a><br/>
介紹: DEEPLEARNING.UNIVERSITY的論文庫已經收錄了963篇經過分類的深度學習論文了，很多經典論文都已經收錄</p>

<p>*<a href="https://www.youtube.com/watch?v=wTp3P2UnTfQ&amp;hd=1">《MLMU.cz &ndash; Radim Řehůřek &ndash; Word2vec &amp; friends (7.1.2015)》</a><br/>
介紹: Radim Řehůřek(Gensim開發者)在一次機器學習聚會上的報告，關於word2vec及其優化、應用和擴展，很實用.<a href="http://pan.baidu.com/s/1c03wd24">國內網盤</a></p>

<p>*<a href="http://databricks.com/blog/2015/01/28/introducing-streaming-k-means-in-spark-1-2.html">《Introducing streaming k-means in Spark 1.2》</a><br/>
介紹:很多公司都用機器學習來解決問題，提高用戶體驗。那麽怎麽可以讓機器學習更實時和有效呢？Spark MLlib 1.2裏面的Streaming K-means，由斑馬魚腦神經研究的Jeremy Freeman腦神經科學家編寫，最初是為了實時處理他們每半小時1TB的研究數據，現在發布給大家用了。</p>

<p>*<a href="http://www.hankcs.com/nlp/lda-java-introduction-and-implementation.html">《LDA入門與Java實現》</a><br/>
介紹: 這是一篇面向工程師的LDA入門筆記，並且提供一份開箱即用Java實現。本文只記錄基本概念與原理，並不涉及公式推導。文中的LDA實現核心部分采用了arbylon的LdaGibbsSampler並力所能及地註解了，在搜狗分類語料庫上測試良好，開源在<a href="https://github.com/hankcs/LDA4j">GitHub</a>上。</p>

<p>*<a href="http://aminer.org/">《AMiner &ndash; Open Science Platform》</a><br/>
介紹: AMiner是一個學術搜索引擎，從學術網絡中挖掘深度知識、面向科技大數據的挖掘。收集近4000萬作者信息、8000萬論文信息、1億多引用關系、鏈接近8百萬知識點；支持專家搜索、機構排名、科研成果評價、會議排名。</p>

<p>*<a href="https://www.quora.com/What-are-some-interesting-Word2Vec-results">《What are some interesting Word2Vec results?》</a><br/>
介紹: Quora上的主題，討論Word2Vec的有趣應用，Omer Levy提到了他在CoNLL2014最佳論文裏的分析結果和新方法，Daniel Hammack給出了找特異詞的小應用並提供了<a href="https://github.com/dhammack/Word2VecExample">(Python)代碼</a></p>

<p>*<a href="http://blog.coursegraph.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B1%87%E6%80%BB">《機器學習公開課匯總》</a><br/>
介紹: 機器學習公開課匯總,雖然裏面的有些課程已經歸檔過了，但是還有個別的信息沒有。感謝課程圖譜的小編</p>

<p>*<a href="http://linear.ups.edu/download.html">《A First Course in Linear Algebra》</a><br/>
介紹: 【A First Course in Linear Algebra】Robert Beezer 有答案 有移動版、打印版 使用GNU自由文檔協議 引用了傑弗遜1813年的信</p>

<p>*<a href="https://github.com/ShiqiYu/libfacedetection">《libfacedetection》</a><br/>
介紹:libfacedetection是深圳大學開源的一個人臉圖像識別庫。包含正面和多視角人臉檢測兩個算法.優點:速度快(OpenCV haar+adaboost的2-3倍), 準確度高 (FDDB非公開類評測排名第二），能估計人臉角度。</p>

<p>*<a href="http://dl.acm.org/citation.cfm?doid=2684822.2685310">《Inverting a Steady-State》</a><br/>
介紹:WSDM2015最佳論文 把馬爾可夫鏈理論用在了圖分析上面，比一般的propagation model更加深刻一些。通過全局的平穩分布去求解每個節點影響系數模型。假設合理（轉移受到相鄰的影響系數影響）。可以用來反求每個節點的影響系數</p>

<p>*<a href="http://pan.baidu.com/s/1pJogO7x">《機器學習入門書單》</a><br/>
介紹:機器學習入門書籍，<a href="http://www.hankcs.com/ml/machine-learning-entry-list.html">具體介紹</a></p>

<p>*<a href="http://v1v3kn.tumblr.com/post/47193952400/the-trouble-with-svms">《The Trouble with SVMs》</a><br/>
介紹: 非常棒的強調特征選擇對分類器重要性的文章。情感分類中，根據互信息對復雜高維特征降維再使用樸素貝葉斯分類器，取得了比SVM更理想的效果，訓練和分類時間也大大降低——更重要的是，不必花大量時間在學習和優化SVM上——特征也一樣no free lunch</p>

<p>*<a href="http://www.stat.cmu.edu/%7Elarry/Wasserman.pdf">《Rise of the Machines》</a><br/>
介紹:CMU的統計系和計算機系知名教授Larry Wasserman 在《機器崛起》,對比了統計和機器學習的差異</p>

<p>*<a href="http://tech.meituan.com/mt-mlinaction-how-to-ml.html">《實例詳解機器學習如何解決問題》</a><br/>
介紹:隨著大數據時代的到來，機器學習成為解決問題的一種重要且關鍵的工具。不管是工業界還是學術界，機器學習都是一個炙手可熱的方向，但是學術界和工業界對機器學習的研究各有側重，學術界側重於對機器學習理論的研究，工業界側重於如何用機器學習來解決實際問題。這篇文章是美團的實際環境中的實戰篇</p>

<p>*<a href="http://www.gaussianprocess.org/gpml/">《Gaussian Processes for Machine Learning》</a><br/>
介紹:面向機器學習的高斯過程，章節概要：回歸、分類、協方差函數、模型選擇與超參優化、高斯模型與其他模型關系、大數據集的逼近方法等,<a href="http://vdisk.weibo.com/s/ayG13we2vfWuT">微盤下載</a></p>

<p>*<a href="http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/">《FuzzyWuzzy: Fuzzy String Matching in Python》</a><br/>
介紹:Python下的文本模糊匹配庫，老庫新推，可計算串間ratio(簡單相似系數)、partial_ratio(局部相似系數)、token_sort_ratio(詞排序相似系數)、token_set_ratio(詞集合相似系數)等。<a href="https://github.com/seatgeek/fuzzywuzzy">Github</a></p>

<p>*<a href="http://blocks.readthedocs.org/en/latest/">《Blocks》</a><br/>
介紹:Blocks是基於Theano的神經網絡搭建框架，集成相關函數、管道和算法，幫你更快地創建和管理NN模塊.</p>

<p>*<a href="http://alex.smola.org/teaching/10-701-15/">《Introduction to Machine Learning》</a><br/>
介紹:機器學習大神Alex Smola在CMU新一期的機器學習入門課程”Introduction to Machine Learning“近期剛剛開課，課程4K高清視頻同步到Youtube上，目前剛剛更新到 2.4 Exponential Families,課程視頻<a href="https://www.youtube.com/playlist?list=PLZSO_6-bSqHTTV7w9u7grTXBHMH-mw3qn">playlist</a>, 感興趣的同學可以關註，非常適合入門.</p>

<p>*<a href="http://arxiv.org/abs/1502.01423">《Collaborative Feature Learning from Social Media》</a><br/>
介紹:用社交用戶行為學習圖片的協同特征，可更好地表達圖片內容相似性。由於不依賴於人工標簽(標註)，可用於大規模圖片處理，難在用戶行為數據的獲取和清洗；利用社會化特征的思路值得借鑒.</p>

<p>*<a href="https://blog.twitter.com/2015/introducing-practical-and-robust-anomaly-detection-in-a-time-series">《Introducing practical and robust anomaly detection in a time series》</a><br/>
介紹:Twitter技術團隊對前段時間開源的時間序列異常檢測算法(S-H-ESD)R包的介紹，其中對異常的定義和分析很值得參考，文中也提到——異常是強針對性的，某個領域開發的異常檢測在其他領域直接用可不行.</p>

<p>*<a href="http://www.destinationcrm.com/Articles/Web-Exclusives/Viewpoints/Empower-Your-Team-to-Deal-with-Data-Quality-Issues-101308.aspx">《Empower Your Team to Deal with Data-Quality Issues》</a><br/>
介紹:聚焦數據質量問題的應對，數據質量對各種規模企業的性能和效率都至關重要，文中總結出(不限於)22種典型數據質量問題顯現的信號，以及典型的數據質量解決方案(清洗、去重、統一、匹配、權限清理等)</p>

<p>*<a href="http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E8%B5%84%E6%BA%90">《中文分詞入門之資源》</a><br/>
介紹:中文分詞入門之資源.</p>

<p>*<a href="https://www.youtube.com/playlist?list=PLnDbcXCpYZ8lCKExMs8k4PtIbani9ESX3">《Deep Learning Summit, San Francisco, 2015》</a><br/>
介紹:15年舊金山深度學習峰會視頻集萃,<a href="http://pan.baidu.com/s/1ntiLMcT">國內雲盤</a></p>

<p>*<a href="http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/">《Introduction to Conditional Random Fields》</a><br/>
介紹:很好的條件隨機場(CRF)介紹文章,作者的學習筆記</p>

<p>*<a href="http://cs.stanford.edu/%7Edanqi/papers/emnlp2014.pdf">《A Fast and Accurate Dependency Parser using Neural Networks》</a><br/>
介紹: 來自Stanford，用神經網絡實現快速準確的依存關系解析器</p>

<p>*<a href="https://timdettmers.wordpress.com/2014/08/14/which-gpu-for-deep-learning/">《Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning》</a><br/>
介紹:做深度學習如何選擇GPU的建議</p>

<p>*<a href="http://new.livestream.com/accounts/10932136/events/3779068">《Sparse Linear Models》</a><br/>
介紹: Stanford的Trevor Hastie教授在H2O.ai Meet-Up上的報告，講稀疏線性模型——面向“寬數據”(特征維數超過樣本數)的線性模型,13年同<a href="http://pan.baidu.com/s/1jimPw">主題報告</a>、<a href="http://pan.baidu.com/s/1o6wqW6u">講義</a>.</p>

<p>*<a href="https://github.com/jbhuang0604/awesome-computer-vision">《Awesome Computer Vision》</a><br/>
介紹: 分類整理的機器視覺相關資源列表，秉承Awesome系列風格，有質有量!作者的更新頻率也很頻繁</p>

<p>*<a href="http://www.personal.ceu.hu/staff/Adam_Szeidl/">《Adam Szeidl》</a><br/>
介紹: social networks course</p>

<p>*<a href="http://radar.oreilly.com/2015/01/building-and-deploying-large-scale-machine-learning-pipelines.html/">《Building and deploying large-scale machine learning pipelines》</a><br/>
介紹: 大規模機器學習流程的構建與部署.</p>

<p>*<a href="http://download.csdn.net/detail/lswtzw/8469997">《人臉識別開發包》</a><br/>
介紹: 人臉識別二次開發包，免費，可商用，有演示、範例、說明書.</p>

<p>*<a href="http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/">《Understanding Natural Language with Deep Neural Networks Using Torch》</a><br/>
介紹: 采用Torch用深度學習網絡理解NLP，來自Facebook 人工智能的文章.</p>

<p>*<a href="http://arxiv.org/pdf/1503.00168.pdf">《The NLP Engine: A Universal Turing Machine for NLP》</a><br/>
介紹: 來自CMU的Ed Hovy和Stanford的Jiwei Li一篇有意思的Arxiv文章,作者用Shannon Entropy來刻畫NLP中各項任務的難度.</p>

<p>*<a href="http://staff.city.ac.uk/%7Esb317/papers/foundations_bm25_review.pdf">《TThe Probabilistic Relevance Framework: BM25 and Beyond》</a><br/>
介紹: 信息檢索排序模型BM25(Besting Matching)。1）從經典概率模型演變而來 2）捕捉了向量空間模型中三個影響索引項權重的因子：IDF逆文檔頻率；TF索引項頻率；文檔長度歸一化。3）並且含有集成學習的思想：組合了BM11和BM15兩個模型。4）作者是BM25的提出者和Okapi實現者Robertson.</p>

<p>*<a href="http://www.analyticsvidhya.com/blog/2015/03/introduction-auto-regression-moving-average-time-series/">《Introduction to ARMA Time Series Models – simplified》</a><br/>
介紹: 自回歸滑動平均(ARMA)時間序列的簡單介紹，ARMA是研究時間序列的重要方法，由自回歸模型（AR模型）與滑動平均模型（MA模型）為基礎“混合”構成.</p>

<p>*<a href="http://arxiv.org/pdf/1503.01838v1.pdf">《Encoding Source Language with Convolutional Neural Network for Machine Translation》</a><br/>
介紹: 把來自target的attention signal加入source encoding CNN的輸入，得到了比BBN的模型好的多neural network joint model</p>

<p>*<a href="http://arxiv.org/abs/1502.03815">《Spices form the basis of food pairing in Indian cuisine》</a><br/>
介紹: 揭開印度菜的美味秘訣——通過對大量食譜原料關系的挖掘，發現印度菜美味的原因之一是其中的味道互相沖突，很有趣的文本挖掘研究</p>

<p>*<a href="http://www.52nlp.cn/hmm%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0%E7%B4%A2%E5%BC%95">《HMM相關文章索引》</a><br/>
介紹: HMM相關文章</p>

<p>*<a href="http://www.ccs.neu.edu/home/ekanou/ISU535.09X2/Handouts/Review_Material/zipfslaw.pdf">《Zipf&rsquo;s and Heap&rsquo;s law》</a><br/>
介紹: 1)詞頻與其降序排序的關系,最著名的是語言學家齊夫(Zipf,1902-1950)1949年提出的Zipf‘s law,即二者成反比關系. 曼德勃羅(Mandelbrot,1924- 2010)引入參數修正了對甚高頻和甚低頻詞的刻畫 2)Heaps&#8217; law: 詞匯表與語料規模的平方根(這是一個參數,英語0.4-0.6)成正比</p>

<p>*<a href="http://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/">《I am Jürgen Schmidhuber, AMA》</a><br/>
介紹: Jürgen Schmidhuber在Reddit上的AMA(Ask Me Anything)主題，有不少RNN和AI、ML的幹貨內容，關於開源&amp;思想&amp;方法&amp;建議……耐心閱讀，相信你也會受益匪淺.</p>

<p>*<a href="http://academictorrents.com/">學術種子網站：AcademicTorrents</a><br/>
介紹: 成G上T的學術數據，HN近期熱議話題,主題涉及機器學習、NLP、SNA等。下載最簡單的方法，通過BT軟件，RSS訂閱各集合即可</p>

<p>*<a href="http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html">《機器學習交互速查表》</a><br/>
介紹: Scikit-Learn官網提供，在原有的Cheat Sheet基礎上加上了Scikit-Learn相關文檔的鏈接，方便瀏覽</p>

<p>*<a href="https://timdettmers.wordpress.com/2015/03/09/deep-learning-hardware-guide/">《A Full Hardware Guide to Deep Learning》</a><br/>
介紹: 深度學習的全面硬件指南，從GPU到RAM、CPU、SSD、PCIe</p>

<p>*<a href="http://hi.baidu.com/susongzhi/item/085983081b006311eafe38e7">《行人檢測(Pedestrian Detection)資源》</a><br/>
介紹:Pedestrian Detection paper &amp; data</p>

<p>*<a href="http://arxiv.org/abs/1502.01241">《A specialized face-processing network consistent with the representational geometry of monkey face patches》</a><br/>
介紹: 【神經科學碰撞人工智能】在臉部識別上你我都是專家，即使細微的差別也能辨認。研究已證明人類和靈長類動物在面部加工上不同於其他物種，人類使用梭狀回面孔區（FFA）。Khaligh-Razavi等通過計算機模擬出人臉識別的FFA活動，堪稱神經科學與人工智能的完美結合。</p>

<p>*<a href="https://vimeo.com/19569529">《Neural Net in C++ Tutorial》</a><br/>
介紹: 神經網絡C++教程,本文介紹了用可調節梯度下降和可調節動量法設計和編碼經典BP神經網絡，網絡經過訓練可以做出驚人和美妙的東西出來。此外作者博客的其他文章也很不錯。</p>

<p>*<a href="http://deeplearning4j.org/neuralnetworktable.html">《How to Choose a Neural Network》</a><br/>
介紹:deeplearning4j官網提供的實際應用場景NN選擇參考表，列舉了一些典型問題建議使用的神經網絡</p>

<p>*<a href="https://github.com/yusugomori/DeepLearning">《Deep Learning (Python, C/C++, Java, Scala, Go)》</a><br/>
介紹:一個深度學習項目,提供了Python, C/C++, Java, Scala, Go多個版本的代碼</p>

<p>*<a href="http://deeplearning.net/tutorial/">《Deep Learning Tutorials》</a><br/>
介紹:深度學習教程</p>

<p>*<a href="http://www.ccf.org.cn/resources/1190201776262/2015/03/12/15.pdf">《自然語言處理的發展趨勢——訪卡內基梅隆大學愛德華·霍威教授》</a><br/>
介紹:自然語言處理的發展趨勢——訪卡內基梅隆大學愛德華·霍威教授.</p>

<p>*<a href="http://arxiv.org/abs/1503.03832">《FaceNet: A Unified Embedding for Face Recognition and Clustering》</a><br/>
介紹:Google對Facebook DeepFace的有力回擊—— FaceNet，在LFW(Labeled Faces in the Wild)上達到99.63%準確率(新紀錄)，FaceNet embeddings可用於人臉識別、鑒別和聚類.</p>

<p>*<a href="http://databricks.com/blog/2015/01/21/random-forests-and-boosting-in-mllib.html">《MLlib中的Random Forests和Boosting》</a><br/>
介紹:本文來自Databricks公司網站的一篇博客文章，由Joseph Bradley和Manish Amde撰寫，文章主要介紹了Random Forests和Gradient-Boosted Trees（GBTs）算法和他們在MLlib中的分布式實現，以及展示一些簡單的例子並建議該從何處上手.<a href="http://www.csdn.net/article/2015-03-11/2824178">中文版</a>.</p>

<p>*<a href="http://spn.cs.washington.edu/index.shtml">《Sum-Product Networks(SPN)》</a><br/>
介紹:華盛頓大學Pedro Domingos團隊的DNN，提供論文和實現代碼.</p>

<p>*<a href="http://nlp.stanford.edu/software/nndep.shtml">《Neural Network Dependency Parser》</a><br/>
介紹:基於神經網絡的自然語言依存關系解析器(已集成至Stanford CoreNLP)，特點是超快、準確，目前可處理中英文語料，基於<a href="http://cs.stanford.edu/%7Edanqi/papers/emnlp2014.pdf">《A Fast and Accurate Dependency Parser Using Neural Networks》</a>思路實現.</p>

<p>*<a href="http://www.flickering.cn/nlp/2015/03/%E6%88%91%E4%BB%AC%E6%98%AF%E8%BF%99%E6%A0%B7%E7%90%86%E8%A7%A3%E8%AF%AD%E8%A8%80%E7%9A%84-3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">《神經網絡語言模型》</a><br/>
介紹:本文根據神經網絡的發展歷程，詳細講解神經網絡語言模型在各個階段的形式，其中的模型包含NNLM[Bengio,2003]、Hierarchical NNLM[Bengio, 2005], Log-Bilinear[Hinton, 2007],SENNA等重要變形，總結的特別好.</p>

<p>*<a href="http://www.elg.uottawa.ca/%7Enat/Courses/csi5387_Winter2014/paper13.pdf">《Classifying Spam Emails using Text and Readability Features》</a><br/>
介紹:經典問題的新研究：利用文本和可讀性特征分類垃圾郵件。</p>

<p>*<a href="https://github.com/alexandrebarachant/bci-challenge-ner-2015">《BCI Challenge @ NER 2015》</a><br/>
介紹:<a href="https://www.kaggle.com/c/inria-bci-challenge">Kaggle腦控計算機交互(BCI)競賽</a>優勝方案源碼及文檔，包括完整的數據處理流程，是學習Python數據處理和Kaggle經典參賽框架的絕佳實例</p>

<p>*<a href="http://www.ipol.im/">《IPOL Journal · Image Processing On Line》</a><br/>
介紹:IPOL（在線圖像處理）是圖像處理和圖像分析的研究期刊，每篇文章都包含一個算法及相應的代碼、Demo和實驗文檔。文本和源碼是經過了同行評審的。IPOL是開放的科學和可重復的研究期刊。我一直想做點類似的工作，拉近產品和技術之間的距離.</p>

<p>*<a href="http://eprint.iacr.org/2014/331">《Machine learning classification over encrypted data》</a><br/>
介紹:出自MIT，研究加密數據高效分類問題.</p>

<p>*<a href="https://github.com/purine/purine2">《purine2》</a><br/>
介紹:新加坡LV實驗室的神經網絡並行框架<a href="http://arxiv.org/abs/1412.6249">Purine: A bi-graph based deep learning framework</a>,支持構建各種並行的架構，在多機多卡，同步更新參數的情況下基本達到線性加速。12塊Titan 20小時可以完成Googlenet的訓練。</p>

<p>*<a href="http://michal.io/machine-learning-resources/">Machine Learning Resources</a><br/>
介紹:這是一個機器學習資源庫,雖然比較少.但蚊子再小也是肉.有突出部分.此外還有一個由<a href="http://zhengrui.github.io/zerryland/ML-CV-Resource.html">zheng Rui整理的機器學習資源</a>.</p>

<p>*<a href="https://github.com/cjdd3b/nicar2015/tree/master/machine-learning">《Hands-on with machine learning》</a><br/>
介紹:Chase Davis在NICAR15上的主題報告材料，用Scikit-Learn做監督學習的入門例子.</p>

<p>*<a href="http://www.cse.unsw.edu.au/%7Ebillw/nlpdict.html">《The Natural Language Processing Dictionary》</a><br/>
介紹:這是一本自然語言處理的詞典,從1998年開始到目前積累了成千上萬的專業詞語解釋,如果你是一位剛入門的朋友.可以借這本詞典讓自己成長更快.</p>

<p>*<a href="http://arxiv.org/abs/1503.01331">《PageRank Approach to Ranking National Football Teams》</a><br/>
介紹:通過分析1930年至今的比賽數據，用PageRank計算世界杯參賽球隊排行榜.</p>

<p>*<a href="http://cyclismo.org/tutorial/R/">《R Tutorial》</a><br/>
介紹:R語言教程,此外還推薦一個R語言教程<a href="http://cran.r-project.org/doc/manuals/R-intro.html">An Introduction to R</a>.</p>

<p>*<a href="http://arxiv.org/abs/0803.0476">《Fast unfolding of communities in large networks》</a><br/>
介紹:經典老文，復雜網絡社區發現的高效算法，Gephi中的<a href="https://github.com/ty4z2008/Qix/blob/master/The%20Louvain%20method%20for%20community%20detection%20in%20large%20networks">Community detection</a>即基於此.</p>

<p>*<a href="http://numl.net/">《NUML》</a><br/>
介紹: 一個面向 .net 的開源機器學習庫,<a href="https://github.com/sethjuarez/numl">Github</a></p>

<p>*<a href="http://synaptic.juancazala.com/">《synaptic.Js》</a><br/>
介紹: 支持node.js的JS神經網絡庫，可在客戶端瀏覽器中運行，支持LSTM等。<a href="https://github.com/cazala/synaptic">Github</a></p>

<p>*<a href="http://tjo-en.hatenablog.com/entry/2015/03/20/191614">《Machine learning for package users with R (1): Decision Tree》</a><br/>
介紹: 決策樹</p>

<p>*<a href="http://www.kdnuggets.com/2015/03/deep-learning-curse-dimensionality-autoencoders.html">《Deep Learning, The Curse of Dimensionality, and Autoencoders》</a><br/>
介紹: 討論深度學習自動編碼器如何有效應對維數災難,<a href="http://www.36dsj.com/archives/26223">中文翻譯</a></p>

<p>*<a href="http://www.cs.cmu.edu/%7Esuvrit/teach/">《Advanced Optimization and Randomized Methods》</a><br/>
介紹: CMU的優化與隨機方法課程，由A. Smola和S. Sra主講，優化理論是機器學習的基石，值得深入學習。<a href="http://pan.baidu.com/s/1c0cZtQC">國內雲(視頻)</a></p>

<p>*<a href="http://cs231n.stanford.edu/reports.html">《CS231n: Convolutional Neural Networks for Visual Recognition》</a><br/>
介紹: &ldquo;面向視覺識別的CNN&#8221;課程設計報告集錦.近百篇，內容涉及圖像識別應用的各個方面</p>

<p>*<a href="http://databricks.com/blog/2015/03/25/topic-modeling-with-lda-mllib-meets-graphx.html">《Topic modeling with LDA: MLlib meets GraphX》</a><br/>
介紹:用Spark的MLlib+GraphX做大規模LDA主題抽取.</p>

<p>*<a href="http://arxiv.org/abs/1502.05988">《Deep Learning for Multi-label Classification》</a><br/>
介紹: 基於深度學習的多標簽分類,用基於RBM的DBN解決多標簽分類(特征)問題</p>

<p>*<a href="http://deepmind.com/publications.html">《Google DeepMind publications》</a><br/>
介紹: DeepMind論文集錦</p>

<p>*<a href="http://kaldi-asr.org/">《kaldi》</a><br/>
介紹: 一個開源語音識別工具包,它目前托管在<a href="http://sourceforge.net/projects/kaldi/">sourceforge</a>上面</p>

<p>*<a href="http://datajournalismhandbook.org/">《Data Journalism Handbook》</a><br/>
介紹: 免費電子書《數據新聞手冊》, 國內有熱心的朋友翻譯了<a href="http://datajournalismhandbook.org/chinese/index.html">中文版</a>,大家也可以<a href="http://datajournalismhandbook.org/1.0/en/">在線閱讀</a></p>

<p>*<a href="https://highlyscalable.wordpress.com/2015/03/10/data-mining-problems-in-retail/">《Data Mining Problems in Retail》</a><br/>
介紹: 零售領域的數據挖掘文章.</p>

<p>*<a href="https://timdettmers.wordpress.com/2015/03/26/convolution-deep-learning/">《Understanding Convolution in Deep Learning》</a><br/>
介紹: 深度學習卷積概念詳解,深入淺出.</p>

<p>*<a href="http://pandas.pydata.org/">《pandas: powerful Python data analysis toolkit》</a><br/>
介紹: 非常強大的Python的數據分析工具包.</p>

<p>*<a href="http://breakthroughanalysis.com/2015/03/23/text-analytics-2015/">《Text Analytics 2015》</a><br/>
介紹: 2015文本分析(商業)應用綜述.</p>

<p>*<a href="http://www.slideshare.net/VincenzoLomonaco/deep-learning-libraries-and-rst-experiments-with-theano">《Deep Learning libraries and ﬁrst experiments with Theano》</a><br/>
介紹: 深度學習框架、庫調研及Theano的初步測試體會報告.</p>

<p>*<a href="http://www.iro.umontreal.ca/%7Ebengioy/dlbook/">《DEEP learning》</a><br/>
介紹: MIT的Yoshua Bengio等人講深度學習的新書，還未定稿，線上提供Draft chapters收集反饋，超贊！強烈推薦.</p>

<p>*<a href="https://github.com/hickeroar/simplebayes">《simplebayes》</a><br/>
介紹: Python下開源可持久化樸素貝葉斯分類庫.</p>

<p>*<a href="http://paracel.io/">《Paracel》</a><br/>
介紹:Paracel is a distributed computational framework designed for machine learning problems, graph algorithms and scientific computing in C++.</p>

<p>*<a href="http://hanlp.linrunsoft.com/">《HanLP:Han Language processing》</a><br/>
介紹: 開源漢語言處理包.</p>

<p>*<a href="http://www.rubylab.io/2015/03/18/simple-neural-network-implenentation-in-ruby/">《Simple Neural Network implementation in Ruby》</a><br/>
介紹: 使用Ruby實現簡單的神經網絡例子.</p>

<p>*[《Hacker&rsquo;s guide to Neural Networks》}(<a href="https://karpathy.github.io/neuralnets/">https://karpathy.github.io/neuralnets/</a>)<br/>
介紹:神經網絡黑客入門.</p>

<p>*<a href="http://datasciencemasters.org/">《The Open-Source Data Science Masters》</a><br/>
介紹:好多數據科學家名人推薦,還有資料.</p>

<p>*<a href="http://arxiv.org/abs/1502.01710">《Text Understanding from Scratch》</a><br/>
介紹:實現項目已經開源在github上面<a href="https://github.com/zhangxiangxiao/Crepe">Crepe</a></p>

<p>*<a href="https://levyomer.files.wordpress.com/2015/03/improving-distributional-similarity-tacl-2015.pdf">《Improving Distributional Similarity with Lessons Learned from Word Embeddings》</a><br/>
介紹:作者發現，經過調參，傳統的方法也能和word2vec取得差不多的效果。另外，無論作者怎麽試，GloVe都比不過word2vec.</p>

<p>*<a href="http://cs224d.stanford.edu/index.html">《CS224d: Deep Learning for Natural Language Processing》</a><br/>
介紹:Stanford深度學習與自然語言處理課程,Richard Socher主講.</p>

<p>*<a href="http://courses.washington.edu/css490/2012.Winter/lecture_slides/02_math_essentials.pdf">《Math Essentials in Machine Learning》</a><br/>
介紹:機器學習中的重要數學概念.</p>

<p>*<a href="http://arxiv.org/abs/1503.00007">《Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks》</a><br/>
介紹:用於改進語義表示的樹型LSTM遞歸神經網絡,句子級相關性判斷和情感分類效果很好.實現代碼.</p>

<p>*<a href="http://www.stat.cmu.edu/%7Elarry/=sml/">《Statistical Machine Learning》</a><br/>
介紹:卡耐基梅隆Ryan Tibshirani和Larry Wasserman開設的機器學習課程，先修課程為機器學習(10-715)和中級統計學(36-705)，聚焦統計理論和方法在機器學習領域應用.</p>

<p>*<a href="http://am207.org/">《AM207: Monte Carlo Methods, Stochastic Optimization》</a><br/>
介紹:《哈佛大學蒙特卡洛方法與隨機優化課程》是哈佛應用數學研究生課程，由V Kaynig-Fittkau、P Protopapas主講，Python程序示例，對貝葉斯推理感興趣的朋友一定要看看，提供<a href="http://nbviewer.ipython.org/github/AM207/2015/tree/master/Lectures/">授課視頻及課上IPN講義</a>.</p>

<p>*<a href="http://spark-summit.org/wp-content/uploads/2015/03/SSE15-40-Danford.pdf">《生物醫學的SPARK大數據應用》</a><br/>
介紹:生物醫學的SPARK大數據應用.並且伯克利開源了他們的big data genomics系統<a href="https://github.com/bigdatagenomics/adam">ADAM</a>，其他的內容可以關註一下<a href="http://spark-summit.org/">官方主頁</a>.</p>

<p>*<a href="http://aclanthology.info/">《ACL Anthology》</a><br/>
介紹:對自然語言處理技術或者機器翻譯技術感興趣的親們，請在提出自己牛逼到無以倫比的idea（自動歸納翻譯規律、自動理解語境、自動識別語義等等）之前，請通過谷歌學術簡單搜一下，如果谷歌不可用，這個網址有這個領域幾大頂會的論文列表,切不可斷章取義,胡亂假設.</p>

<p>*<a href="http://www.uni-weimar.de/medien/webis/publications/papers/stein_2015b.pdf">《Twitter Sentiment Detection via Ensemble Classification Using Averaged Confidence Scores》</a><br/>
介紹:論文+代碼:基於集成方法的Twitter情感分類,<a href="https://github.com/webis-de/ECIR-2015-and-SEMEVAL-2015">實現代碼</a>.</p>

<p>*<a href="http://ciml.chalearn.org/schedule">《NIPS 2014 CIML workshop》</a><br/>
介紹:NIPS CiML 2014的PPT,NIPS是神經信息處理系統進展大會的英文簡稱.</p>

<p>*<a href="http://cs231n.stanford.edu/reports.html">《CS231n: Convolutional Neural Networks for Visual Recognition》</a><br/>
介紹:斯坦福的深度學習課程的Projects 每個人都要寫一個論文級別的報告 裏面有一些很有意思的應用 大家可以看看 .</p>

<p>*<a href="http://www.sumsar.net/blog/2015/03/a-speed-comparison-between-flexible-linear-regression-alternatives-in-r/">《A Speed Comparison Between Flexible Linear Regression Alternatives in R》</a><br/>
介紹:R語言線性回歸多方案速度比較具體方案包括lm()、nls()、glm()、bayesglm()、nls()、mle2()、optim()和Stan’s optimizing()等.</p>

<p>*<a href="http://www.allthingsdistributed.com/2015/04/machine-learning.html">《Back-to-Basics Weekend Reading &ndash; Machine Learning》</a><br/>
介紹:文中提到的三篇論文（機器學習那些事、無監督聚類綜述、監督分類綜述）都很經典，Domnigos的機器學習課也很精彩</p>

<p>*<a href="http://arxiv.org/abs/1504.00641">《A Probabilistic Theory of Deep Learning》</a><br/>
介紹:萊斯大學（Rice University）的深度學習的概率理論.</p>

<p>*<a href="http://www.gregreda.com/2015/03/30/beer-review-markov-chains/">《Nonsensical beer reviews via Markov chains》</a><br/>
介紹:基於馬爾可夫鏈自動生成啤酒評論的開源Twitter機器人, <a href="https://github.com/gjreda/beer-snob-says">Github</a>.</p>

<p>*<a href="http://nlp.stanford.edu/courses/NAACL2013/">《Deep Learning for Natural Language Processing (without Magic)》</a>
介紹:視頻+講義:深度學習用於自然語言處理教程(NAACL13).</p>

<p>*<a href="https://www.youtube.com/watch?v=U4IYsLgNgoY&amp;hd=1">《Introduction to Data Analysis using Machine Learning》</a><br/>
介紹:用機器學習做數據分析,David Taylor最近在McGill University研討會上的報告，還提供了一系列講機器學習方法的ipn，很有價值。<a href="https://github.com/Prooffreader/intro_machine_learning">GitHub</a>。<a href="http://pan.baidu.com/s/1mgtE9te">國內雲盤</a></p>

<p>*<a href="http://arxiv.org/abs/1503.08909">《Beyond Short Snippets: Deep Networks for Video Classification》</a><br/>
介紹:基於CNN+LSTM的視頻分類, <a href="http://pan.baidu.com/s/1c0cZS9E">Google演示</a>.</p>

<p>*<a href="http://www.quora.com/How-does-Quora-use-machine-learning-in-2015/answer/Xavier-Amatriain">《How does Quora use machine learning in 2015?》</a><br/>
介紹:Quora怎麽用機器學習.</p>

<p>*<a href="https://aws.amazon.com/cn/blogs/aws/amazon-machine-learning-make-data-driven-decisions-at-scale/">《Amazon Machine Learning – Make Data-Driven Decisions at Scale》</a><br/>
介紹:亞馬遜在機器學習上面的一些應用,<a href="https://github.com/awslabs/machine-learning-samples">代碼示例</a>.</p>

<p>*<a href="https://github.com/ogrisel/parallel_ml_tutorial">《Parallel Machine Learning with scikit-learn and IPython》</a><br/>
介紹:並行機器學習指南(基於scikit-learn和IPython). <a href="http://nbviewer.ipython.org/github/ogrisel/parallel_ml_tutorial/tree/master/notebooks/">Notebook</a></p>

<p>*<a href="http://blog.kaggle.com/2015/04/08/new-video-series-introduction-to-machine-learning-with-scikit-learn/">《Intro to machine learning with scikit-learn》</a><br/>
介紹:DataSchool的機器學習基本概念教學.</p>

<p>*<a href="https://github.com/hughperkins/DeepCL">《DeepCLn》</a><br/>
介紹:一個基於OpenGL實現的卷積神經網絡，支持Linux及Windows系.</p>

<p>*<a href="https://www.mapr.com/blog/inside-look-at-components-of-recommendation-engine">《An Inside Look at the Components of a Recommendation Engine》</a><br/>
介紹:基於Mahout和Elasticsearch的推薦系統.</p>

<p>*<a href="http://www.ssc.upenn.edu/%7Efdiebold/Teaching221/econ221.html">《Forecasting in Economics, Business, Finance and Beyond》</a><br/>
介紹:Francis X. Diebold的《(經濟|商業|金融等領域)預測方法.</p>

<p>*<a href="http://www.ssc.upenn.edu/%7Efdiebold/Teaching706/econ706Penn.html">《Time Series Econometrics &ndash; A Concise Course》</a><br/>
介紹:Francis X. Diebold的《時序計量經濟學》.</p>

<p>*<a href="http://fotiad.is/blog/sentiment-analysis-comparison/">《A comparison of open source tools for sentiment analysis》</a><br/>
介紹:基於Yelp數據集的開源<a href="https://github.com/sfotiadis/yenlp">情感分析工具</a>比較,評測覆蓋Naive Bayes、SentiWordNet、CoreNLP等 .</p>

<p>*<a href="http://vdisk.weibo.com/s/ayG13we2u_sAZ">《Pattern Recognition And Machine Learning》</a><br/>
介紹:國內Pattern Recognition And Machine Learning讀書會資源匯總,<a href="http://vdisk.weibo.com/u/1841149974">各章pdf講稿</a>,<a href="http://www.cnblogs.com/Nietzsche/">博客</a>.</p>

<p>*<a href="https://highlyscalable.wordpress.com/2012/05/01/probabilistic-structures-web-analytics-data-mining/">《Probabilistic Data Structures for Web Analytics and Data Mining》</a><br/>
介紹:用於Web分析和數據挖掘的概率數據結構.</p>

<p>*<a href="https://blindmotion.github.io/2015/04/11/ml-in-navigation/">《Machine learning in navigation devices: detect maneuvers using accelerometer and gyroscope》</a><br/>
介紹:機器學習在導航上面的應用.</p>

<p>*<a href="https://www.youtube.com/user/Taylorns34/videos">《Neural Networks Demystified》</a><br/>
介紹:Neural Networks Demystified系列視頻，Stephen Welch制作，純手繪風格，淺顯易懂,<a href="http://pan.baidu.com/s/1i3AFURj">國內雲盤</a>.</p>

<p>*<a href="https://www.datacamp.com/swirl-r-tutorial">《swirl + DataCamp》</a><br/>
介紹:{swirl}數據訓練營:R&amp;數據科學在線交互教程.</p>

<p>*<a href="http://blog.terminal.com/recurrent-neural-networks-deep-net-optimization-lstm/">《Learning to Read with Recurrent Neural Networks》</a><br/>
介紹:關於深度學習和RNN的討論<a href="http://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a>.</p>

<p>*<a href="http://wanghaitao8118.blog.163.com/blog/static/13986977220153811210319/">深度強化學習（Deep Reinforcement Learning）的資源</a><br/>
介紹:Deep Reinforcement Learning.</p>

<p>*<a href="https://github.com/jakevdp/sklearn_pycon2015">《Machine Learning with Scikit-Learn》</a><br/>
介紹:(PyCon2015)Scikit-Learn機器學習教程,<a href="https://github.com/ogrisel/parallel_ml_tutorial">Parallel Machine Learning with scikit-learn and IPython</a>.</p>

<p>*<a href="http://www.cs.cmu.edu/%7Eymiao/pdnntk.html">《PDNN》</a><br/>
介紹:PDNN: A Python Toolkit for Deep Learning.</p>

<p>*<a href="http://alex.smola.org/teaching/10-701-15/index.html">《Introduction to Machine Learning》</a><br/>
介紹:15年春季學期CMU的機器學習課程，由Alex Smola主講，提供講義及授課視頻，很不錯.<a href="http://pan.baidu.com/s/1pJxBePX">國內雲盤</a>.</p>

<p>*<a href="http://www.st.ewi.tudelft.nl/%7Ehauff/TI2736-B.html">《Big Data Processing》</a><br/>
介紹:大數據處理課.內容覆蓋流處理、MapReduce、圖算法等.</p>

<p>*<a href="https://www.hakkalabs.co/articles/spark-mllib-making-practical-machine-learning-easy-and-scalable">《Spark MLlib: Making Practical Machine Learning Easy and Scalable》</a><br/>
介紹:用Spark MLlib實現易用可擴展的機器學習,<a href="http://pan.baidu.com/s/1gdxSOZh">國內雲盤</a>.</p>

<p>*<a href="http://mrkulk.github.io/www_cvpr15/">《Picture: A Probabilistic Programming Language for Scene Perception》</a><br/>
介紹:以往上千行代碼概率編程(語言)實現只需50行.</p>

<p>*<a href="http://zevross.com/blog/2014/08/04/beautiful-plotting-in-r-a-ggplot2-cheatsheet-3/">《Beautiful plotting in R: A ggplot2 cheatsheet》</a><br/>
介紹:ggplot2速查小冊子,<a href="http://www.ling.upenn.edu/%7Ejoseff/avml2012/">另外一個</a>,此外還推薦<a href="http://zevross.com/blog/2015/01/13/a-new-data-processing-workflow-for-r-dplyr-magrittr-tidyr-ggplot2/">《A new data processing workflow for R: dplyr, magrittr, tidyr, ggplot2》</a>.</p>

<p>*<a href="http://emnlp2014.org/papers/pdf/EMNLP2014148.pdf">《Using Structured Events to Predict Stock Price Movement: An Empirical Investigation》</a><br/>
介紹:用結構化模型來預測實時股票行情.</p>

<p>*<a href="http://ijcai-15.org/index.php/accepted-papers">《International Joint Conference on Artificial Intelligence Accepted paper》</a><br/>
介紹:<a href="http://ijcai.org/">國際人工智能聯合會議</a>錄取論文列表,大部分論文可使用Google找到.</p>

<p>*<a href="http://petewarden.com/2015/04/20/why-gemm-is-at-the-heart-of-deep-learning/">《Why GEMM is at the heart of deep learning》</a><br/>
介紹:一般矩陣乘法(GEMM)對深度學習的重要性.</p>

<p>*<a href="https://github.com/dmlc">《Distributed (Deep) Machine Learning Common》</a><br/>
介紹:A Community of awesome Distributed Machine Learning C++ projects.</p>

<p>*<a href="http://webdocs.cs.ualberta.ca/%7Esutton/book/the-book.html">《Reinforcement Learning: An Introduction》</a><br/>
介紹:免費電子書&lt;強化學習介紹>,<a href="http://pan.baidu.com/s/1jkaMq">第一版(1998)</a>,<a href="http://pan.baidu.com/s/1dDnNEnR">第二版(2015草稿)</a>,相關課程<a href="http://incompleteideas.net/rlai.cs.ualberta.ca/RLAI/RLAIcourse/2010.html">資料</a>, <a href="http://www.inf.ed.ac.uk/teaching/courses/rl/">Reinforcement Learning</a>.</p>

<p>*<a href="http://blogs.msdn.com/b/microsoft_press/archive/2015/04/15/free-ebook-microsoft-azure-essentials-azure-machine-learning.aspx">《Free ebook: Microsoft Azure Essentials: Azure Machine Learning》</a><br/>
介紹:免費書:Azure ML使用精要.</p>

<p>*<a href="http://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks">《A Deep Learning Tutorial: From Perceptrons to Deep Networks》</a><br/>
介紹:A Deep Learning Tutorial: From Perceptrons to Deep Networks.</p>

<p>*《A Brief Overview of Deep Learning》
介紹:<a href="http://xhrwang.me/2015/01/16/a-brief-overview-of-deep-learning.html">中文版</a>.</p>

<p>*<a href="https://github.com/dmlc/wormhole">《Wormhole》</a><br/>
介紹:Portable, scalable and reliable distributed machine learning.</p>

<p>*<a href="https://github.com/soumith/convnet-benchmarks">《convnet-benchmarks》</a><br/>
介紹:CNN開源實現橫向評測,參評框架包括Caffe 、Torch-7、CuDNN 、cudaconvnet2 、fbfft、Nervana Systems等，NervanaSys表現突出.</p>

<p>*<a href="http://islpc21.is.cs.cmu.edu:3000/lti_catalogue">《This catalogue lists resources developed by faculty and students of the Language Technologies Institute.》</a><br/>
介紹:卡耐基梅隆大學計算機學院語言技術系的資源大全,包括大量的NLP開源軟件工具包，基礎數據集，論文集，數據挖掘教程，機器學習資源.</p>

<p>*<a href="https://github.com/mayank93/Twitter-Sentiment-Analysis">《Sentiment Analysis on Twitter》</a><br/>
介紹:Twitter情感分析工具SentiTweet,<a href="http://pan.baidu.com/s/1i3kXPlj">視頻+講義</a>.</p>

<p>*<a href="http://machinelearning.wustl.edu/mlpapers/venues">《Machine Learning Repository @ Wash U》</a><br/>
介紹:華盛頓大學的Machine Learning Paper Repository.</p>

<p>*<a href="https://github.com/soulmachine/machine-learning-cheat-sheet">《Machine learning cheat sheet》</a><br/>
介紹:機器學習速查表.</p>

<p>*<a href="http://spark-summit.org/east">《Spark summit east 2015 agenda》</a><br/>
介紹:最新的Spark summit會議資料.</p>

<p>*<a href="http://pan.baidu.com/s/1eQkybJG">《Learning Spark》</a><br/>
介紹:Ebook Learning Spark.</p>

<p>*<a href="http://pan.baidu.com/s/1jGot9qe">《Advanced Analytics with Spark, Early Release Edition》</a><br/>
介紹:Ebook Advanced Analytics with Spark, Early Release Edition.</p>

<p>*<a href="http://keg.cs.tsinghua.edu.cn/jietang/">國內機器學習算法及應用領域人物篇:唐傑</a><br/>
介紹:清華大學副教授，是圖挖掘方面的專家。他主持設計和實現的Arnetminer是國內領先的圖挖掘系統，該系統也是多個會議的支持商.</p>

<p>*<a href="http://www.cse.ust.hk/%7Eqyang/">國內機器學習算法及應用領域人物篇:楊強</a><br/>
介紹:遷移學習的國際領軍人物.</p>

<p>*<a href="http://cs.nju.edu.cn/zhouzh/">國內機器學習算法及應用領域人物篇:周誌華</a><br/>
介紹:在半監督學習，multi-label學習和集成學習方面在國際上有一定的影響力.</p>

<p>*<a href="http://ir.hit.edu.cn/%7Ewanghaifeng/whf_pub.htm">國內機器學習算法及應用領域人物篇:王海峰</a><br/>
介紹:信息檢索，自然語言處理，機器翻譯方面的專家.</p>

<p>*<a href="http://www.cs.jhu.edu/%7Ejunwu/">國內機器學習算法及應用領域人物篇:吳軍</a><br/>
介紹:吳軍博士是當前Google中日韓文搜索算法的主要設計者。在Google其間，他領導了許多研發項目，包括許多與中文相關的產品和自然語言處理的項目,他的新個人主頁.</p>

<p>*<a href="http://www.eecs.berkeley.edu/%7Ejunyanz/cat/cat_papers.html">《Cat Paper Collection》</a><br/>
介紹:喵星人相關論文集.</p>

<p>*<a href="http://blog.dato.com/how-to-evaluate-machine-learning-models-part-1-orientation">《How to Evaluate Machine Learning Models, Part 1: Orientation》</a><br/>
介紹:如何評價機器學習模型系列文章, <a href="http://blog.dato.com/how-to-evaluate-machine-learning-models-part-2a-classification-metrics">How to Evaluate Machine Learning Models, Part 2a: Classification Metrics</a>, <a href="http://blog.dato.com/how-to-evaluate-machine-learning-models-part-2b-ranking-and-regression-metrics">How to Evaluate Machine Learning Models, Part 2b: Ranking and Regression Metrics</a>.</p>

<p>*<a href="https://blog.twitter.com/2015/building-a-new-trends-experience">《Building a new trends experience》</a><br/>
介紹:Twitter新trends的基本實現框架.</p>

<p>*<a href="https://www.packtpub.com/big-data-and-business-intelligence/storm-blueprints-patterns-distributed-real-time-computation">《Storm Blueprints: Patterns for Distributed Real-time Computation》</a><br/>
介紹:Storm手冊，<a href="https://github.com/cjie888/storm-trident">中文翻譯</a>.</p>

<p>*<a href="https://github.com/haifengl/smile">《SmileMiner》</a><br/>
介紹:Java機器學習算法庫SmileMiner.</p>

<p>*<a href="http://nlp.csai.tsinghua.edu.cn/%7Ely/talks/cwmt14_tut.pdf">《機器翻譯學術論文寫作方法和技巧》</a><br/>
介紹:機器翻譯學術論文寫作方法和技巧，Simon Peyton Jones的<a href="http://research.microsoft.com/en-us/um/people/simonpj/papers/giving-a-talk/giving-a-talk.htm">How to write a good research paper</a>同類視頻<a href="https://www.youtube.com/watch?v=g3dkRsTqdDA">How to Write a Great Research Paper</a>, <a href="http://vdisk.weibo.com/s/ayG13we2volht">How to paper talk</a>.</p>

<p>*<a href="http://blog.csdn.net/zouxy09/article/details/45288129">《神經網絡訓練中的Tricks之高效BP（反向傳播算法）》</a><br/>
介紹:神經網絡訓練中的Tricks之高效BP,博主的其他博客也挺精彩的.</p>

<p>*<a href="http://www.52cs.org/?p=499">《我和NLP的故事》</a><br/>
介紹:作者是NLP方向的碩士，短短幾年內研究成果頗豐,推薦新入門的朋友閱讀.</p>

<p>*<a href="http://www.cs.ucla.edu/%7Epalsberg/h-number.html">《The h Index for Computer Science 》</a><br/>
介紹:UCLA的Jens Palsberg根據Google Scholar建立了一個計算機領域的H-index牛人列表,我們熟悉的各個領域的大牛絕大多數都在榜上，包括1位諾貝爾獎得主，35位圖靈獎得主，近百位美國工程院/科學院院士，300多位ACM Fellow,在這裏推薦的原因是大家可以在google通過搜索牛人的名字來獲取更多的資源,這份資料很寶貴.</p>

<p>*<a href="http://ttic.uchicago.edu/%7Embansal/papers/acl14_structuredTaxonomy.pdf">《Structured Learning for Taxonomy Induction with Belief Propagation》</a><br/>
介紹:用大型語料庫學習概念的層次關系，如鳥是鸚鵡的上級，鸚鵡是虎皮鸚鵡的上級。創新性在於模型構造，用因子圖刻畫概念之間依存關系，因引入兄弟關系，圖有環，所以用有環擴散（loopy propagation）叠代計算邊際概率（marginal probability）.</p>

<p>*<a href="http://www.stata.com/stata14/bayesian-analysis/">《Bayesian analysis》</a><br/>
介紹: 這是一款貝葉斯分析的商業軟件,官方寫的貝葉斯分析的手冊有250多頁,雖然R語言 已經有類似的項目,但畢竟可以增加一個可選項.</p>

<p><a href="https://github.com/ty4z2008/Qix/blob/master/dl.md">Origin</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Machine Learning is Fun!(FW)]]></title>
    <link href="http://www.aprilzephyr.com/blog/04302015/machine-learning-is-fun/"/>
    <updated>2015-04-30T14:44:26+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/04302015/machine-learning-is-fun</id>
    <content type="html"><![CDATA[<p>在聽到人們談論機器學習的時候，你是不是對它的涵義只有幾個模糊的認識呢？你是不是已經厭倦了在和同事交談時只能一直點頭？讓我們改變一下吧！</p>

<p>本指南的讀者對象是所有對機器學習有求知欲但卻不知道如何開頭的朋友。我猜很多人已經讀過了“機器學習”的<a href="http://en.wikipedia.org/wiki/Machine_learning">維基百科詞條</a>，倍感挫折，以為沒人能給出一個高層次的解釋。本文就是你們想要的東西。</p>

<p>本文目標在於平易近人，這意味著文中有大量的概括。但是誰在乎這些呢？只要能讓讀者對於ML更感興趣，任務也就完成了。<!--more--></p>

<h3>何為機器學習？</h3>

<p>機器學習這個概念認為，對於待解問題，你無需編寫任何專門的程序代碼，遺傳算法（Generic Algorithms）能夠在數據集上為你得出有趣的答案。對於遺傳算法，不用編碼，而是將數據輸入，它將在數據之上建立起它自己的邏輯。</p>

<p>舉個例子，有一類算法稱為分類算法，它可以將數據劃分為不同的組別。一個用來識別手寫數字的分類算法，不用修改一行代碼，就可以用來將電子郵件分為垃圾郵件和普通郵件。算法沒變，但是輸入的訓練數據變了，因此它得出了不同的分類邏輯。<br/>
<img src="http://www.aprilzephyr.com/images/m1.png"></p>

<h6><em>機器學習算法是個黑盒，可以重用來解決很多不同的分類問題。</em></h6>

<p>“機器學習”是一個涵蓋性術語，覆蓋了大量類似的遺傳算法。</p>

<h3>兩類機器學習算法</h3>

<p>你可以認為機器學習算法分為兩大類：<strong>監督式學習（Supervised Learning）</strong>和<strong>非監督式學習（Unsupervised Learning）</strong>。兩者區別很簡單，但卻非常重要。<em>(還有第三種學習方式——增強學習(<a href="https://class.coursera.org/neuralnets-2012-001/lecture">Reinforcement Learning</a>)：學習選擇行為來最大化效益。輸出是一個行為或一系列行為，唯一的監督信號是偶爾的有監督的獎勵，目標是選擇行為最大化未來的獎勵，通常使用一個折現因子，因此不用考慮太遠的未來。增強學習是困難的，因為獎勵是延時的，所以很難確定我們哪一步做對做錯，而且有監督的獎勵只是時而出現，並不提供太多信息，所以不能學習很多參數。&mdash;Themis_Sword注)</em></p>

<h4>監督式學習</h4>

<p>假設你是一名房產經紀，生意越做越大，因此你雇了一批實習生來幫你。但是問題來了——你可以看一眼房子就知道它到底值多少錢，實習生沒有經驗，不知道如何估價。</p>

<p>為了幫助你的實習生（也許是為了解放你自己去度個假），你決定寫個小軟件，可以根據房屋大小、地段以及類似房屋的成交價等因素來評估你所在地區房屋的價值。</p>

<p>你把3個月來城裏每筆房屋交易都寫了下來，每一單你都記錄了一長串的細節——臥室數量、房屋大小、地段等等。但最重要的是，你寫下了最終的成交價：</p>

<h6><em>這是我們的“訓練數據”。</em></h6>

<p><img src="http://www.aprilzephyr.com/images/m2.png"></p>

<p>我們要利用這些訓練數據來編寫一個程序來估算該地區其他房屋的價值：<br/>
<img src="http://www.aprilzephyr.com/images/m3.png"></p>

<p>這就稱為<strong>監督式學習</strong>。你已經知道每一棟房屋的售價，換句話說，你知道問題的答案，並可以反向找出解題的邏輯。</p>

<p>為了編寫軟件，你將包含每一套房產的訓練數據輸入你的機器學習算法。算法嘗試找出應該使用何種運算來得出價格數字。</p>

<p>這就像是算術練習題，算式中的運算符號都被擦去了：<br/>
<img src="http://www.aprilzephyr.com/images/m4.png"></p>

<h6><em>天哪！一個陰險的學生將老師答案上的算術符號全擦去了。</em></h6>

<p>看了這些題，你能明白這些測驗裏面是什麽樣的數學問題嗎？你知道，你應該對算式左邊的數字“做些什麽”以得出算式右邊的答案。</p>

<p>在監督式學習中，你是讓計算機為你算出數字間的關系。而一旦你知道了解決這類特定問題所需要的數學方法後，你就可以解答同類的其它問題了。</p>

<h4>非監督式學習</h4>

<p>讓我們回到開頭那個房地產經紀的例子。要是你不知道每棟房子的售價怎麽辦？即使你所知道的只是房屋的大小、位置等信息，你也可以搞出很酷的花樣。這就是所謂的<strong>非監督式學習</strong>。<br/>
<img src="http://www.aprilzephyr.com/images/m5.png"></p>

<h6><em>即使你不是想去預測未知的數據（如價格），你也可以運用機器學習完成一些有意思的事。</em></h6>

<p>這就有點像有人給你一張紙，上面列出了很多數字，然後對你說:“我不知道這些數字有什麽意義，也許你能從中找出規律或是能將它們分類，或是其它什麽-祝你好運！”</p>

<p>你該怎麽處理這些數據呢？首先，你可以用個算法自動地從數據中劃分出不同的細分市場。也許你會發現大學附近的買房者喜歡戶型小但臥室多的房子，而郊區的買房者偏好三臥室的大戶型。這些信息可以直接幫助你的營銷。</p>

<p>你還可以作件很酷的事，自動找出房價的離群數據，即與其它數據迥異的值。這些鶴立雞群的房產也許是高樓大廈，而你可以將最優秀的推銷員集中在這些地區，因為他們的傭金更高。</p>

<p>本文余下部分我們主要討論監督式學習，但這並不是因為非監督式學習用處不大或是索然無味。實際上，隨著算法改良，不用將數據和正確答案聯系在一起，因此非監督式學習正變得越來越重要。</p>

<h6>老學究請看:還有很多其它種類的機器學習算法。但初學時這樣理解不錯了。</h6>

<h3>太酷了，但是評估房價真能被看作“學習”嗎？</h3>

<p>作為人類的一員，你的大腦可以應付絕大多數情況，並且沒有任何明確指令也能夠學習如何處理這些情況。如果你做房產經紀時間很長，你對於房產的合適定價、它的最佳營銷方式以及哪些客戶會感興趣等等都會有一種本能般的“感覺”。強人工智能（Strong AI）研究的目標就是要能夠用計算機復制這種能力。</p>

<p>但是目前的機器學習算法還沒有那麽好——它們只能專註於非常特定的、有限的問題。也許在這種情況下，“學習”更貼切的定義是“在少量範例數據的基礎上找出一個等式來解決特定的問題”。</p>

<p>不幸的是，“機器在少量範例數據的基礎上找出一個等式來解決特定的問題”這個名字太爛了。所以最後我們用“機器學習”取而代之。</p>

<p>當然，要是你是在50年之後來讀這篇文章，那時我們已經得出了強人工智能算法，而本文看起來就像個老古董。未來的人類，你還是別讀了，叫你的機器仆人給你做份三明治吧。</p>

<h3>讓我們寫代碼吧!</h3>

<p>前面例子中評估房價的程序，你打算怎麽寫呢？往下看之前，先思考一下吧。</p>

<p>如果你對機器學習一無所知，很有可能你會嘗試寫出一些基本規則來評估房價，如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood):
</span><span class='line'>  price = 0
</span><span class='line'> 
</span><span class='line'>  # In my area, the average house costs $200 per sqft
</span><span class='line'>  price_per_sqft = 200
</span><span class='line'> 
</span><span class='line'>  if neighborhood == "hipsterton":
</span><span class='line'>    # but some areas cost a bit more
</span><span class='line'>    price_per_sqft = 400
</span><span class='line'> 
</span><span class='line'>  elif neighborhood == "skid row":
</span><span class='line'>    # and some areas cost less
</span><span class='line'>    price_per_sqft = 100
</span><span class='line'> 
</span><span class='line'>  # start with a base price estimate based on how big the place is
</span><span class='line'>  price = price_per_sqft * sqft
</span><span class='line'> 
</span><span class='line'>  # now adjust our estimate based on the number of bedrooms
</span><span class='line'>  if num_of_bedrooms == 0:
</span><span class='line'>    # Studio apartments are cheap
</span><span class='line'>    price = price — 20000
</span><span class='line'>  else:
</span><span class='line'>    # places with more bedrooms are usually
</span><span class='line'>    # more valuable
</span><span class='line'>    price = price + (num_of_bedrooms * 1000)
</span><span class='line'> 
</span><span class='line'> return price</span></code></pre></td></tr></table></div></figure>


<p>假如你像這樣瞎忙幾個小時，也許會取得一點成效，但是你的程序永不會完美，而且當價格變化時很難維護。</p>

<p>如果能讓計算機找出實現上述函數功能的辦法，這樣豈不更好？只要返回的房價數字正確，誰會在乎函數具體幹了些什麽呢？</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood):
</span><span class='line'>  price = &lt;computer, plz do some math for me&gt;
</span><span class='line'> 
</span><span class='line'>  return price</span></code></pre></td></tr></table></div></figure>


<p>考慮這個問題的一種角度是將房價看做一碗美味的湯，而湯中成分就是臥室數、面積和地段。如果你能算出每種成分對最終的價格有多大影響，也許就能得到各種成分混合起來形成最終價格的具體比例。</p>

<p>這樣可以將你最初的程序（全是瘋狂的if else語句）簡化成類似如下的樣子：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood):
</span><span class='line'> price = 0
</span><span class='line'> 
</span><span class='line'> # a little pinch of this
</span><span class='line'> price += num_of_bedrooms * .841231951398213
</span><span class='line'> 
</span><span class='line'> # and a big pinch of that
</span><span class='line'> price += sqft * 1231.1231231
</span><span class='line'> 
</span><span class='line'> # maybe a handful of this
</span><span class='line'> price += neighborhood * 2.3242341421
</span><span class='line'> 
</span><span class='line'> # and finally, just a little extra salt for good measure
</span><span class='line'> price += 201.23432095
</span><span class='line'> 
</span><span class='line'> return price</span></code></pre></td></tr></table></div></figure>


<p>請註意那些用粗體標註的神奇數字
&mdash;&ndash;<strong>.841231951398213, 1231.1231231,2.3242341421</strong>和<strong>201.23432095</strong>。它們稱為<strong>權重</strong>。如果我們能找出對每棟房子都適用的完美權重，我們的函數就能預測所有的房價！</p>

<p>找出最佳權重的一種笨辦法如下所示：</p>

<h4>步驟1：</h4>

<p>首先，將每個權重都設為1.0：
&#8220;`
def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood):
  price = 0</p>

<p>  # a little pinch of this
  price += num_of_bedrooms * 1.0</p>

<p>  # and a big pinch of that
  price += sqft * 1.0</p>

<p>  # maybe a handful of this
  price += neighborhood * 1.0</p>

<p>  # and finally, just a little extra salt for good measure
  price += 1.0</p>

<p>  return price
 &#8220;`</p>

<h4>步驟2：</h4>

<p>將每棟房產帶入你的函數運算，檢驗估算值與正確價格的偏離程度：<br/>
<img src="http://www.aprilzephyr.com/images/m6.png"></p>

<h6><em>運用你的程序預測房屋價格。</em></h6>

<p>例如：上表中第一套房產實際成交價為25萬美元，你的函數估價為17.8萬，這一套房產你就差了7.2萬。</p>

<p>再將你的數據集中的每套房產估價偏離值平方後求和。假設數據集中有500套房產交易，估價偏離值平方求和總計為86,123,373美元。這就反映了你的函數現在的“正確”程度。</p>

<p>現在，將總計值除以500，得到每套房產的估價偏離平均值。將這個平均誤差值稱為你函數的代價。</p>

<p>如果你能調整權重使得這個代價變為0，你的函數就完美了。它意味著，根據輸入的數據，你的程序對每一筆房產交易的估價都是分毫不差。而這就是我們的目標——嘗試不同的權重值以使代價盡可能的低。</p>

<h4>步驟3：</h4>

<p>不斷重復步驟2，嘗試<strong>所有可能的權重值組合</strong>。哪一個組合使得代價最接近於0，它就是你要使用的，你只要找到了這樣的組合，問題就得到了解決!</p>

<h3>思想擾動時間</h3>

<p>這太簡單了，對吧？想一想剛才你做了些什麽。你取得了一些數據，將它們輸入至三個通用的簡單步驟中，最後你得到了一個可以對你所在區域的房屋進行估價的函數。房價網，要當心咯！
但是下面的事實可能會擾亂你的思想：</p>

<p>1.過去40年來，很多領域（如語言學/翻譯學）的研究表明，這種通用的“攪動數據湯”（我編造的詞）式的學習算法已經勝過了需要利用真人明確規則的方法。機器學習的“笨”辦法最終打敗了人類專家。</p>

<p>2.你最後寫出的函數真是笨，它甚至不知道什麽是“面積”和“臥室數”。它知道的只是攪動，改變數字來得到正確的答案。</p>

<p>3.很可能你都不知道為何一組特殊的權重值能起效。所以你只是寫出了一個你實際上並不理解卻能證明的函數。
4.試想一下，你的程序裏沒有類似“面積”和“臥室數”這樣的參數，而是接受了一組數字。假設每個數字代表了你車頂安裝的攝像頭捕捉的畫面中的一個像素，再將預測的輸出不稱為“價格”而是叫做“方向盤轉動度數”，<strong>這樣你就得到了一個程序可以自動操縱你的汽車了！</strong></p>

<p>太瘋狂了，對吧？</p>

<h3>步驟3中的“嘗試每個數字”怎麽回事？</h3>

<p>好吧，當然你不可能嘗試所有可能的權重值來找到效果最好的組合。那可真要花很長時間，因為要嘗試的數字可能無窮無盡。
為避免這種情況，數學家們找到了很多<a href="http://en.wikipedia.org/wiki/Gradient_descent">聰明的辦法</a>來快速找到優秀的權重值，而不需要嘗試過多。下面是其中一種：
首先，寫出一個簡單的等式表示前述步驟2：</p>

<h6><em>這是你的代價函數。</em></h6>

<p><img src="http://www.aprilzephyr.com/images/m7.png"></p>

<p>接著，讓我們將這同一個等式用機器學習的數學術語（現在你可以忽略它們）進行重寫：</p>

<h6><em>θ表示當前的權重值。 J(θ) 意為“當前權重值對應的代價”。</em></h6>

<p><img src="http://www.aprilzephyr.com/images/m8.png"></p>

<p>這個等式表示我們的估價程序在當前權重值下偏離程度的大小。
如果將所有賦給臥室數和面積的可能權重值以圖形形式顯示，我們會得到類似下圖的圖表：<br/>
<img src="http://www.aprilzephyr.com/images/m9.png"></p>

<h6><em>代價函數的圖形像一支碗。縱軸表示代價。</em></h6>

<p>圖中藍色的最低點就是代價最低的地方——即我們的程序偏離最小。最高點意味著偏離最大。所以，如果我們能找到一組權重值帶領我們到達圖中的最低點，我們就找到了答案！</p>

<p><img src="http://www.aprilzephyr.com/images/m10.png"></p>

<p>因此，我們只需要調整權重值使我們在圖上能向著最低點“走下坡路”。如果對於權重的細小調節能一直使我們保持向最低點移動，那麽最終我們不用嘗試太多權重值就能到達那裏。</p>

<p>如果你還記得一點微積分的話，你也許記得如果你對一個函數求導，結果會告訴你函數在任一點的斜率。換句話說，對於圖上給定一點，它告訴我們那條路是下坡路。我們可以利用這一點朝底部進發。</p>

<p>所以，如果我們對代價函數關於每一個權重求偏導，那麽我們就可以從每一個權重中減去該值。這樣可以讓我們更加接近山底。一直這樣做，最終我們將到達底部，得到權重的最優值。（讀不懂？不用擔心，接著往下讀）。</p>

<p>這種找出最佳權重的辦法被稱為<strong>批量梯度下降</strong>，上面是對它的高度概括。如果想搞懂細節，不要害怕，繼續<a href="https://hbfs.wordpress.com/2012/04/24/introduction-to-gradient-descent/">深入下去</a>吧。</p>

<p>當你使用機器學習算法庫來解決實際問題，所有這些都已經為你準備好了。但明白一些具體細節總是有用的。</p>

<h3>還有什麽你隨便就略過了？</h3>

<p>上面我描述的三步算法被稱為<strong>多元線性回歸</strong>。你估算等式是在求一條能夠擬合所有房價數據點的直線。然後，你再根據房價在你的直線上可能出現的位置用這個等式來估算從未見過的房屋的價格。這個想法威力強大，可以用它來解決“實際”問題。</p>

<p>但是，我為你展示的這種方法可能在簡單的情況下有效，它不會在所有情況下都有用。原因之一是因為房價不會一直那麽簡單地跟隨一條連續直線。</p>

<p>但是，幸運的是，有很多辦法來處理這種情況。對於非線性數據，很多其他類型的機器學習算法可以處理（如神經網絡或有核向量機）。還有很多方法運用線性回歸更靈活，想到了用更復雜的線條來擬合。在所有的情況中，尋找最優權重值這一基本思路依然適用。</p>

<p>還有，我忽略了<strong>過擬合</strong>的概念。很容易碰上這樣一組權重值，它們對於你原始數據集中的房價都能完美預測，但對於原始數據集之外的任何新房屋都預測不準。這種情況的解決之道也有不少（如正則化以及使用交叉驗證數據集）。學會如何處理這一問題對於順利應用機器學習至關重要。</p>

<p>換言之，基本概念非常簡單，要想運用機器學習得到有用的結果還需要一些技巧和經驗。但是，這是每個開發者都能學會的技巧。</p>

<h3>機器學習法力無邊嗎？</h3>

<p>一旦你開始明白機器學習技術很容易應用於解決貌似很困難的問題（如手寫識別），你心中會有一種感覺，只要有足夠的數據，你就能夠用機器學習解決任何問題。只需要將數據輸入進去，就能看到計算機變戲法一樣找出擬合數據的等式。</p>

<p>但是很重要的一點你要記住，機器學習只能對用你占有的數據實際可解的問題才適用。</p>

<p>例如，如果你建立了一個模型來根據每套房屋內盆栽數量來預測房價，它就永遠不會成功。房屋內盆栽數量和房價之間沒有任何的關系。所以，無論它怎麽去嘗試，計算機也推導不出兩者之間的關系。<br/>
<img src="http://www.aprilzephyr.com/images/m11.png"></p>

<h6><em>你只能對實際存在的關系建模。</em></h6>

<h3>怎樣深入學習機器學習</h3>

<p>我認為，當前機器學習的最大問題是它主要活躍於學術界和商業研究組織中。對於圈外想要有個大體了解而不是想成為專家的人們，簡單易懂的學習資料不多。但是這一情況每一天都在改善。</p>

<p>吳恩達教授（Andrew Ng）在Coursera上的<a href="https://www.coursera.org/course/ml">機器學習免費課程</a>非常不錯。我強烈建議由此入門。任何擁有計算機科學學位、還能記住一點點數學的人應該都能理解。</p>

<p>另外，你還可以下載安裝<a href="http://scikit-learn.org/stable/">SciKit-Learn</a>，用它來試驗成千上萬的機器學習算法。它是一個python框架，對於所有的標準算法都有“黑盒”版本。</p>

<ol>
<li><a href="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471">Origin</a></li>
<li><a href="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471">中文翻譯</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[神經網絡(書摘).]]></title>
    <link href="http://www.aprilzephyr.com/blog/04302015/shen-jing-wang-luo-shu-zhai/"/>
    <updated>2015-04-30T11:15:35+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/04302015/shen-jing-wang-luo-shu-zhai</id>
    <content type="html"><![CDATA[<p><img src="http://www.aprilzephyr.com/images/astonishing.jpg"></p>

<p> “……我相信，對一個模型的最好的檢驗是它的設計者能否回答這些問題：‘現在你知道哪些原本不知道的東西？’以及‘你如何證明它是否是對的？’”  ——詹姆斯·鮑爾（<a href="http://en.wikipedia.org/wiki/James_M._Bower">James M.Bower</a>)<!--more--></p>

<p>神經網絡是由具有各種相互聯系的單元組成的集合。每個單元具有極為簡化的神經元的特性。神經網絡常常被用來模擬神經系統中某些部分的行為，生產有用的商業化裝置以及檢驗腦是如何工作的一般理論。</p>

<p>神經科學家們究竟為什麽那麽需要理論呢？如果他們能了解單個神經元的確切行為，他們就有可能預測出具有相互作用的神經元群體的特性。令人遺憾的是，事情並非如此輕而易舉。事實上，單個神經元的行為通常遠不那麽簡單，而且神經元幾乎總是以一種復雜的方式連接在一起。此外，整個系統通常是高度非線性的。線性系統，就其最簡單形式而言，當輸入加倍時，它的輸出也嚴格加倍——即輸出與輸入呈比例關系。①例如，在池塘的表面，當
兩股行進中的小湍流彼此相遇時，它們會彼此穿過而互不幹擾。為了計算兩股小水波聯合產生的效果，人們只需把第一列波與第二列波的效果在空間和時間的每一點上相加即可。這樣，每一列波都獨立於另一列的行為。對於大振幅的波則通常不是這樣。物理定律表明，大振幅情況下均衡性被打破。沖破一列波的過程是高度非線性的：一旦振幅超過某個閾值，波的行為完全以全新的方式出現。那不僅僅是“更多同樣的東西”，而是某些新的特性。非線性行為在日常生活中很普遍，特別是在愛情和戰爭當中。正如歌中的：“吻她一次遠不及吻她兩次的一半那麽美妙。”</p>

<p>如果一個系統是非線性的，從數學上理解它通常比線性系統要困難得多。它的行為可能更為復雜。因此對相互作用的神經元群體進行預測變得十分困難，特別是最終的結果往往與直覺相反。</p>

<p>高速數字計算機是近50年來最重要的技術發展之一。它時常被稱作馮.諾依曼計算機，以紀念這位傑出的科學家、計算機的締造者。由於計算機能像人腦一樣對符號和數字進行操作，人們自然地想像腦是某種形式相當復雜的馮·諾依曼計算機。這種比較，如果陷入極端的話，將導致不切實際的理論。</p>

<p>計算機是構建在固有的高速組件之上的。即便是個人計算機，其基本周期，或稱時鐘頻率，也高於每秒1000萬次操作。相反地，一個神經元的典型發放率僅僅在每秒100個脈沖的範圍內。計算機要快上百萬倍。而像克雷型機那樣的高速超級計算機速度甚至更高。大致說來，計算機的操作是序列式的，即一條操作接著一條操作。與此相反，腦的工作方式則通常是大規模並行的，例如，從每只眼睛到達腦的軸突大約有100萬個，它們全都同時工作。
在系統中這種高度的並行情況幾乎重復出現在每個階段。這種連線方式在某種程度上彌補了神經元行為上的相對緩慢性。它也意味著即使失去少數分散的神經元也不大可能明顯地改變腦的行為。用專業術語講，腦被稱作“故障弱化”（Degrade Gracefully)。而計算機則是脆弱的，哪怕是對它極小的損傷，或是程序中的一個小錯誤，也會引起大的災難。計算機中出現錯誤則是災難性的（Degrade Catastrophically)。</p>

<p>計算機在工作中是高度穩定的。因為其單個組件是很可靠的，當給定相同的輸入時通常產生完全同樣的輸出。反之，單個神經元則具有更多的變化。它們受可以調節其行為的信號所支配，有些特性邊“計算”邊改變。</p>

<p>一個典型的神經元可能具有來自各處的上百乃至數萬個輸入，其軸突又有大量投射。而計算機的一個基本元件——晶體管，則只有極少數的輸入和輸出。</p>

<p>在計算機中，信息被編碼成由0和1組成的脈沖序列。計算機通過這種形式高度精確地將信息從一個特定的地方傳送到另一個地方。信息可以到達特定的地址，提取或者改變那裏所儲存的內容。這樣就能夠將信息存入記憶體的某個特殊位置，並在以後的某些時刻進一步加以利用。這種精確性在腦中是不會出現的。盡管一個神經元沿它的軸突發送的脈沖的模式（而不僅僅是其平均發放率）可能攜帶某些信息，但並不存在精確的由脈沖編碼的信息。①這樣，記憶必然將以不同的形式“存儲”。</p>

<p>腦看起來一點也不像通用計算機。腦的不同部分，甚至是新皮層的不同部分，都是專門用來處理不同類型的信息的（至少在某種程度上是這樣的）。看來大多數記憶存儲在進行當前操作的那個地方。所有這些與傳統的馮·諾依曼計算機完全不同，因為執行計算機的基本操作（如加法.乘法等等）僅在一個或少數幾個地方，而它的記憶卻存貯在許多很不同的地方。</p>

<p>最後，計算機是由工程師精心設計出來的，而腦則是動物經自然選擇一代又一代進化而來的。這就產生了如第一章所述的本質上不同的設計形式。</p>

<p>人們習慣於從硬件和軟件的角度來談論計算機。由於人們編寫軟件（計算機程序）時幾乎不必了解硬件（回路等）的細節，所以人們——特別是心理學家——爭論說沒必要了解有關腦的“硬件”的任何知識。實際上想把這種理論強加到腦的操作過程中是不恰當的，腦的硬件與軟件之間並沒有明顯的差異。對於這種探討的一種合理的解釋是，雖然腦的活動是高度並行的，在所有這些平行操作的頂端有某些形式的（由註意控制的）序列機制，因而，在腦的操作的較高層次，在那些遠離感覺輸入的地方，可以膚淺地說腦與計算機有某種相似之處。</p>

<p>人們可以從一個理論途徑的成果來對它作判斷。計算機按編寫的程序執行，因而擅長解決諸如大規模數字處理、嚴格的邏輯推理以及下棋等某些類型的問題。這些事情大多數人都沒有它們完成得那麽快、那麽好。但是，面對常人能快速、不費氣力就能完成的任務，如觀察物體並理解其意義，即便是最現代的計算機也顯得無能為力。</p>

<p>近幾年在設計新一代的、以更加並行方式工作的計算機方面取得了重要進展。大多數設計使用了許多小型計算機，或是小型計算機的某些部件。它們被連接在一起，並同時運行。由一些相當復雜的設備來處理小計算機之間的信息交換並對計算進行全局控制。像天氣預測等類似問題，其基本要素在多處出現。此時超級計算機特別有用。</p>

<p>人工智能界也采取了行動設計更具有腦的特點的程序。他們用一種模糊邏輯取代通常計算中使用的嚴格的邏輯。命題不再一定是真的或假的，而只需是具有更大或更小的可能性。程序試圖在一組命題中發現具有最大可能性的那種組合，並以之作為結論，而不是那些它認為可能性較小的結論。</p>

<p>在概念的設置上，這種方法確實比早期的人工智能方法與腦更為相像，但在其他方面，特別是在記憶的存貯上，則不那麽像腦。因此，要檢查它與真實的腦在所有層次上行為的相似性可能會有困難。</p>

<p>一群原先很不知名的理論工作者發展了一種更具有腦的特性的方法。如今它被稱為PDP方法（即平行分布式處理）。這個話題有很長的歷史，我只能概述一二。在1943年沃侖·麥卡洛克（Warrenc McCulloch）和沃爾特·皮茲（Walter Pitts）的工作是這方面最早的嘗試之一。他們表明，在原則上由非常簡單的單元連接在一起組成的“網絡”可以對任何邏輯和算術函數進行計算。因為網絡的單元有些像大大簡化的神經元，它現在常被稱作“神經網絡”。</p>

<p>這個成就非常令人鼓舞，以致它使許多人受到誤導，相信腦就是這樣工作的。或許它對現代計算機的設計有所幫助，但它的最引人註目的結論就腦而言則是極端錯誤的。</p>

<p>下一個重要的進展是弗蘭克·羅森布拉特（Frank Rosenblatt）發明的一種非常簡單的單層裝置，他稱之為感知機（Perceptron)。意義在於，雖然它的連接最初是隨機的，它能使用一種簡單而明確的規則改變這些連接，因而可以教會它執行某些簡單的任務，如識別固定位置的印刷字母。感知機的工作方式是，它對任務只有兩種反應：正確或是錯誤。你只需告訴它它所作出的（暫時的）回答是否正確。然後它根據一種感知機學習規則來改變其連接。羅森布拉特證明，對於某一類簡單的問題——“線性可分”的問題——感知機通過有限次訓練就能學會正確的行為。</p>

<p>由於這個結果在數學上很優美，從而吸引了眾人的註目。只可惜它時運不濟，它的影響很快就消退了。馬文·明斯基（MarVinMinsky)和西摩·佩伯特（Segmour Papert)證明感知機的結構及學習規則無法執行“異或問題”（如，判斷這是蘋果還是桔子，但不是二者皆是），因而也不可能學會它。他們寫了一本書，通篇詳述了感知機的局限性。這在許多年內扼殺了人們對感知機的興趣（明斯基後來承認做得過分了）。此問大部分工作將註意力轉向人工智能方法。①</p>

<p>用簡單單元構建一個多層網絡，使之完成簡單的單層網絡所無法完成的異或問題（或類似任務），這是可能的。這種網絡必定具有許多不同層次上的連接，問題在於，對哪些最初是隨機的連接進行修改才能使網絡完成所要求的操作。如果明斯基和佩伯特為這個問題提供了解答，而不是把感知機打入死路的話，他們的貢獻會更大些。</p>

<p>下一個引起廣泛註意的發展來自約翰·霍普菲爾德（John Hop-field)，一位加利福尼亞州理工學院的物理學家，後來成為分子生物學家和腦理論家。1982年他提出了一種網絡，現在被稱為霍普菲爾德網絡(見圖53）。這是一個具有自反饋的簡單網絡。每個單元只能有兩種輸出：一1（表示抑制）或十1（表示興奮）。但每個單元具有多個輸入。每個連接均被指派一個特定的強度。在每個時刻單元把來自它的全部連接的效果(2)總和起來。如果這個總和大於0則置輸出狀態為十1（平均而言，當單元興奮性輸入大於抑制性輸人時，則輸出為正），否則就輸出一1。有些時候這意味著一個單元的輸出會因為來自其他單元的輸入發生了改變而改變。</p>

<p>盡管如此，仍有不少理論工作者默默無聞地繼續工作。這其中包括斯蒂芬.格羅斯伯格（Stephen Grossberg），吉姆·安德森（Jim Anderson），托伊沃.科霍寧（TeuvoKohonen）和戴維·威爾肖（Devid Willshaw）。(2)每個輸入對單元的影響是將當前的輸入信號（+1或-1）與其相應的權值相乘而得到的。（如果當前信號是-1，權重是+2，則影響為-2。）</p>

<p>計算將被一遍遍地反復進行，直到所有單元的輸出都穩定為止。①在霍普菲爾德網絡中，所有單元的狀態並不是同時改變的，而是按隨機次序一個接一個進行，霍普菲爾德從理論上證明了，給定一組權重（連接強度）以及任何輸入，網絡將不會無限制地處於漫遊狀態，也不會進入振蕩，而是迅速達到一個穩態。①</p>

<p>霍普菲爾德的論證令人信服，表達也清晰有力。他的網絡對數學家和物理學家有巨大的吸引力，他們認為終於找到了一種他們可以涉足腦研究的方法（正如我們在加利福尼亞州所說的）。雖然這個網絡在許多細節上嚴重違背生物學，但他們並不對此感到憂慮。</p>

<p>如何調節所有這些連接的強度呢？194年，加拿大心理學家唐納德·赫布（Donald Hebb）出版了《行為的組織》一書。當時人們就像現在一樣普遍相信，在學習過程中，一個關鍵因素是神經元的連接（突觸）強度的調節。赫布意識到，僅僅因為一個突觸是活動的，就增加其強度，這是不夠的。他期望一種只在兩個神經元的活動相關時才起作用的機制。他的書中有一個後來被廣泛引用的段落：“當細胞A的一個軸突和細胞B 很近，足以對它產生影響，並且持久地、不斷地參與了對細胞B 的興奮，那麽在這兩個細胞或其中之一會發生某種生長過程或新陳代謝變化，以致於A作為能使B 興奮的細胞之一，它的影響加強了。”這個機制以及某些類似規則，現在稱為“赫布律”。</p>

<p>霍普菲爾德在他的網絡中使用了一種形式的赫布規則來調節連接權重。對於問題中的一種模式，如果兩個單元具有相同的輸出，則它們之間的相互連接權重都設為+1。如果它們具有相反的輸出，則兩個權重均設為-1。大致他說，每個單元激勵它的“朋友”並試圖削弱它的“敵人”。</p>

<p>霍普菲爾德網絡是如何工作的呢？如果網絡輸入的是正確的單元活動模式，它將停留在該狀態。這並沒有什麽特別的，因為此時給予它的就是答案。值得註意的是，如果僅僅給出模式的一小部分作為“線索”，它在經過短暫的演化後，會穩定在正確的輸出即整個模式上，在不斷地調節各個單元的輸出之後，網絡所揭示的是單元活動的穩定聯系。最終它將有效地從某些僅僅與其存貯的“記憶”接近的東西中恢復出該記憶，此外，這種記憶也被稱作是按“內容尋址”的——即它沒有通常計算機中具有的分離的、唯一用於作為“地址”的信號。輸入模式的任何可察覺的部分都將作為地址。這開始與人的記憶略微有些相似了。</p>

<p>請註意記憶並不必存貯在活動狀態中，它也可以完全是被動的，因為它是鑲嵌在權重的模式之中的即在所有各個單元之間的連接強度之中。網絡可以完全不活動（所有輸出置為0），但只要有信號輸入，網絡突然活動起來並在很短時間內進入與其應當記住的模式相對應的穩定的活動狀態。據推測，人類長期記憶的回憶具有這種一般性質（只是活動模式不能永久保持）。你能記住大量現在一時想不起來的事情。</p>

<p>神經網絡（特別是霍普菲爾德網絡）能“記住”一個模式，但是除此以外它還能再記住第二個模式嗎？如果幾個模式彼此不太相似，一個網絡是能夠全部記住這幾個不同模式，即給出其中一個模式的足夠大的一部分，網絡經過少數幾個周期後將輸出該模式。因為任何一個記憶都是分布在許多連接當中的，所以整個系統中記憶是分布式的。因為任何一個連接都可能包含在多個記憶中，因而記憶是可以疊加的。此外，記憶具有魯棒性，改變少數連接通常不會顯著改變網絡的行為。</p>

<p>為了實現這些特性就需要付出代價，這不足為奇。如果將過多的記憶加到網絡之中則很容易使它陷入混亂。即使給出線索，甚至以完整的模式作為輸入，網絡也會產生毫無意義的輸出。①</p>

<p>有人提出這是我們做夢時出現的現象（弗洛伊德稱之為“凝聚”——Condensation），但這是題外話。值得註意的是，所有這些特性是“自然發生”的。它們並不是網絡設計者精心設置的，而是由單元的本性、它們連接的模式以及權重調節規則所決定的。</p>

<p>霍普菲爾德網絡還有另一個性質，即當幾個輸人事實上彼此大致相似時，在適當計算網絡的連接權重後，它“記住”的將是訓練的模式的某種平均。這是另一個與腦有些類似的性質。對我們人類而言，當我們聽某個特定的聲調時，即便它在一定範圍內發生變化，我們也會覺得它是一樣的。輸入是相似但不同的，而輸出——我們所聽到的——則是一樣的。</p>

<p>這些簡單網絡是不能和腦的復雜性相提並論的，但這種簡化確實使我們可能對它們的行為有所了解，即使是簡單網絡中出現的特點也可能出現在具有相同普遍特性的更復雜的網絡中，此外，它們向我們提供了多種觀點，表明特定的腦回路所可能具有的功能。例如，海馬中有一個稱為CA3的區域，它的連接事實上很像一個按內容尋址的網絡。當然，這是否正確尚需實驗檢驗。</p>

<p>有趣的是，這些簡單的神經網絡具有全息圖的某些特點。在全息圖中，幾個影像可以彼此重疊地存貯在一起；全息圖的任何一部分都能用來恢復整個圖像，只不過清晰度會下降；全息圖對於小的缺陷是魯棒的。對腦和全息圖兩者均知之甚少的人經常會熱情地支持這種類比。幾乎可以肯定這種比較是沒有價值的。原因有兩個。詳細的數學分析表明神經網絡和全息圖在數學上是不同的。更重要的是，雖然神經網絡是由那些與真實神經元有些相似的單元
構建的，沒有證據表明腦中具有全息圖所需的裝置或處理過程。（1）</p>

<p>一本更新的書產生了巨大的沖擊力，這就是戴維·魯梅爾哈特（David Rumelhart）、詹姆斯·麥克萊蘭（James McClelland）和PDP小組所編的一套很厚的兩卷著作《平行分布式處理》（1)。該書於1986年問世，並很快至少在學術界成為最暢銷書。名義上我也是PDP小組的成員，並和淺沼智行（Chiko Asanuma）合寫了其中的一個章節。不過我起的作用很小。我幾乎只有一個貢獻，就是堅持要求他們停止使用神經元一詞作為他們網絡的單元。</p>

<p>加利福尼亞州立大學聖叠戈分校心理系離索爾克研究所僅有大約一英裏。在70年代末80年代初我經常步行去參加他們的討論小組舉行的小型非正式會議。那時我時常漫步的地方如今已變成了巨大的停車場。生活的步伐越來越快，我現在已改為驅車飛馳於兩地之間了。</p>

<p>研究小組當時是由魯梅爾哈特和麥克萊蘭領導的，但是不久麥克萊蘭就離開前往東海岸了。他們倆最初都是心理學家，但他們對符號處理器感到失望並共同研制了處理單詞的“相互作用激勵器”的模型。在克裏斯托夫·朗格特-希金斯（Christopher Longuet-Higgins）的另一位學生傑弗裏·希爾頓（Geoffrey Hinton）的鼓勵下，他們著手研究一個更加雄心勃勃的“聯結主義”方案。他們采納了平行分布式處理這個術語，因為它比以前的術語——聯想記憶②——的覆蓋面更廣。</p>

<p>在人們發明網絡的初期，一些理論家勇敢地開始了嘗試。他們把一些仍顯笨拙的小型電子回路（其中常包括有老式繼電器）連接在一起來模擬他們的非常簡單的網絡。現在已發展出了復雜得多的神經網絡，這得益於現代計算機的運算速度得到了極大的提高，也很便宜。現在可以在計算機（這主要是數字計算機）上模擬檢驗關於網絡的新思想，而不必像早期的研究那樣僅靠粗糙的模擬線路或是用相當困難的數學論證。</p>

<p>1986年出版的《平行分布式處理》一書從1981年底開始經過了很長時間的醞釀。這很幸運，因為它是一個特殊算法的最新發展（或者說是它的復興或應用），在其早期工作基礎上，很快給人留下了深刻的印象。該書的熱情讀者不僅包括腦理論家和心理學家，還有數學家、物理學家和工程師，甚至有人工智能領域的工作者。不過後者最初的反應是相當敵視的。最終神經科學家和分子生物學家也對它的消息有所耳聞。</p>

<p>該書的副標題是“認知微結構的探索”。它是某種大雜燴，但是其中一個的特殊的算法產生了驚人的效果。該算法現在稱作“誤差反傳算法”，通常簡稱為“反傳法”。為了理解這個算法，你需要知道一些關於學習算法的一般性知識。</p>

<p>在神經網絡有些學習形式被稱作是“無教師的”。這意味著沒有外界輸入的指導信息。對任何連接的改變只依賴於網絡內部的局部狀態。簡單的赫布規則具有這種特點。與之相反，在有教師學習中，從外部向網絡提供關於網絡執行狀況的指導信號。</p>

<p>無教師學習具有很誘人的性質，因為從某種意義上說網絡是在自己指導自己。理論家們設計了一種更有效的學習規則，但它需要一位“教師”來告訴網絡它對某些輸入的反應是好、是差還是很糟。這種規則中有一個稱作“δ律”。</p>

<p>訓練一個網絡需要有供訓練用的輸入集合，稱作“訓練集”。很快我們在討論網絡發音器（NETtalk）時將看到一個這樣的例子。這有用的訓練集必須是網絡在訓練後可能遇到的輸入的合適的樣本。通常需要將訓練集的信號多次輸入，因而在網絡學會很好地執行之前需要進行大量的訓練。其部分原因是這種網絡的連接通常是隨機的。而從某種意義上講，腦的初始連接是由遺傳機制控制的，通常不完全是隨機的。</p>

<p>網絡是如何進行訓練的呢？當訓練集的一個信號被輸入到網絡中，網絡就會產生一個輸出。這意味著每個輸出神經元都處在一個特殊的活動狀態。教師則用信號告訴每個輸出神經元它的誤差，即它的狀態與正確之間的差異，δ這個名稱便來源於這個真實活動與要求之間的差異（數學上δ常用來表示小而有限的差異）。網絡的學習規則利用這個信息計算如何調整權重以改進網絡的性能。</p>

<p>Adaline網絡是使用有教師學習的一個較早的例子。它是1960年由伯納德·威德羅（Bernard Widrow）和霍夫（M.E.Hoff）設計的，因此δ律又稱作威德羅-霍夫規則。他們設計規則使得在每一步修正中總誤差總是下降的。①這意味著隨著訓練過程網絡最終會達到一個誤差的極小值。這是毫無疑問的，但還不能確定它是真正的全局極小還是僅僅是個局域極小值。用自然地理的術語說就是，我們達到的是一個火山口中的湖，還是較低的池塘。海洋，還是像死海那樣的凹下去的海（低於海平面的海）？</p>

<p>訓練算法是可以調節的，因而趨近局域極小的步長可大可小。如果步長過大，算法會使網絡在極小值附近跳來跳去（開始時它會沿下坡走，但走得太遠以致又上坡了）。如果步子小，算法就需要極長的時間才能達到極小值的底端。人們也可以使用更精細的調節方案。</p>

<p>反傳算法是有教師學習算法中的一個特殊例子。為了讓它工作，網絡的單元需要具有一些特殊性質。它們的輸出不必是二值的（即，或0，或者＋1或-1），而是分成若幹級。它通常在0到+1之間取值。理論家們盲目地相信這對應於神經元的平均發放率（取最大發放率為＋1），但他們常常說不清應該在什麽時候取這種平均。</p>

<p>如何確定這種“分級”輸出的大小呢？像以前一樣，每個單元對輸入加權求和，但此時不再有一個真實的閾值。如果總和很小，輸出幾乎是0。總和稍大一些時，輸出便增加。當總和很大時，輸出接近於最大值。圖54所示的S形函數（Sigmoid函數）體現了這種輸入總和與輸出間的典型關系。如果將一個真實神經元的平均發放率視為它的輸出，那麽它的行為與此相差不大。</p>

<p>這條看似平滑的曲線有兩個重要性質。它在數學上是“可微的”，即任意一處的斜率都是有限的；反傳算法正依賴於這個特性。更重要的是，這條曲線是非線性的，而真實神經元即是如此。當（內部）輸入加倍時輸出並不總是加倍。這種非線性使得它能處理的問題比嚴格的線性系統更加廣泛。</p>

<p>現在讓我們看一個典型的反傳網絡。它通常具有三個不同的單元層（見圖55）。最底層是輸入層。下一層被稱作“隱單元”層，因為這些單元並不直接與網絡外部的世界連接。最頂層是輸出層。最底層的每個單元都與上一層的所有單元連接。中間層也是如此。網絡只有前向連接，而沒有側向連接，除了訓練以外也沒有反向的投射。它的結構幾乎不能被簡化。</p>

<p>訓練開始的時候，所有的權重都被隨機賦值，因而網絡最初對所有信號的反應是無意義的。此後給定一個訓練輸入，產生輸出並按反傳訓練規則調節權重。過程如下：在網絡對訓練產生輸出以後，告訴高層的每個單元它的輸出與“正確”輸出之間的差。單元利用該信息來對每個從低層單元達到它的突觸的權重進行小的調整。然後它將該信息反傳到隱層的每個單元。每個隱層單元則收集所有高層單元傳未的誤差信息，並以此調節來自最底層的所有突觸。</p>

<p>從整體上看具體的算法使得網絡總是不斷調節以減小誤差。這個過程被多次重復。（該算法是普適的，可以用於多於三層的前向網絡。）</p>

<p>經過了足夠數量的訓練之後網絡就可以使用了。此時有一個輸入的測試集來檢驗網絡。測試集是經過選擇的，它的一般（統計）特性與訓練集相似，但其他方面則不同。（權重在這個階段保持不變，以便考察訓練後網絡的行為。）如果結果不能令人滿意，設計者會從頭開始，修改網絡的結構、輸入和輸出的編碼方式、訓練規則中的參數或是訓練總數。</p>

<p>所有這些看上去顯得很抽象。舉個例子或許能讓讀者清楚一些。特裏·塞吉諾斯基和查爾斯·羅森堡（Charles Rosenberg）在1987年提供了一個著名的演示。他們把他們的網絡稱為網絡發音器（NETtalk）。它的任務是把書寫的英文轉化成英文發音。英文的拼法不規則,這使它成為一門發音特別困難的語言，因而這個任務並不那麽簡單易行。當然，事先並不把英語的發音規則清楚地告訴網絡。在訓練過程中，網絡每次嘗試後將得到修正信號，網絡則從中學習。輸入是通過一種特殊的方式一個字母接一個字母地傳到網絡中。NETtalk的全部輸出是與口頭發音相對應的一串符號，為了讓演示更生動，網絡的輸出與一個獨立的以前就有的機器（一種數字發音合成器）耦合。它能將NETtallk的輸出變為發音，這樣就可以聽到機器“朗讀”英語了。</p>

<p>由於一個英語字母的發音在很大程度上依賴於它前後的字母搭配，輸入層每次讀入一串7個字母。①輸出層中的單元與音素所要求的21個發音特征②相對應，還有5個單元處理音節分界和重音。圖56給出了它的一般結構。③</p>

<p>他們使用了兩段文字的摘錄來訓練網絡，每段文字都附有訓練機器所需的標音法。第一段文字摘自梅裏亞姆-韋伯斯特袖珍詞典。第二段摘錄則多少有些令人奇怪，是一個小孩的連續說話。初始權重具有小的隨機值，並在訓練期內每處理一個詞更新一次。他們編寫程序使得計算機能根據提供的輸入和（正確的）輸出信息自動地完成這一步。在對真實的輸出進行判斷時，程序會采納一個與真實發音最接近的音素作為最佳猜測，通常有好幾個“發音”輸出單元對此有關系。</p>

<p>聆聽機器學著“讀”英語是一件令人著迷的事情。①最初，由於初始連接是隨機的，只能聽到一串令人困惑的聲音。NETtalk很快就學會了區分元音和輔音。但開始時它只知道一個元音和一個輔音，因此像在咿呀學語。後來它能識別詞的邊界，並能發出像詞那樣的一串聲音。在對訓練集進行了大約十次操作之後，單詞變得清楚，讀的聲音也和幼兒說話很像了。</p>

<p>實際結果並不完美，在某種情況下英語發音依賴於詞意，而NETtalk對此一無所知。一些相似的發音通常引起混淆，如論文（Thesis)和投擲（Throw）的“th”音。把同一個小孩的另一段例文作為檢測，機器完成得很好，表明它能把從相當小的訓練集（1024個單詞）中學到的推廣到它從未遇到的新詞上。②這稱為“泛化”。</p>

<p>顯然網絡不僅僅是它所訓練過的每一個單詞的查詢表。它的泛化能力取決於英語發音的冗余度。並不是每一個英語單詞都按自己唯一的方式發音，雖然首次接觸英語的外國人容易這樣想。（這個問題是由於英語具有兩個起源造成的，即拉丁語系和日爾曼語系，這使得英語的詞匯十分豐富。）</p>

<p>相對於大多數從真實神經元上收集的資料而言，神經網絡的一個優點在於在訓練後很容易檢查它的每一個隱單元的感受野。一個字母僅會激發少數幾個隱單元，還是像全息圖那樣它的活動在許多隱單元中傳播呢？答案更接近於前者。雖然在每個字母一發音對應中並沒有特殊的隱單元，但是每個這種對應並不傳播到所有的隱單元。</p>

<p>因此便有可能檢查隱單元的行為如何成簇的（即具有相同的特性）。塞吉諾斯基和羅森堡發現“……最重要的區別是元音與輔音完全分離，然而在這兩類之中隱單元簇具有不同的模式，對於元音而言，下一個重要的變量是字母，而輔音成簇則按照了一種混合的策略，更多地依賴於它們聲音的相似性。”</p>

<p>這種相當雜亂的布置在神經網絡中是典型現象，其重要性在於它與許多真實皮層神經元（如視覺系統中的神經元）的反應驚人地相似，而與工程師強加給系統的那種巧妙的設計截然不同。</p>

<p>他們的結論是：
NETtalk是一個演示，是學習的許多方面的縮影。首先，網絡在開始時具有一些合理的“先天”的知識，體現為由實驗者選擇的輸入輸出的表達形式，但沒有關於英語的特別知識——網絡可以對任何具有相同的字母和音素集的語言進行訓練。其次，網絡通過學習獲得了它的能力，其間經歷了幾個不同的訓練階段，並達到了一種顯著的水平。最後，信息分布在網絡之中，因而沒有一個單元或連接是必不可少的，作為結果，網絡具有容錯能力，對增長的損害是故障弱化的。此外，網絡從損傷中恢復的速度比重新學習要快得多。</p>

<p>盡管這些與人類的學習和記憶很相似，但NETtalk過於簡單，還不能作為人類獲得閱讀能力的一個好的模型。網絡試圖用一個階段完成人類發育中兩個階段出現的過程，即首先是兒童學會說話；只有在單詞及其含義的表達已經建立好以後，他們才學習閱讀。同時，我們不僅具有使用字母-發音對應的能力，似乎還能達到整個單詞的發音表達，但在網絡中並沒有單詞水平的表達。註意到網絡上並沒有什麽地方清楚地表達英語的發音規則，這與標準的
計算機程序不同。它們內在地鑲嵌在習得的權重模式當中。這正是小孩學習語言的方式。它能正確他說話，但對它的腦所默認的規則一無所知。①</p>

<p>NETtalk有幾條特性是與生物學大為抵觸的。網絡的單元違背了一條規律，即一個神經元只能產生興奮性或抑制性輸出，而不會二者皆有。更為嚴重的是，照字面上說，反傳算法要求教師信息快速地沿傳遞向前的操作信息的同一個突觸發送回去。這在腦中是完全不可能發生的。試驗中用了獨立的回路來完成這一步，但對我而言它們顯得過於勉強，並不符合生物原型。</p>

<p>盡管有這些局限性，NETtalk展示了一個相對簡單的神經網絡所能完成的功能，給人印象非常深刻。別忘了那裏只有不足500個神經元和2萬個連接。如果包括（在前面的腳註中列出的）某些限制和忽略，這個數目將會大一些，但恐怕不會大10倍。而在每一側新皮層邊長大約四分之一毫米的一小塊表面（比針尖還小）有大約5000個神經元。因而與腦相比，NETtalk僅是極小的一部分。②所以它能學會這樣相對復雜的任務給人印象格外深刻。</p>

<p>另一個神經網絡是由西德尼·萊基（Sidney Lehky）和特裏·塞吉諾斯基設計的。他們的網絡所要解決的問題是在不知道光源方向的情況下試圖從某些物體的陰影中推斷出其三維形狀（第四章　描述的所謂從陰影到形狀問題）。對隱層單元的感受野進行檢查時發現了令人吃驚的結果。其中一些感受野與實驗中在腦視覺第一區（V1區）發現的一些神經元非常相似。它們總是成為邊緣檢測器或棒檢測器，但在訓練過程中，並未向網絡呈現過邊或棒，設計者也未強行規定感受野的形狀。它們的出現是訓練的結果。此外，當用一根棒來測試網絡時，其輸出層單元的反應類似於V1區具有端點抑制（End-stopping）的復雜細胞。</p>

<p>網絡和反傳算法二者都在多處與生物學違背，但這個例子提出了這樣一個回想起來應該很明顯的問題：僅僅從觀察腦中一個神經元的感受野並不能推斷出它的功能，正如第十一章描述的那樣，了解它的投射野，即它將軸突傳向哪些神經元，也同樣重要。</p>

<p>我們已經關註了神經網絡中“學習”的兩種極端情況：由赫布規則說明的無教師學習和反傳算法那樣的有教師學習。此外還有若幹種常見的類型。一種同樣重要的類型是“競爭學習”。①其基本思想是網絡操作中存在一種勝者為王機制，使得能夠最好地表達了輸入的含義的那個單元（或更實際他說是少數單元）抑制了其他所有單元。學習過程中，每一步中只修正與勝者密切相關的那些連接，而不是系統的全部連接。這通常用一個三層網絡進行模擬，如同標準的反傳網絡，但又有顯著差異，即它的中間層單元之間具有強的相互連接。這些連接的強度通常是固定的，並不改變。通常短程連接是興奮性的，而長程的則是抑制性的，一個單元傾向於與其近鄰友好而與遠處的相對抗。這種設置意味著中間層的神經元為整個網絡的活動而競爭。在一個精心設計的網絡中，在任何一次試驗中通常只有一個勝者。</p>

<p>這種網絡並沒有外部教師。網絡自己尋找最佳反應。這種學習算法使得只有勝者及其近鄰單元調節輸入權重。這種方式使得當前的那種特殊反應在將來出現可能性更大。由於學習算法自動將權重推向所要求的方向，每個隱單元將學會與一種特定種類的輸入相聯系。①</p>

<p>到此為止我們考慮的網絡處理的是靜態的輸入，並在一個時間間隔後產生一個靜態的輸出。很顯然在腦中有一些操作能表達一個時間序列，如口哨吹出一段曲調或理解一種語言並用之交談。人們初步設計了一些網絡來著手解決這個問題，但目前尚不深入。（NETtalk確實產生了一個時間序列，但這只是數據傳入和傳出網絡的一種方法，而不是它的一種特性。）</p>

<p>語言學家曾經強調，目前在語言處理方面（如句法規則）根據人工智能理論編寫的程序處理更為有效。其本質原因是網絡擅長於高度並行的處理，而這種語言學任務要求一定程度的序列式處理。腦中具有註意系統，它具有某種序列式的本性，對低層的並行處理進行操作，迄今為止神經網絡並未達到要求的這種序列處理的復雜程度，雖然它應當出現。</p>

<p>真實神經元（其軸突、突觸和樹突）都存在不可避免的時間延遲和處理過程中的不斷變化。神經網絡的大多數設計者認為這些特性很討厭，因而回避它們。這種態度也許是錯的。幾乎可以肯定進化就建立在這些改變和時間延遲上，並從中獲益。</p>

<p>對這些神經網絡的一種可能的批評是，由於它們使用這樣一種大體上說不真實的學習算法，事實上它們並不能揭示很多關於腦的情況。對此有兩種答案。一種是嘗試在生物學看來更容易接受的算法，另一種方法更有效且更具有普遍性。加利福尼亞州立大學聖叠戈分校的戴維·齊帕澤（David Zipser），一個由分子生物學家轉為神經理論學家，曾經指出，對於鑒別研究中的系統的本質而言，反傳算法是非常好的方法。他稱之為“神經系統的身份證明”。他的觀點是，如果一個網絡的結構至少近似於真實物體，並了解了系統足夠多的限制，那麽反傳算法作為一種最小化誤差的方法，通常能達到一個一般性質相似於真實生物系統的解。這樣便在朝著了解生物系統行為的正確方向上邁出了第一步。</p>

<p>如果神經元及其連接的結構還算逼真，並已有足夠的限制被加入到系統中，那麽產生的模型可能是有用的，它與現實情況足夠相似。這樣便允許仔細地研究模型各組成部分的行為。與在動物上做相同的實驗相比，這更加快速也更徹底。</p>

<p>我們必須明白科學目標並非到此為止，這很重要。例如，模型可能會顯示，在該模型中某一類突觸需要按反傳法確定的某種方式改變。但在真實系統中反傳法並不出現。因此模擬者必須為這一類突觸找到合適的真實的學習規則。例如，那些特定的突觸或許只需要某一種形式的赫布規則。這些現實性的學習規則可能是局部的，在模型的各個部分不盡相同。如果需要的話，可能會引入一些全局信號，然後必須重新運行該模型。</p>

<p>如果模型仍能工作，那麽實驗者必須表明這種學習方式確實在預測的地方出現，並揭示這種學習所包含的細胞和分子機制以支持這個觀點。只有如此我們才能從這些“有趣”的演示上升為真正科學的有說服力的結果。</p>

<p>所有這些意味著需要對大量的模型及其變體進行測試。幸運的是，隨著極高速而又廉價的計算機的發展，現在可以對許多模型進行模擬。這樣人們就可以檢測某種設置的實際行為是否與原先所希望的相同，但即便使用最先進的計算機也很難檢驗那些人們所希望的巨大而復雜的模型。</p>

<p>“堅持要求所有的模型應當經過模擬檢驗，這令人遺憾地帶來了兩個副產品。如果一個的假設模型的行為相當成功，其設計者很難相信它是不正確的。然而經驗告訴我們，若幹差異很大的模型也會產生相同的行為。為了證明這些模型哪個更接近於事實，看來還需要其他證據，諸如真實神經元及腦中該部分的分子的準確特性。</p>

<p>另一種危害是，對成功的模型過分強調會抑制對問題的更為自由的想像，從而會阻礙理論的產生。自然界是以一種特殊的方式運行的。對問題過於狹隘的討論會使人們由於某種特殊的困難而放棄極有價值的想法。但是進化或許使用了某些額外的小花招來回避這些困難。盡管有這些保留，模擬一個理論，即便僅僅為了體會一下它事實上如何工作，也是有用的。</p>

<p>我們對神經網絡能總結出些什麽呢？它們的基礎設計更像腦，而不是標準計算機的結構，然而，它們的單元並沒有真實神經元那樣復雜，大多數網絡的結構與新皮層的回路相比也過於簡單。目前，如果一個網絡要在普通計算機上在合理的時間內進行模擬，它的規模只能很小。隨著計算機變得越來越快，以及像網絡那樣高度並行的計算機的生產商業化，這會有所改善，但仍將一直是嚴重的障礙。</p>

<p>盡管神經網絡有這些局限性，它現在仍然顯示出了驚人的完成任務的能力。整個領域內充滿了新觀點。雖然其中許多網絡會被人們遺忘，但通過了解它們，抓住其局限性並設計改進它們的新方法，肯定會有堅實的發展。這些網絡有可能具有重要的商業應用。盡管有時它會導致理論家遠離生物事實，但最終會產生有用的觀點和發明。也許所有這些神經網絡方面的工作的最重要的結果是它提出了關於腦可能的工作方式的新觀點。</p>

<p>在過去，腦的許多方面看上去是完全不可理解的。得益於所有這些新的觀念，人們現在至少瞥見了將來按生物現實設計腦模型的可能性，而不是用一些毫無生物依據的模型僅僅去捕捉腦行為的某些有限方面。即便現在這些新觀念已經使我們對實驗的討論更為敏銳，我們現在更多地了解了關於個體神經元所必須掌握的知識。我們可以指出回路的哪些方面我們尚不足夠了解（如新皮層的向回的通路），我們從新的角度看待單個神經元的行為，並意識到在實驗日程上下一個重要的任務是它們整個群體的行為。神經網絡還有很長的路要走，但它們終於有了好的開端。<br/>
  ======================<br/>
①查爾斯·安德森（Charles Anderson）和戴維·範·埃森提出腦中有些裝置將信息按規定路線從一處傳至另一處。不過這個觀點尚有爭議。<br/>
①該網絡以一個早期網絡為基礎。那個網絡被稱為“自旋玻璃”，是物理學家受一種理論概念的啟發而提出的。<br/>
①這對應於一個適定的數學函數（稱為“能量函數”，來自自旋玻璃）的（局域）極小值。霍普菲爾德還給出了一個確定權重的簡單規則以使網絡的每個特定的活動模式對應於能量函數的一個極小值。<br/>
①對於霍普菲爾德網絡而言，輸出可視為網絡存貯的記憶中與輸出（似為“輸入”之誤——譯者註）緊密相關的那些記憶的加權和。<br/>
①在1968年，克裏斯托夫·朗格特-希金斯（Christopher Longuet-Higgins）從全息圖出發發明了一種稱為“聲音全息記器”（Holophone）的裝置。此後他又發明了另一種裝置稱為“相關圖”，並最終形成了一種特殊的神經網絡形式。他的學生戴維·威爾肖在完成博士論文期間對其進行了詳細的研究。<br/>
(2)他們和其他一些想法接近的理論家合作，在1981年完成了《聯想記憶的並行模式》，由傑弗裏·希爾頓（Geoffrey Hinton）和吉姆·安德森編著。這本書的讀者主要是神經網絡方面的工作者，它的影響並不像後一本書那樣廣泛。<br/>
(1)PDP即平行分布式處理（Parallel Distributed Processing）的縮寫。<br/>
①更準確他說是誤差的平方的平均值在下降，因此該規則有時又叫做最小均方（LMS）規則。<br/>
①29個“字母”各有一個相應的單元；這包括字母表中的26個字母，還有三個表示標點和邊界。因而輸入層需要29x7=203個單元。<br/>
②例如，因為輔音p和b發音時都是以攏起嘴唇開始的，所以都稱作“唇止音”。<br/>
③中間層（隱層）最初有80個隱單元，後來改為120個，結果能完成得更好。機器總共需要調節大約2萬個突觸。權重可正可負。他們並沒有構造一個真正的平行的網絡來做這件事，而是在一臺中型高速計算機上（一臺VAX 11//780FPA）模擬這個網絡。<br/>
①計算機的工作通常不夠快，不能實時地發音，因而需要先把輸出錄下來，再加速播放，這樣人們才能聽明白。<br/>
②塞吉諾斯基和羅森堡還表明，網絡對於他們設置的連接上的隨機損傷具有相當的抵抗力。在這種環境下它的行為是”故障弱化”。他們還試驗以11個字母（而不是7個字母）為一組輸入。這顯著改善了網絡的成績。加上第二個隱單元層並不能改善它的成績，但有助於網絡更好地進行泛化。<br/>
①除了上面列出的以外，NEttalk還有許多簡化。雖然作者們信奉分布式表達，在輸入輸出均有“祖母細胞”即，例如有一個單元代表“窗口中第三個位置上的字母a”。這樣做是為了降低計算所需要的時間，是一種合理的簡化形式。雖然數據順序傳入7個字母的方式在人工智能程序是完全可以接受的，卻顯得與生物事實相違背。輸出的“勝者為王”這一步並不是由“單元”完成的，也不存在一組單元去表達預計輸出與實際輸出之間的差異（即教師信號）。這些運算都是由程序執行的。<br/>
②這種比較不太公平，因為神經網絡的一個單元更好的考慮是等價於腦中一小群相神經元。因而更合適的數字大約是8萬個神經元（相當於一平方毫米皮層下神經元的數目）。<br/>
①它是由斯蒂芬·格羅斯伯格、托伊沃·科霍寧等人發展的。<br/>
①我不打算討論競爭網絡的局限性。顯然必須有足夠多的隱單元來容納網絡試圖從提供的輸入中所學的所有東西，訓練不能太快，也不能太慢，等等。這種網絡要正確工作需要仔細設計。毫無疑問，不久的將來會發明出基於競爭學習基本思想的更加復雜的應用。</p>

<p><a href="http://en.wikipedia.org/wiki/The_Astonishing_Hypothesis">《驚人的假說&mdash;靈魂的科學探索》Francis Crick 1994&#8217;</a> 湖南科學技術出版社出版</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[I Am a Nerd/Weirdo/Crackpot.]]></title>
    <link href="http://www.aprilzephyr.com/blog/04272015/i-am-a-nerd-slash-weirdo-slash-crackpot/"/>
    <updated>2015-04-27T19:50:26+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/04272015/i-am-a-nerd-slash-weirdo-slash-crackpot</id>
    <content type="html"><![CDATA[<p><img src="http://www.aprilzephyr.com/images/rain.jpg"></p>

<hr />

<p><strong>Nerd</strong><br/>
: a person who behaves awkwardly around other people and usually has unstylish clothes, hair, etc.<br/>
: a person who is very interested in technical subjects, computers, etc.</p>

<p><strong>Weirdo</strong><br/>
: a strange or unusual person</p>

<p><strong>Crackpot</strong><br/>
: a person who is crazy or very strange</p>

<p>&mdash;From <strong><em><a href="http://www.merriam-webster.com">Merriam Webster Dictionary</a></em></strong></p>

<hr />

<!--more-->


<p>I have got no idea about the noun which could exactly describe myself&mdash;in Chinese I mean myself a 奇葩(QiPa).</p>

<p>I am a QiPa cuz I am so languish not to lay down a backup flat sheet after the dirty one&rsquo;s been washed. However, I volunteered to have shower everyday as soon as getting back to my apartment.</p>

<p>I am a QiPa cuz I need washing my hair every morning. However, I could tolerant some tiny dirty spots on my pants or shoes and my those so-casual shirts.</p>

<p>I am a QiPa cuz I am too alone to attend &ldquo;unnecessary&rdquo; social or other activities. However, I am kind of eager to be understood and admitted.</p>

<p>I am a QiPa cuz I am only interested in American Justice related TV series and enough aware of their fictionality. However, I am hooked in such ethereal Justice, human right and happy ends.</p>

<p>I am a QiPa cuz I read a lot including fictional, non-fictional, scientific, technical, even Philosophical and Chinese medical. However, I could not make myself a thing nor be unconventional.</p>

<p>I am a QiPa cuz I try to be abstemious about daily basic necessities. However, I am somewhat squandering money on travelling, books(now I have a kindle), civil aircraft models and have no schedule about buying a house(or somewhere to shelter) even at present.</p>

<p>I am a QiPa cuz I know it&rsquo;s meaningless to be too reasonable with woman so well. However, I keep indulging myself into a dead-end state with the loved in so many specific aspects.</p>

<p>I am a QiPa cuz I give top priority nothing but love. However, I am so likely to be messed up in those trifles.</p>

<p>I am a QiPa cuz I thought I am firm and resolute sufficiently. However, I am thirsting for support and encouragement from the intimates.</p>

<p>I am a QiPa cuz I feel I understand, however, I don&rsquo;t.</p>

<p>Maybe, I am who I am, who is actually, non-existent.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[About Love]]></title>
    <link href="http://www.aprilzephyr.com/blog/04212015/about-love/"/>
    <updated>2015-04-21T15:40:14+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/04212015/about-love</id>
    <content type="html"><![CDATA[<p><img src="http://www.aprilzephyr.com/images/love.jpg"></p>

<p><em>Whenever I get gloomy with the state of the world, I think about the arrival&rsquo;s gate at Heathrow airport. General opinion start to make out that we live in a world of hatred and greed. But I don&rsquo;t see that, seems to me that love is everywhere. Often it&rsquo;s not particularly dignified or newsworthy, but it&rsquo;s always there, fathers and sons, mothers and daughters, husbands and wives, boyfriend, girlfriend, old friends. When the plane hit the Twin Tower, as far as I know, none of the phone calls from people on board were messages of hate or revenge. They are all messages of love. If you look for it, I&rsquo;ve got a sneaky feeling that love actually is all around.</em>   <br/>
<strong>&mdash;&ldquo;Love Actually&rdquo; (Movie, 2003&#8217;)</strong></p>

<!--more-->


<p><em>I have to tell you this and you need to hear it. I&rsquo;ve loved you since I met you&hellip; But I wouldn&rsquo;t allow myself to truly feel it until today. I was always thinking ahead. Making decisions out of fear. Today, because of what I learned from you&hellip; every choice I made was different and my life has completely changed. And I&rsquo;ve learned that if you do that, you&rsquo;re living your life fully. It doesn&rsquo;t matter if you have five minutes or fifty years. Samantha, if not for today, if not for you&hellip; I would never have known love at all. So thank you for being the person who taught me to love, and to be loved.</em>      <br/>
<strong>&mdash;&ldquo;If Only&rdquo; (Movie, 2004&#8217;)</strong></p>

<p><em>The fountains mingle with the river
And the rivers with the Ocean,
The winds of Heaven mix for ever
With a sweet emotion;
Nothing in the world is single;
All things by a law divine
In one spirit meet and mingle,
Why not I with thine?</em></p>

<p><em>See the mountains kiss high Heaven
And the waves clasp one another;
No sister-flower would be forgiven
If it disdained its brother;
And the sunlight clasps the earth
And the moonbeams kiss the sea;
What is all this sweet work worth
If thou kiss not me?</em><br/>
<strong>&mdash;&ldquo;Love&rsquo;s Philosophy&rdquo; (Percy Bysshe Shelley, 1820&#8217;)</strong></p>

<p><em>Let me not to the marriage of true minds
Admit impediments. Love is not love
Which alters when it alteration finds,
Or bends with the remover to remove:
O no; it is an ever-fixed mark,
That looks on tempests, and is never shaken;
It is the star to every wandering bark,
Whose worth&rsquo;s unknown, although his height be taken.
Love&rsquo;s not Time&rsquo;s fool, though rosy lips and cheeks
Within his bending sickle&rsquo;s compass come;
Love alters not with his brief hours and weeks,
But bears it out even to the edge of doom.
If this be error and upon me proved,
I never writ, nor no man ever loved.</em> <br/>
<strong>&mdash;&ldquo;Sonnet 116&rdquo; (Shakespeare, 1609&#8217;)</strong></p>

<p>Love is not a word, it is a state of mind<br/>
Love is beyond a promise, it is a belief<br/>
Love is hope, it is also fortitude<br/>
Love makes a little green, but not so jealous<br/>
Love leads to a colorful dream, which is worth weaving and cherishing<br/>
Love means tolerating, which permits you being real<br/>
Love paints your life, furthermore harbors your soul.<br/>
Love is so hard to achieve, but it trully lasts.<br/>
<strong>&mdash;&ldquo;About Love&rdquo; (Themis_Sword, 2015&#8217;)</strong></p>

<p><strong>I Love Thee! <a href="http://www.weibo.com/leah0204">@leah0204</a></strong></p>

<iframe width="420" height="315" src="https://www.youtube.com/embed/1moWxHdTkT0" frameborder="0" allowfullscreen></iframe>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Eve of Another Birthday]]></title>
    <link href="http://www.aprilzephyr.com/blog/04182015/the-eve-of-another-birthday/"/>
    <updated>2015-04-18T13:48:27+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/04182015/the-eve-of-another-birthday</id>
    <content type="html"><![CDATA[<p><img src="http://www.aprilzephyr.com/images/life.jpg"></p>

<p>I almost forgot how old I am this year.</p>

<p>Thanks my parents for their affectionate SMS this morning wishing me a happy birthday and take-care overseas alone.</p>

<p>Actually, I might be solitary in a way rather than lonely.<!--more--></p>

<p>Retrospecting, It seems like I even don&rsquo;t tolerate continuing the &ldquo;insipid and mundane&rdquo; life traces no matter in which city of China. The gap between the so-called &ldquo;dream&rdquo; and reality keeps on tearing. I am kind of negative for picking that apple always higher despite my leaping and attempting. So I chose to leave(flounder) and chase a new style sitting in a classroom as a postgraduate student, overseas. There would be other choices for sure, nevertheless, I also need some fresh air.</p>

<p>Adaptability would never be an issue for me in the last ten years since my admission to university away from hometown without regarding to geographical position nor language speaking. So I live well for now, or, in other words, I survive well, for not self-sufficient.</p>

<p>I&rsquo;m trying to stay hungary and foolish, so I study and review knowledge almost everyday without any passion of social networkings nor outdoor activities. Meanwhile, the efficiency of learning is not so satisfactory, frankly. The more materials or resources I consult, the more self-ignorant I feel, which is so frustrated. I could recall a professor&rsquo;s words <strong>&ldquo;Time Is the Only Enemy!&rdquo;</strong> on the registration day.</p>

<p>It doesn&rsquo;t mean living in a vacuum while no comparing with others&#8217; gains. Especially I&rsquo;m nothing but a student on the margin of my twenties. I remind myself that actually I am gaining much, in mental.</p>

<p>Thankfully, our transnational love evolves smoothly. As my motivity to move on so fearlessly, she is fabulous. Feeling comforting and cozy with her so much. Weaving our dreams and moreover, we are struggling, inch by inch, towards the brilliant future of ours.</p>

<p>It would be only quite an ordinary day of tomorrow, as for me, I&rsquo;d rather consider it another stair up.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The 20 Most Popular TED Talks of All Time]]></title>
    <link href="http://www.aprilzephyr.com/blog/04032015/the-20-most-popular-ted-talks-of-all-time/"/>
    <updated>2015-04-03T20:00:00+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/04032015/the-20-most-popular-ted-talks-of-all-time</id>
    <content type="html"><![CDATA[<p><img src="http://www.aprilzephyr.com/images/think.jpg"></p>

<p>Nonprofit organization TED launched in 1984 with a mission to present ideas worth sharing.</p>

<p>It has since become a cultural phenomenon, bringing together thought leaders from around the globe to give short, a few minutes talks about ideas that could change the world.</p>

<p>Of the more than 1,800 TED Talks, which have been viewed a total of 2.5 billion times across all platforms, a few have risen to the top. The following 20 talks are the most popular ever on Ted.com.<!--more--></p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/ken_robinson_says_schools_kill_creativity.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>
Sir Ken Robinson makes an entertaining and profoundly moving case for creating an education system that nurtures (rather than undermines) creativity.</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/amy_cuddy_your_body_language_shapes_who_you_are.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>Body language affects how others see us, but it may also change how we see ourselves. Social psychologist Amy Cuddy shows how “power posing” — standing in a posture of confidence, even when we don’t feel confident — can affect testosterone and cortisol levels in the brain, and might even have an impact on our chances for success.</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/simon_sinek_how_great_leaders_inspire_action.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>Simon Sinek has a simple but powerful model for inspirational leadership all starting with a golden circle and the question &ldquo;Why?&rdquo; His examples include Apple, Martin Luther King, and the Wright brothers &hellip; (Filmed at TEDxPugetSound.)</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/brene_brown_on_vulnerability.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>Brené Brown studies human connection — our ability to empathize, belong, love. In a poignant, funny talk, she shares a deep insight from her research, one that sent her on a personal quest to know herself as well as to understand humanity. A talk to share.</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/jill_bolte_taylor_s_powerful_stroke_of_insight.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>Jill Bolte Taylor got a research opportunity few brain scientists would wish for: She had a massive stroke, and watched as her brain functions — motion, speech, self-awareness — shut down one by one. An astonishing story.</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/pranav_mistry_the_thrilling_potential_of_sixthsense_technology.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>At TEDIndia, Pranav Mistry demos several tools that help the physical world interact with the world of data — including a deep look at his SixthSense device and a new, paradigm-shifting paper &ldquo;laptop.&rdquo; In an onstage Q&amp;A, Mistry says he&rsquo;ll open-source the software behind SixthSense, to open its possibilities to all.</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/mary_roach_10_things_you_didn_t_know_about_orgasm.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>&ldquo;Bonk&rdquo; author Mary Roach delves into obscure scientific research, some of it centuries old, to make 10 surprising claims about sexual climax, ranging from the bizarre to the hilarious. (This talk is aimed at adults. Viewer discretion advised.)</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/tony_robbins_asks_why_we_do_what_we_do.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>Tony Robbins discusses the &ldquo;invisible forces&rdquo; that motivate everyone&rsquo;s actions — and high-fives Al Gore in the front row.</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/dan_pink_on_motivation.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>Career analyst Dan Pink examines the puzzle of motivation, starting with a fact that social scientists know but most managers don&rsquo;t: Traditional rewards aren&rsquo;t always as effective as we think. Listen for illuminating stories — and maybe, a way forward.</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/david_gallo_shows_underwater_astonishments.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>David Gallo shows jaw-dropping footage of amazing sea creatures, including a color-shifting cuttlefish, a perfectly camouflaged octopus, and a Times Square&rsquo;s worth of neon light displays from fish who live in the blackest depths of the ocean. This short talk celebrates the pioneering work of ocean explorers like Edith Widder and Roger Hanlon.</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/dan_gilbert_asks_why_are_we_happy.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>Dan Gilbert, author of &ldquo;Stumbling on Happiness,&rdquo; challenges the idea that we’ll be miserable if we don’t get what we want. Our &ldquo;psychological immune system&rdquo; lets us feel truly happy even when things don’t go as planned.</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/susan_cain_the_power_of_introverts.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>In a culture where being social and outgoing are prized above all else, it can be difficult, even shameful, to be an introvert. But, as Susan Cain argues in this passionate talk, introverts bring extraordinary talents and abilities to the world, and should be encouraged and celebrated.</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/pattie_maes_demos_the_sixth_sense.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>This demo — from Pattie Maes&#8217; lab at MIT, spearheaded by Pranav Mistry — was the buzz of TED. It&rsquo;s a wearable device with a projector that paves the way for profound interaction with our environment. Imagine &ldquo;Minority Report&rdquo; and then some.</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/elizabeth_gilbert_on_genius.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>Elizabeth Gilbert muses on the impossible things we expect from artists and geniuses — and shares the radical idea that, instead of the rare person &ldquo;being&rdquo; a genius, all of us &ldquo;have&rdquo; a genius. It&rsquo;s a funny, personal and surprisingly moving talk.</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/hans_rosling_shows_the_best_stats_you_ve_ever_seen.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>You&rsquo;ve never seen data presented like this. With the drama and urgency of a sportscaster, statistics guru Hans Rosling debunks myths about the so-called &ldquo;developing world.&rdquo;</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/pamela_meyer_how_to_spot_a_liar.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>On any given day we&rsquo;re lied to from 10 to 200 times, and the clues to detect those lie can be subtle and counter-intuitive. Pamela Meyer, author of Liespotting, shows the manners and &ldquo;hotspots&rdquo; used by those trained to recognize deception — and she argues honesty is a value worth preserving.</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/shawn_achor_the_happy_secret_to_better_work.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>We believe that we should work to be happy, but could that be backwards? In this fast-moving and entertaining talk, psychologist Shawn Achor argues that actually happiness inspires productivity. (Filmed at TEDxBloomington.)</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/david_blaine_how_i_held_my_breath_for_17_min.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>In this highly personal talk from TEDMED, magician and stuntman David Blaine describes what it took to hold his breath underwater for 17 minutes — a world record (only two minutes shorter than this entire talk!) — and what his often death-defying work means to him. Warning: do NOT try this at home.</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/keith_barry_does_brain_magic.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>First, Keith Barry shows us how our brains can fool our bodies — in a trick that works via podcast too. Then he involves the audience in some jaw-dropping (and even a bit dangerous) feats of brain magic.</p>

<iframe src="https://embed-ssl.ted.com/talks/lang/en/cameron_russell_looks_aren_t_everything_believe_me_i_m_a_model.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>Cameron Russell admits she won “a genetic lottery”: she&rsquo;s tall, pretty and an underwear model. But don&rsquo;t judge her by her looks. In this fearless talk, she takes a wry look at the industry that had her looking highly seductive at barely 16 years old.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[...]]></title>
    <link href="http://www.aprilzephyr.com/blog/12012014/dot-dot-dot/"/>
    <updated>2014-12-01T16:37:15+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/12012014/dot-dot-dot</id>
    <content type="html"><![CDATA[<p><img src="http://www.aprilzephyr.com/images/adventure.jpg"></p>

<p>今天，2014年最後一個月的第一天，是該收拾下情緒了。</p>

<p>2014年，普通的不能再普通的一年，卻夾雜了太多的變化，這些變化，甚至改變了未來的方向。<!--more--></p>

<p>去年的辭職空檔期甚至延續到了今年的前五個月，超過整整七個月的空檔期，要算焦灼，還是焦慮，此刻的自己都回憶不起來那時，到底是什麼樣的心境。</p>

<p>還好，工作只是糊口的家什，事業才是值得追求和爭取的。</p>

<p>於是，工作，辭職，又工作。</p>

<p>直到現在，依然還算是沒有脫離“工作”的羈絆吧。</p>

<p>苦盡甘來？或許之前也不算苦，即使大半年像個游魂。</p>

<p>結識了True Friends，也遇到了她。</p>

<p>更安心了，就像久枯之地突然流過潺潺溪水；就靜靜的，靜靜的，直到心裏。如果硬要說有什麼不安，可能，是擔心自己不夠出色，不夠優秀，讓她委屈。</p>

<p>也收到了大學的offer，即將在新年啟程，去另一個國家，開始求學之旅，開始另一種人生。</p>

<p>自己很幸運，很幸運，不然，不會同時擁有，擁有一個愛人，擁有一份美好的未來。</p>

<p>此刻，耳機裏正好傳來最喜歡的那首“Forever in Love”。</p>

<p>感恩節剛過，如果說把“感恩”說出來，一遍兩遍三遍，未免太矯情。如此，心裏知道，便好。不求其他的，只求無愧、無悔。</p>

<p>還好，掙扎了這麼多年，還沒放棄。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pieces]]></title>
    <link href="http://www.aprilzephyr.com/blog/08302014/pieces/"/>
    <updated>2014-08-30T22:15:03+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/08302014/pieces</id>
    <content type="html"><![CDATA[<p><img src="http://www.aprilzephyr.com/images/owlcoffee.jpg"></p>

<p>A friend said I am a traditional person intrinsically somehow with an attempt to break the invisible shackles, the boundary of the traditional and the nontraditional. I know it&rsquo;s true for I am raised and influenced since my juvenile in such family and society.<!--more--></p>

<p>Let&rsquo;s define the word &ldquo;traditional&rdquo; with the meaning of life styles with or close to Eastern world, and the word &ldquo;nontraditional&rdquo; with the opposite one.</p>

<p>With thousands years&#8217; culture of the doctrine of the mean in Eastern world, it would be so easy about choosing just like an objective question, following the tide and keeping away from too leftward or too rightward. It is also believed safe and reliable. If I am always as pure as a plain paper about my mind, there would be never so troublesome.</p>

<p>If comparing the modes of thinking as a curve of Normal Distribution, the curve in the Eastern world is supposed to be steep and thin while the curve in the Western world is supposed to be flat and fat, that is the difference. Persons&#8217; innate thoughts and exterior activities in the two environments are pulled or pushed from the two types of curve.</p>

<p>No readings, no worries. Especially when reading so many books about different life styles, thoughts, viewpoints and experiences of this flat world, notions&#8217; sparking and colliding in the consciousness. While endeavoring to experience colorful diversities of life, the farther you deviate, the stronger viscous forces pull you back to the curve. (Based on the theory of evolution, it would take tens or hundreds of generations to have a thorough change, of that curve, for the whole society.) And I also believe, it&rsquo;s true.</p>

<p>Retrospecting myself, what I would like to do is exploring this magnificent earth by reading thousands of books and traveling thousands of miles. Only after that, I could have a proper state of mind to choose and settle down. I would like to live a fresh and unique myself without considering what the general trends&#8217; choices. Obviously that&rsquo;s the reason  I am who I am. I would try to make some tiny changes within an invisible scope, the so-called margin of safety. As for others, I would be not so sure. Maybe that, the flounder, is some proof of my youth.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hurt]]></title>
    <link href="http://www.aprilzephyr.com/blog/07102014/hurt/"/>
    <updated>2014-07-10T16:52:28+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/07102014/hurt</id>
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube.com/embed/vt1Pwfnh5pc" frameborder="0" allowfullscreen></iframe>


<p>I hurt myself today<br/>
To see if I still feel  <!--more-->
I focus on the pain<br/>
The only thing that&rsquo;s real<br/>
The needle tears a hole<br/>
The old familiar sting<br/>
Try to kill it all away<br/>
But I remember everything</p>

<p>What have I become<br/>
My sweetest friend<br/>
Everyone I know goes away<br/>
In the end<br/>
And you could have it all<br/>
My empire of dirt<br/>
I will let you down<br/>
I will make you hurt</p>

<p>I wear this crown of thorns<br/>
Upon my liar&rsquo;s chair<br/>
Full of broken thoughts<br/>
I cannot repair<br/>
Beneath the stains of time<br/>
The feelings disappear<br/>
You are someone else<br/>
I am still right here</p>

<p>What have I become<br/>
My sweetest friend<br/>
Everyone I know goes away<br/>
In the end<br/>
And you could have it all<br/>
My empire of dirt<br/>
I will let you down<br/>
I will make you hurt</p>

<p>If I could start again<br/>
A million miles away<br/>
I would keep myself<br/>
I would find a way</p>

<p><strong>What would remain imperishably while lines&#8217; etching on the face? A word, some memories, or just serenity with or without regret.</strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[New Job, New Way]]></title>
    <link href="http://www.aprilzephyr.com/blog/06142014/new-job/"/>
    <updated>2014-06-14T10:04:25+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/06142014/new-job</id>
    <content type="html"><![CDATA[<p><img src="http://www.aprilzephyr.com/images/bigdata.jpg"></p>

<p>It&rsquo;s been a whole month working in a new company, which is a venture company with the area of distributed storage focused.<!--more--></p>

<p>Returning back to Beijing after half a year&rsquo;s separation, living in a high-rise apartment, I soon realized, it would be a new way.</p>

<p>Everything&rsquo;s changed whereas everything seems the same.</p>

<p>NEW CHALLENGES come with the new position. Studying and reading fulfill every day and almost every minute, that joys me. I could see vigor&rsquo;s back and fresh air&rsquo;s pervading.</p>

<p>Time to transform and evolve.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[You Are Alive]]></title>
    <link href="http://www.aprilzephyr.com/blog/05042014/you-are-alive/"/>
    <updated>2014-05-04T20:21:19+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/05042014/you-are-alive</id>
    <content type="html"><![CDATA[<p><img src="http://www.aprilzephyr.com/images/alive.jpg"></p>

<p>如果你的內心有不安<br/>
If you&rsquo;re carrying your restlessness in your heart,<!--more--><br/>
那麽你還活著<br/>
you are alive<br/>
如果你的眼中有對夢想的渴望<br/>
If you&rsquo;re carrying the flames of dreams in your eyes,<br/>
那麽你還活著<br/>
you are alive<br/>
像一陣風一般的自由生活<br/>
Like a gust of wind, learn to live free<br/>
學著像大海的波浪般流動<br/>
Learn to flow like the waves that make a sea<br/>
張開你的雙臂擁抱每個時刻，你都可能收獲一份問候<br/>
May every moment gift you a new sight to greet<br/>
如果你的眼中有期望<br/>
If you&rsquo;re carrying wonder in your eyes,<br/>
那麽你還活著<br/>
you are alive<br/>
如果你的內心有不安<br/>
If you&rsquo;re carrying your restlessness in your heart<br/>
那麽你還活著<br/>
you are alive</p>

<p>&mdash;From Indian Movie <a href="http://www.imdb.com/title/tt1562872/">&ldquo;Zindagi Na Milegi Dobara&rdquo;</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python 正則表達式指南(轉)]]></title>
    <link href="http://www.aprilzephyr.com/blog/05042014/python-zheng-ze-biao-da-shi-zhi-nan-zhuan/"/>
    <updated>2014-05-04T14:49:04+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/05042014/python-zheng-ze-biao-da-shi-zhi-nan-zhuan</id>
    <content type="html"><![CDATA[<h4>1. 正則表達式基礎</h4>

<h5>1.1 簡單介紹</h5>

<p>正則表達式並不是Python的一部分。正則表達式是用於處理字符串的強大工具，擁有自己獨特的語法以及一個獨立的處理引擎，效率上可能不如str自帶的方法，但功能十分強大。得益於這一點，在提供了正則表達式的語言裏，正則表達式的語法都是一樣的，區別只在於不同的編程語言實現支持的語法數量不同；但不用擔心，不被支持的語法通常是不常用的部分。如果已經在其他語言裏使用過正則表達式，只需要簡單看一看就可以上手了。</p>

<p>下圖展示了使用正則表達式進行匹配的流程：<!--more--><br/>
<img src="http://www.aprilzephyr.com/images/zhengzbds.png"></p>

<p>正則表達式的大致匹配過程是：依次拿出表達式和文本中的字符比較，如果每一個字符都能匹配，則匹配成功；一旦有匹配不成功的字符則匹配失敗。如果表達式中有量詞或邊界，這個過程會稍微有一些不同，但也是很好理解的，看下圖中的示例以及自己多使用幾次就能明白。</p>

<p>下錶列出了Python支持的正則表達式元字符和語法：</p>

<table><tbody>
<tr><td><em> 語法 </em></td><td><em> 說明 </em></td><td><em> 表達式實例 </em></td><td><em> 完整匹配的字符串 </em></td></tr>
<tr><td></td><td><em> 字符 </em><td></td></td><td></td></tr>
<tr><td> 一般字符 </td><td> 匹配自身 </td><td> abc </td><td> abc </td></tr>
<tr><td> . </td><td> 匹配任意除換行符&#8221;\n&#8221;外的字符。在DOTALL模式中也能匹配換行符 </td><td> a.c </td><td> abc </td></tr>
<tr><td> \ </td><td> 轉義字符，使後一個字符改變原來的意思。如果字符串中有字符*需要匹配，可以使用\*或者字符集[*] </td><td> a&#46;c a&#92;c </td><td> a.c a\c </td></tr>
<tr><td> [&#8230;] </td><td> 字符集(字符類)。對應的位置可以是字符集中任意字符。字符集中的字符可以逐個列出，也可以給出範圍，如[abc]或[a-c]。第一個字符如果是^則表示取反，如[^abc]表示不是abc的其他字符。 所有的特殊字符在字符集中都失去原油的特殊含義。在字符集中如果要使用]、-或^，可以在前面加上反斜槓，或把]、-放在第一個字符，把^放在非第一個字符 </td><td> a[bdc]e </td><td> abe ace ade </td></tr>
<tr><td></td><td><em> 預定義字符集(可以寫在字符集[&#8230;]中) </em><td></td></td><td></td></tr>
<tr><td> \d </td><td> 數字:[0-9] </td><td> a\dc </td><td> a1c </td></tr>
<tr><td> \D </td><td> 非數字:[^\d] </td><td> a\Dc </td><td> abc </td></tr>
<tr><td> \s </td><td> 非白字符:[<空格>\t\r\n\f\v] </td><td> a\sc </td><td> a c </td></tr>
<tr><td> \S </td><td> 非空白字符:[^\s] </td><td> a\Sc </td><td> abc </td></tr>
<tr><td> \w </td><td> 單詞字符:[A-Z a-z 0-9] </td><td> a\wc </td><td> abc </td></tr>
<tr><td> \W </td><td> 非單詞字符:[^\W] </td><td> a\Wc </td><td> a c </td></tr>
<tr><td></td><td><em> 數量詞(用在字符或(&#8230;)之後) </em><td></td></td><td></td></tr>
<tr><td> * </td><td> 匹配前一個字符0或無限次 </td><td> abc* </td><td> ab abccc </td></tr>
<tr><td> + </td><td> 匹配前一個字符1或無限次 </td><td> abc+ </td><td> abc abccc </td></tr>
<tr><td> ? </td><td> 匹配前一個字符0或1次 </td><td> abc? </td><td> ab abc </td></tr>
<tr><td> {m} </td><td> 匹配前一個字符m次 </td><td> ab{2}c </td><td> abbc </td></tr>
<tr><td> {m,n} </td><td> 匹配前一個字符m至n次。m和n可以省略：若省略m，則匹配0至n次；若省略n，則匹配m至無限次 </td><td> ab{1,2}c </td><td> abc abbc </td></tr>
<tr><td> \*?+? ?? {m,n}? </td><td> 使*+?{m,n}變成非貪婪模式 </td><td> 示例在下文中介紹 </td><td> </td></tr>
<tr><td></td><td><em> 邊界匹配(不消耗待匹配字符串中的字符) </em><td></td></td><td></td></tr>
<tr><td> ^ </td><td> 匹配字符串開頭。在多行模式中匹配每一行的開頭。 </td><td> ^abc </td><td> abc </td></tr>
<tr><td> $ </td><td> 匹配字符串末尾。在多行模式中匹配每一行的末尾。 </td><td> abc$ </td><td> abc </td></tr>
<tr><td> \A </td><td> 儘匹配字符串開頭。 </td><td> \Aabc </td><td> abc </td></tr>
<tr><td> \Z </td><td> 儘匹配字符串末尾。 </td><td> \Zabc </td><td> abc </td></tr>
<tr><td> \b </td><td> 匹配\w和\W之間。 </td><td> a\b!bc </td><td> a!bc </td></tr>
<tr><td> \B </td><td> [^\b] </td><td> a\Bbc </td><td> abc </td></tr>
<tr><td></td><td><em> 邏輯、分組 </em><td></td></td><td></td></tr>
<tr><td> | </td><td> |代表左右表達式任意匹配一個。總是先嘗試匹配左邊的表達式，一旦成功匹配則跳過匹配右邊的表達式。如果|沒有被包括在()中，則它的範圍是整個正則表達式。 </td><td> abc|def </td><td> abc def </td></tr>
<tr><td> (&#8230;) </td><td> 被擴起來的表達式將作為分組，從表達式左邊開始每遇到一個分組的左括號&#8217;(&#8216;，編號+1。另外，分組表達式作為一個整體，可以後接數量詞。表達式中的|儘在該組中有效。 </td><td> (abc){2} a(123|456)c </td><td> abcabc a456c </td></tr>
<tr><td> (?P<name>&#8230;) </td><td> 分組，除了原有的編號外再指定一個額外的別名。 </td><td> (?P<id>abc){2} </td><td> abcabc </td></tr>
<tr><td> \<number> </td><td> 引用編號為<number>的分組匹配到的字符串 </td><td> (\d)abc\1 </td><td> 1abc1 5abc5 </td></tr>
<tr><td> (?P=name) </td><td> 引用別名為<name>的分組匹配到的字符串。 </td><td> (?P<id>\d)abc(?P=id) </td><td> 1abc 5abc5 </td></tr>
<tr><td></td><td><em> 特殊構造(不作為分組) </em><td></td></td><td></td></tr>
<tr><td> (?:&#8230;) </td><td> (&#8230;)的不分組版本，用於使用&#8217;|&#8217;或後接數量詞 </td><td> (?:abc){2} </td><td> abc abc </td></tr>
<tr><td> (?iLmsux) </td><td> iLmsux的每個字符串代表一個匹配模式，只能用在正則表達式的開頭，可選多個。匹配模式將在下文中介紹。 </td><td> (?i)(abc) </td><td> AbC </td></tr>
<tr><td> (?#&#8230;) </td><td> #後的內容將作為註釋被忽略 </td><td> abc(?#comment)123 </td><td> abc123 </td></tr>
<tr><td> (?=&#8230;) </td><td> 之後的字符串內容需要匹配表達式才能成功匹配。不消耗字符串內容。 </td><td> abc(?=\d) </td><td> 後面是數字的a </td></tr>
<tr><td> (?!&#8230;) </td><td> 之後的字符串內容需要不匹配表達式才能成功匹配。不消耗字符串內容。 </td><td> abc(?!\d) </td><td> 後面不是數字的a </td></tr>
<tr><td> (?<=...) </td><td> 之前的字符串內容需要匹配表達式才能成功匹配。不消耗字符串內容。 </td><td> (?<=\d)a </td><td> 前面是數字的a </td></tr>
<tr><td> (?< !...) </td><td> 之前的字符串內容需要不匹配表達式才能成功匹配。不消耗字符串內容。 </td><td> (?<!\d)a </td><td> 前面不是數字的a </td></tr>
<tr><td> (?(id/name)yes-pattern|no-pattern) </td><td> 如果編號為id/別名為name的組匹配到字符，則需要皮皮yes-pattern，否則需要匹配no-pattern。 |np-pattern可以省略。 </td><td> (\d)abc(?(1)\d|abc) </td><td> 1abc2 abcabc </td></tr>
</tbody></table>


<p></p>

<h5>1.2 數量詞的貪婪模式與非貪婪模式</h5>

<p>正則表達式通常用於在文本中查找匹配的字符串。Python裏數量詞默認是貪婪的（在少數語言裏也可能是默認非貪婪），總是嘗試匹配盡可能多的字符；非貪婪的則相反，總是嘗試匹配盡可能少的字符。例如：正則表達式&#8221;a*&ldquo;如果用於查找&#8221;abbbc&#8221;，將找到&#8221;abbb&#8221;。而如果使用非貪婪的數量詞&#8221;ab*?&#8221;，將找到&#8221;a&#8221;。</p>

<h5>1.3. 反斜杠的困擾</h5>

<p>與大多數編程語言相同，正則表達式裏使用&#8221;\&ldquo;作為轉義字符，這就可能造成反斜杠困擾。假如你需要匹配文本中的字符&rdquo;\&ldquo;，那麽使用編程語言表示的正則表達式裏將需要4個反斜杠&rdquo;&#92;&#92;&ldquo;：前兩個和後兩個分別用於在編程語言裏轉義成反斜杠，轉換成兩個反斜杠後再在正則表達式裏轉義成一個反斜杠。Python裏的原生字符串很好地解決了這個問題，這個例子中的正則表達式可以使用r&rdquo;&#92;&ldquo;表示。同樣，匹配一個數字的&rdquo;&#92;d&#8221;可以寫成r&#8221;\d&#8221;。有了原生字符串，你再也不用擔心是不是漏寫了反斜杠，寫出來的表達式也更直觀。</p>

<h5>1.4. 匹配模式</h5>

<p>正則表達式提供了一些可用的匹配模式，比如忽略大小寫、多行匹配等，這部分內容將在Pattern類的工廠方法re.compile(pattern[, flags])中一起介紹。</p>

<h4>2. re模塊</h4>

<h5>2.1 開始使用re</h5>

<p>Python通過re模塊提供對正則表達式的支持。使用re的一般步驟是先將正則表達式的字符串形式編譯為Pattern實例，然後使用Pattern實例處理文本並獲得匹配結果（一個Match實例），最後使用Match實例獲得信息，進行其他的操作。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># encoding: UTF-8</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">re</span>
</span><span class='line'>
</span><span class='line'><span class="c"># 将正则表达式编译成Pattern对象</span>
</span><span class='line'><span class="n">pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r&#39;hello&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># 使用Pattern匹配文本，获得匹配结果，无法匹配时将返回None</span>
</span><span class='line'><span class="n">match</span> <span class="o">=</span> <span class="n">pattern</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="s">&#39;hello world!&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">if</span> <span class="n">match</span><span class="p">:</span>
</span><span class='line'>    <span class="c"># 使用Match获得分组信息</span>
</span><span class='line'>    <span class="k">print</span> <span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'><span class="c">### 输出 ###</span>
</span><span class='line'><span class="c"># hello</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p><strong>re.compile(strPattern[, flag]):</strong><br/>
這個方法是Pattern類的工廠方法，用於將字符串形式的正則表達式編譯為Pattern對象。 第二個參數flag是匹配模式，取值可以使用按位或運算符&#8217;|&lsquo;表示同時生效，比如re.I | re.M。另外，你也可以在regex字符串中指定模式，比如re.compile(&#8216;pattern&rsquo;, re.I | re.M)與re.compile(&lsquo;(?im)pattern&rsquo;)是等價的。
可選值有：<br/>
* re.I(re.IGNORECASE): 忽略大小寫（括號內是完整寫法，下同）<br/>
* M(MULTILINE): 多行模式，改變&#8217;^&lsquo;和&rsquo;$&lsquo;的行為（參見上圖）<br/>
* S(DOTALL): 點任意匹配模式，改變&rsquo;.&lsquo;的行為<br/>
* L(LOCALE): 使預定字符類 \w \W \b \B \s \S 取決於當前區域設定<br/>
* U(UNICODE): 使預定字符類 \w \W \b \B \s \S \d \D 取決於unicode定義的字符屬性<br/>
* X(VERBOSE): 詳細模式。這個模式下正則表達式可以是多行，忽略空白字符，並可以加入註釋。以下兩個正則表達式是等價的：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">a</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r&quot;&quot;&quot;\d +  # the integral part</span>
</span><span class='line'><span class="s">                   \.    # the decimal point</span>
</span><span class='line'><span class="s">                   \d *  # some fractional digits&quot;&quot;&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
</span><span class='line'><span class="n">b</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r&quot;\d+\.\d*&quot;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>
re提供了眾多模塊方法用於完成正則表達式的功能。這些方法可以使用Pattern實例的相應方法替代，唯一的好處是少寫一行re.compile()代碼，但同時也無法復用編譯後的Pattern對象。這些方法將在Pattern類的實例方法部分一起介紹。如上面這個例子可以簡寫為：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="s">r&#39;hello&#39;</span><span class="p">,</span> <span class="s">&#39;hello world!&#39;</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>
re模塊還提供了一個方法escape(string)，用於將string中的正則表達式元字符如*/+/?等之前加上轉義符再返回，在需要大量匹配元字符時有那麽一點用。</p>

<h5>2.2 Match</h5>

<p>Match对象是一次匹配的结果，包含了很多关于此次匹配的信息，可以使用Match提供的可读属性或方法来获取这些信息。</p>

<p>属性：<br/>
1) string: 匹配时使用的文本。<br/>
2) re: 匹配时使用的Pattern对象。<br/>
3) pos: 文本中正则表达式开始搜索的索引。值与Pattern.match()和Pattern.seach()方法的同名参数相同。<br/>
4) endpos: 文本中正则表达式结束搜索的索引。值与Pattern.match()和Pattern.seach()方法的同名参数相同。<br/>
5) lastindex: 最后一个被捕获的分组在文本中的索引。如果没有被捕获的分组，将为None。<br/>
6) lastgroup: 最后一个被捕获的分组的别名。如果这个分组没有别名或者没有被捕获的分组，将为None。</p>

<p>方法：<br/>
1) <strong>group([group1, …]):</strong> <br/>
获得一个或多个分组截获的字符串；指定多个参数时将以元组形式返回。group1可以使用编号也可以使用别名；编号0代表整个匹配的子串；不填写参数时，返回group(0)；没有截获字符串的组返回None；截获了多次的组返回最后一次截获的子串。<br/>
2) <strong>groups([default]):</strong><br/>
以元组形式返回全部分组截获的字符串。相当于调用group(1,2,…last)。default表示没有截获字符串的组以这个值替代，默认为None。<br/>
3) <strong>groupdict([default]):</strong><br/>
返回以有别名的组的别名为键、以该组截获的子串为值的字典，没有别名的组不包含在内。default含义同上。<br/>
4) <strong>start([group]):</strong><br/>
返回指定的组截获的子串在string中的起始索引（子串第一个字符的索引）。group默认值为0。<br/>
5) <strong>end([group]):</strong><br/>
返回指定的组截获的子串在string中的结束索引（子串最后一个字符的索引+1）。group默认值为0。<br/>
6) <strong>span([group]):</strong><br/>
返回(start(group), end(group))。<br/>
7) <strong>expand(template):</strong><br/>
将匹配到的分组代入template中然后返回。template中可以使用\id或\g<id>、\g<name>引用分组，但不能使用编号0。\id与\g<id>是等价的；但\10将被认为是第10个分组，如果你想表达\1之后是字符&#8217;0&#8217;，只能使用\g<1>0。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">re</span>
</span><span class='line'><span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="s">r&#39;(\w+) (\w+)(?P&lt;sign&gt;.*)&#39;</span><span class="p">,</span> <span class="s">&#39;hello world!&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;m.string:&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">string</span>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;m.re:&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">re</span>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;m.pos:&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">pos</span>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;m.endpos:&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">endpos</span>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;m.lastindex:&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">lastindex</span>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;m.lastgroup:&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">lastgroup</span>
</span><span class='line'>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;m.group(1,2):&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;m.groups():&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">groups</span><span class="p">()</span>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;m.groupdict():&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">groupdict</span><span class="p">()</span>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;m.start(2):&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;m.end(2):&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">end</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;m.span(2):&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">span</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span> <span class="s">r&quot;m.expand(r&#39;\2 \1\3&#39;):&quot;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="s">r&#39;\2 \1\3&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c">### output ###</span>
</span><span class='line'><span class="c"># m.string: hello world!</span>
</span><span class='line'><span class="c"># m.re: &lt;_sre.SRE_Pattern object at 0x016E1A38&gt;</span>
</span><span class='line'><span class="c"># m.pos: 0</span>
</span><span class='line'><span class="c"># m.endpos: 12</span>
</span><span class='line'><span class="c"># m.lastindex: 3</span>
</span><span class='line'><span class="c"># m.lastgroup: sign</span>
</span><span class='line'><span class="c"># m.group(1,2): (&#39;hello&#39;, &#39;world&#39;)</span>
</span><span class='line'><span class="c"># m.groups(): (&#39;hello&#39;, &#39;world&#39;, &#39;!&#39;)</span>
</span><span class='line'><span class="c"># m.groupdict(): {&#39;sign&#39;: &#39;!&#39;}</span>
</span><span class='line'><span class="c"># m.start(2): 6</span>
</span><span class='line'><span class="c"># m.end(2): 11</span>
</span><span class='line'><span class="c"># m.span(2): (6, 11)</span>
</span><span class='line'><span class="c"># m.expand(r&#39;\2 \1\3&#39;): world hello!</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<h5>2.3 Pattern</h5>

<p>Pattern對象是一個編譯好的正則表達式，通過Pattern提供的一系列方法可以對文本進行匹配查找。<br/>
Pattern不能直接實例化，必須使用re.compile()進行構造。<br/>
Pattern提供了幾個可讀屬性用於獲取表達式的相關信息：<br/>
1) pattern: 編譯時用的表達式字符串。<br/>
2) flags: 編譯時用的匹配模式。數字形式。<br/>
3) groups: 表達式中分組的數量。<br/>
4) groupindex: 以表達式中有別名的組的別名為鍵、以該組對應的編號為值的字典，沒有別名的組不包含在內。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">re</span>
</span><span class='line'><span class="n">p</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r&#39;(\w+) (\w+)(?P&lt;sign&gt;.*)&#39;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;p.pattern:&quot;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">pattern</span>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;p.flags:&quot;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">flags</span>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;p.groups:&quot;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">groups</span>
</span><span class='line'><span class="k">print</span> <span class="s">&quot;p.groupindex:&quot;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">groupindex</span>
</span><span class='line'>
</span><span class='line'><span class="c">### output ###</span>
</span><span class='line'><span class="c"># p.pattern: (\w+) (\w+)(?P&lt;sign&gt;.*)</span>
</span><span class='line'><span class="c"># p.flags: 16</span>
</span><span class='line'><span class="c"># p.groups: 3</span>
</span><span class='line'><span class="c"># p.groupindex: {&#39;sign&#39;: 3}</span>
</span></code></pre></td></tr></table></div></figure>


<p>
实例方法[ | re模块方法]：<br/>
1) <strong>match(string[, pos[, endpos]]) | re.match(pattern, string[, flags]):</strong><br/>
这个方法将从string的pos下标处起尝试匹配pattern；如果pattern结束时仍可匹配，则返回一个Match对象；如果匹配过程中pattern无法匹配，或者匹配未结束就已到达endpos，则返回None。<br/>
pos和endpos的默认值分别为0和len(string)；re.match()无法指定这两个参数，参数flags用于编译pattern时指定匹配模式。<br/>
注意：这个方法并不是完全匹配。当pattern结束时若string还有剩余字符，仍然视为成功。想要完全匹配，可以在表达式末尾加上边界匹配符&#8217;$&lsquo;。<br/>
示例参见2.1小节。
2) <strong>search(string[, pos[, endpos]]) | re.search(pattern, string[, flags]):</strong><br/>
这个方法用于查找字符串中可以匹配成功的子串。从string的pos下标处起尝试匹配pattern，如果pattern结束时仍可匹配，则返回一个Match对象；若无法匹配，则将pos加1后重新尝试匹配；直到pos=endpos时仍无法匹配则返回None。<br/>
pos和endpos的默认值分别为0和len(string))；re.search()无法指定这两个参数，参数flags用于编译pattern时指定匹配模式。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># encoding: UTF-8 </span>
</span><span class='line'><span class="kn">import</span> <span class="nn">re</span>
</span><span class='line'>
</span><span class='line'><span class="c"># 将正则表达式编译成Pattern对象 </span>
</span><span class='line'><span class="n">pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r&#39;world&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># 使用search()查找匹配的子串，不存在能匹配的子串时将返回None </span>
</span><span class='line'><span class="c"># 这个例子中使用match()无法成功匹配 </span>
</span><span class='line'><span class="n">match</span> <span class="o">=</span> <span class="n">pattern</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="s">&#39;hello world!&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">if</span> <span class="n">match</span><span class="p">:</span>
</span><span class='line'>    <span class="c"># 使用Match获得分组信息 </span>
</span><span class='line'>    <span class="k">print</span> <span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'><span class="c">### 输出 ### </span>
</span><span class='line'><span class="c"># world</span>
</span></code></pre></td></tr></table></div></figure>


<p>
3) <strong>split(string[, maxsplit]) | re.split(pattern, string[, maxsplit]):</strong><br/>
按照能夠匹配的子串將string分割後返回列表。maxsplit用於指定最大分割次數，不指定將全部分割。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">re</span>
</span><span class='line'>
</span><span class='line'><span class="n">p</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r&#39;\d+&#39;</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span> <span class="n">p</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;one1two2three3four4&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c">### output ###</span>
</span><span class='line'><span class="c"># [&#39;one&#39;, &#39;two&#39;, &#39;three&#39;, &#39;four&#39;, &#39;&#39;]</span>
</span></code></pre></td></tr></table></div></figure>


<p>
4) <strong>findall(string[, pos[, endpos]]) | re.findall(pattern, string[, flags]):</strong><br/>
搜索string，以列表形式返回全部能匹配的子串。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">re</span>
</span><span class='line'>
</span><span class='line'><span class="n">p</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r&#39;\d+&#39;</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span> <span class="n">p</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s">&#39;one1two2three3four4&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c">### output ###</span>
</span><span class='line'><span class="c"># [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;]</span>
</span></code></pre></td></tr></table></div></figure>


<p>
5) <strong>finditer(string[, pos[, endpos]]) | re.finditer(pattern, string[, flags]):</strong><br/>
搜索string，返回一個順序訪問每一個匹配結果（Match對象）的叠代器。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">re</span>
</span><span class='line'>
</span><span class='line'><span class="n">p</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r&#39;\d+&#39;</span><span class="p">)</span>
</span><span class='line'><span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">finditer</span><span class="p">(</span><span class="s">&#39;one1two2three3four4&#39;</span><span class="p">):</span>
</span><span class='line'>    <span class="k">print</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(),</span>
</span><span class='line'>
</span><span class='line'><span class="c">### output ###</span>
</span><span class='line'><span class="c"># 1 2 3 4</span>
</span></code></pre></td></tr></table></div></figure>


<p>
6) <strong>sub(repl, string[, count]) | re.sub(pattern, repl, string[, count]):</strong><br/>
使用repl替換string中每一個匹配的子串後返回替換後的字符串。<br/>
當repl是一個字符串時，可以使用\id或\g<id>、\g<name>引用分組，但不能使用編號0。<br/>
當repl是一個方法時，這個方法應當只接受一個參數（Match對象），並返回一個字符串用於替換（返回的字符串中不能再引用分組）。<br/>
count用於指定最多替換次數，不指定時全部替換。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">re</span>
</span><span class='line'>
</span><span class='line'><span class="n">p</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r&#39;(\w+) (\w+)&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">s</span> <span class="o">=</span> <span class="s">&#39;i say, hello world!&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="k">print</span> <span class="n">p</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">r&#39;\2 \1&#39;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">()</span> <span class="o">+</span> <span class="s">&#39; &#39;</span> <span class="o">+</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'><span class="k">print</span> <span class="n">p</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c">### output ###</span>
</span><span class='line'><span class="c"># say i, world hello!</span>
</span><span class='line'><span class="c"># I Say, Hello World!</span>
</span></code></pre></td></tr></table></div></figure>


<p>
7) <strong>subn(repl, string[, count]) |re.sub(pattern, repl, string[, count]):</strong><br/>
返回 (sub(repl, string[, count]), 替換次數)。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">re</span>
</span><span class='line'>
</span><span class='line'><span class="n">p</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r&#39;(\w+) (\w+)&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">s</span> <span class="o">=</span> <span class="s">&#39;i say, hello world!&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="k">print</span> <span class="n">p</span><span class="o">.</span><span class="n">subn</span><span class="p">(</span><span class="s">r&#39;\2 \1&#39;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">()</span> <span class="o">+</span> <span class="s">&#39; &#39;</span> <span class="o">+</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'><span class="k">print</span> <span class="n">p</span><span class="o">.</span><span class="n">subn</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c">### output ###</span>
</span><span class='line'><span class="c"># (&#39;say i, world hello!&#39;, 2)</span>
</span><span class='line'><span class="c"># (&#39;I Say, Hello World!&#39;, 2)</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p><a href="http://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html">Origin</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tips on Writing(Fw)]]></title>
    <link href="http://www.aprilzephyr.com/blog/05022014/tips-on-writing/"/>
    <updated>2014-05-02T16:41:00+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/05022014/tips-on-writing</id>
    <content type="html"><![CDATA[<h4>Decide What You Think First</h4>

<p>When working on a challenging task — writing a speech, preparing an important presentation, or developing a new idea — it&rsquo;s helpful to get feedback from others. Do they think it&rsquo;s any good? In what direction do they think you should take it? But sometimes, too much feedback can drown out the most important opinion: your own. If you feel like you&rsquo;re getting too much input or are no longer sure what you think of your own work, take a break from the feedback. Decide what you think. This will build your confidence and trust in yourself. Once you&rsquo;ve articulated and refined your own perspective, reach back out to your trusted advisors to get theirs.<br/>
Adapted from <a href="http://blogs.hbr.org/2010/11/how-to-teach-yourself-to-trust/">&ldquo;How to Teach Yourself to Trust Yourself&rdquo; by Peter Bregman.</a><!--more--></p>

<h4>Three Ways to Tighten Your Writing</h4>

<p>Writing today—a report, memo, or email—must be short if you want people to read it. But succinctly expressing yourself can be tough. Here are three ways to trim your writing and say what you want in fewer words:<br/>
* <strong>Refine it.</strong> Take a hard look at the structure of your writing. Only include sections that are necessary to support your points.<br/>
* <strong>Consider an informal tone.</strong> Just because you&rsquo;re writing a report doesn&rsquo;t mean you need to be formal. Writing like a bureaucrat makes you use longer words and a complicated sentence structure. Adopting a more informal tone often helps you be direct and concise.<br/>
* <strong>Cut and then cut more.</strong> Look over your document sentence by sentence. If a sentence doesn&rsquo;t serve an important purpose, get rid of it.<br/>
Adapted from <a href="http://hbr.org/product/guide-to-better-business-writing-2nd-edition/an/10919-PDF-ENG">Guide to Better Business Writing.</a></p>

<h4>Choose Clarity over Brevity</h4>

<p>Writing experts emphasize the importance of using as few words as possible to deliver your message. The evolution of technology has supported this trend toward brevity; see tweets, status updates, and text messages as examples. But we may have gone too far. Sometimes messages that are too brief sacrifice clarity and leave out crucial information. When crafting your next message, choose clarity over brevity; include all relevant information and be sure it is logically organized. This is as true for PowerPoint presentations and research reports as it is for emails. Being brief is important but not at the risk of being misunderstood.<br/>
Adapted from <a href="http://blogs.hbr.org/2009/10/when-clarity-is-not-the-same-a/">&ldquo;When Clarity is Not the Same as Brevity&rdquo; by David Silverman.</a></p>

<h4>Three Tips for Writing Reader-Friendly Memos</h4>

<p>In business today, readers are time-pressed, content-driven, and decision-focused. To write effectively, remember that they want simple and direct communications. Here are three tips for giving readers what they want and need:<br/>
* <strong>Avoid complex phrasing.</strong> Writing elegantly is not important; delivering smart content is. Let the message stand out more than your language.<br/>
* <strong>Be concise.</strong> Many memo writers get hung up on &ldquo;flow.&rdquo; But flowing sentences tend to be long and dense. You don&rsquo;t need choppy sentences, just hardworking ones that deliver content concisely.<br/>
* <strong>Skip the jargon.</strong> Jargon can be a useful way to communicate among experts, but you should never use jargon if it&rsquo;s meaningless, if you don&rsquo;t understand it, or when your audience isn&rsquo;t familiar with it.<br/>
Adapted from <a href="http://hbr.org/product/guide-to-better-business-writing-2nd-edition/an/10919-PDF-ENG">Guide to Better Business Writing.</a></p>

<h4>Three Rules for Making Your Writing Clear</h4>

<p>In business writing, you get points for clarity, not style. Instead of trying to wax poetic about your division&rsquo;s plans for the next 60 days, just make your point. Here are three ways to do that:<br/>
* <strong>One idea per paragraph.</strong> Novels hold several complex ideas and emotions in a single paragraph. In business writing, limit your thoughts to one per paragraph. When you have another suggestion, thought or idea, start a  new paragraph.<br/>
* <strong>Put your point in the first sentence.</strong> Don&rsquo;t entice your readers with background information and build-up. No one has time for that. Make your primary point first. Then go into supporting detail.<br/>
* <strong>Make it &ldquo;scannable.&rdquo;</strong> Few people read every word in an email. Use headers and bullet points so that your audience can quickly scan your message and understand your point.<br/>
Adapted from <a href="http://blogs.hbr.org/2011/03/how-to-succeed-in-business-wri/">&ldquo;How to Succeed in Business Writing: Don&rsquo;t Be Dickens&rdquo; by David Silverman.</a></p>

<p><a href="http://hbr.org/web/management-tip/tips-on-writing">Origin</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[這樣寫英文Email]]></title>
    <link href="http://www.aprilzephyr.com/blog/04172014/zhe-yang-xie-ying-wen-email/"/>
    <updated>2014-04-17T17:15:01+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/04172014/zhe-yang-xie-ying-wen-email</id>
    <content type="html"><![CDATA[<p><strong>1. 郵件的開頭</strong><br/>
感謝讀者是郵件開場白的好辦法。感謝您的讀者能讓對方感到高興，特別是之後你有事相求的情況下會很有幫助。</p>

<p>Thank you for contacting us.如果有人寫信來詢問公司的服務，就可以使用這句句子開頭。向他們對公司的興趣表示感謝。</p>

<p>Thank you for your prompt reply.當一個客戶或是同事很快就回復了你的郵件，一定記得要感謝他們。如果回復並不及時，只要將“prompt”除去即可，你還可以說，“Thank you for getting back to me.”<!--more--></p>

<p>Thank you for providing the requested information.如果你詢問某人一些信息，他們花了點時間才發送給你，那就用這句句子表示你仍然對他們的付出表示感激。</p>

<p>Thank you for all your assistance.如果有人給了你特別的幫助，那一定要感謝他們！如果你想對他們表示特別的感激，就用這個句子，“I truly appreciate … your help in resolving the problem.”Thank you raising your concerns.</p>

<p>就算某個客戶或是經理寫郵件給你對你的工作提出了一定的質疑，你還是要感謝他們。這樣你能表現出你對他們的認真態度表示尊重及感激。同時，你也可以使用，“Thank you for your feedback.”</p>

<p><strong>2. 郵件的結尾</strong> <br/>
在郵件開頭表示感謝一般是表示對對方過去付出的感謝，而在郵件結尾處表示感謝是對將來的幫助表示感謝。事先表示感謝，能讓對方在行動時更主動更樂意。</p>

<p>Thank you for your kind cooperation.如果你需要讀者幫助你做某事，那就先得表示感謝。</p>

<p>Thank you for your attention to this matter.與以上的類似，本句包含了你對對方將來可能的幫助表示感謝。</p>

<p>Thank you for your understanding.如果你寫到任何會對讀者產生負面影響的內容那就使用這句句子吧。</p>

<p>Thank you for your consideration.如果您是在尋求機會或是福利，例如你在求職的話，就用這封郵件結尾。</p>

<p>Thank you again for everything you&rsquo;ve done.這句句子可以用在結尾，和以上有所不同。如果你在郵件開頭已經謝過了讀者，你就可以使用這句話，但是因為他們的幫助，你可以著重再次感謝你們的付出。</p>

<p><strong>3. 十種場合的表達</strong><br/>
1) <em>Greeting message 祝福</em></p>

<p>Hope you have a good trip back. 祝旅途愉快。</p>

<p>How are you? 你好嗎?</p>

<p>How is the project going? 項目進行順利嗎?</p>

<p><em>2) Initiate a meeting 發起會議</em><br/>
I suggest we have a call tonight at 9:30pm (China Time) with you and Brown. Please let me know if the time is okay for you and Ben.<br/>
我建議我們今晚九點半和Brown小聚一下,你和Ben有沒有空?</p>

<p>I would like to hold a meeting in the afternoon about our development planning for the project A.<br/>
今天下午我建議我們就A項目的發展計劃開會討論一下。</p>

<p>We’d like to have the meeting on Thu Oct 30. Same time.<br/>
十月三十號(周四),老時間,開會。</p>

<p>Let’s make a meeting next Monday at 5:30 PM SLC time.<br/>
下周一鹽湖城時區下午五點半開會。</p>

<p>I want to talk to you over the phone regarding issues about report development and the XXX project.<br/>
我想跟你電話討論下報告進展和XXX項目的情況。</p>

<p><em>3) Seeking for more information/feedbacks/suggestions 咨詢信息/反饋/建議</em></p>

<p>Should you have any problem accessing the folders, please let me know.<br/>
如果存取文件有任何問題請和我聯系。</p>

<p>Thank you and look forward to having your opinion on the estimation and schedule.<br/>
謝謝你,希望能聽到更多你對評估和日程計劃的建議。</p>

<p>Look forward to your feedbacks and suggestions soon.<br/>
期待您的反饋建議!</p>

<p>What is your opinion on the schedule and next steps we proposed?<br/>
你對計劃方面有什麽想法?下一步我們應該怎麽做?</p>

<p>What do you think about this?<br/>
這個你怎麽想?</p>

<p>Feel free to give your comments.<br/>
請隨意提出您的建議。</p>

<p>Any question, please don’t hesitate to let me know.<br/>
有任何問題,歡迎和我們聯系。</p>

<p>Any question, please let me know.<br/>
有任何問題,歡迎和我們聯系。</p>

<p>Please contact me if you have any questions.<br/>
有任何問題,歡迎和我們聯系。</p>

<p>Please let me know if you have any question on this.<br/>
有任何問題,歡迎和我聯系。</p>

<p>Your comments and suggestions are welcome!<br/>
歡迎您的評論和建議!</p>

<p>Please let me know what you think?<br/>
歡迎您的評論和建議!</p>

<p>Do you have any idea about this?<br/>
對於這個您有什麽建議嗎?</p>

<p>It would be nice if you could provide a bit more information on the user’s behavior.<br/>
您若是能夠就用戶行為方面提供更多的信息就太感激了!</p>

<p>At your convenience, I would really appreciate you looking into this matter/issue.<br/>
如果可以,我希望你能負責這件事情。</p>

<p><em>4) Give feedback 意見反饋</em><br/>
Please see comments below.<br/>
請看下面的評論。</p>

<p>My answers are in blue below.<br/>
我的回答已標藍。</p>

<p>I add some comments to the document for your reference.<br/>
我加了些評論給你參考。</p>

<p><em>5) Attachment 附件</em><br/>
I enclose the evaluation report for your reference.<br/>
我附加了評估報告供您閱讀。</p>

<p>Attached please find today’s meeting notes.<br/>
今天的會議記錄在附件裏。</p>

<p>Attach is the design document, please review it.<br/>
設計文檔在附件裏,請評閱。</p>

<p>For other known issues related to individual features, please see attached release notes.<br/>
其他個人特征方面的信息請見附件。</p>

<p><em>6) Point listing 列表</em><br/>
Today we would like to finish following tasks by the end of today:1…….2…….<br/>
今天我們要完成的任務:1…….2…….</p>

<p>Some known issues in this release:1…….2…….<br/>
聲明中涉及的一些問題:1…….2…….</p>

<p>Our team here reviewed the newest SCM policy and has following concerns:1…….2…….<br/>
我們閱讀了最新的供應鏈管理政策,做出如下考慮:1…….2…….</p>

<p>Here are some more questions/issues for your team:1…….2…….<br/>
以下是對你們團隊的一些問題:1…….2…….</p>

<p>The current status is as following: 1…… 2……<br/>
目前數據如下: 1…… 2……</p>

<p>Some items need your attention:1…….2…….<br/>
以下方面需提請註意:1…….2…….</p>

<p><em>7) Raise question 提出問題</em><br/>
I have some questions about the report XX-XXX.<br/>
我對XX-XXX報告有一些疑問。</p>

<p>For the assignment ABC, I have the following questions:…<br/>
就ABC協議,我有以下幾個問題:……</p>

<p><em>8) Proposal 提議</em><br/>
For the next step of platform implementation, I am proposing…<br/>
關於平臺啟動的下一步計劃,我有一個提議……</p>

<p>I suggest we can have a weekly project meeting over the phone call in the near future.<br/>
我建議我們就一周項目開一個電話會議。</p>

<p>Achievo team suggest to adopt option A to solve outstanding issue……<br/>
Achievo團隊建議應對突出問題采用A辦法。</p>

<p><em>9) Thanks note 感謝信</em><br/>
Thank you so much for the cooperation.<br/>
感謝你的合作!</p>

<p>Thanks for the information.<br/>
謝謝您提供的信息!</p>

<p>I really appreciate the effort you all made for this sudden and tight project.<br/>
對如此緊急的項目您做出的努力我表示十分感謝。</p>

<p>Thank you for your attention!</p>

<p>Thanks to your attention!<br/>
謝謝關心!</p>

<p>Your kind assistance on this are very much appreciated.<br/>
我們對您的協助表示感謝。</p>

<p>Really appreciate your help!<br/>
非常感謝您的幫助!</p>

<p><em>10) Apology 道歉</em><br/>
I sincerely apologize for this misunderstanding!<br/>
對造成的誤解我真誠道歉!</p>

<p>I apologize for the late asking but we want to make sure the correctness of our implementation ASAP.<br/>
很抱歉現在才進行詢問,但是我們需要盡快核實執行信息。</p>

<p><strong>4. 分清目標</strong><br/>
Informal – Thanks for the email of 15 February.<br/>
Formal – Thank you for your email received 15 February.</p>

<p>Informal – Sorry, I can’t make it.<br/>
Formal – I am afraid I will not be able to attend.</p>

<p>Informal – Could you…?<br/>
Formal – I was wondering if you could….?</p>

<p><strong>5. 直接與間接表達</strong><br/>
Direct – I need this in half an hour.<br/>
Indirect and polite – Would it be possible to have this in half an hour?</p>

<p>Direct – There will be a delay.<br/>
Indirect – I’m afraid there will be a slight delay.</p>

<p>Direct – It’s a bad idea.<br/>
Indirect – To be honest, I’m not sure it would be a good idea.</p>

<p><strong>6. 用詞正面</strong><br/>
Look at these words: helpful, good question, agreed, together, useful, I’d be delighted, mutual, opportunity.</p>

<p>Now look at these: busy, crisis, failure, forget it, I can’t, it’s impossible, waste, hard.</p>

<p>The words you use show your attitude to life so choose your words wisely.</p>

<p><strong>7. Business Email Format</strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Subject: ___________
</span><span class='line'>
</span><span class='line'>Dear Sir,
</span><span class='line'>
</span><span class='line'>Reference to your _______ dated ______ regarding ____, I would like to intimate that ___________. You will soon receive a detailed hard copy regarding the same.
</span><span class='line'>
</span><span class='line'>For any further queries, please feel free to contact me on my email address or phone number xxx-xxxx.
</span><span class='line'>
</span><span class='line'>Thanks and best regards,
</span><span class='line'>
</span><span class='line'>Sender information
</span><span class='line'>Sender Designation
</span><span class='line'>Company Name
</span><span class='line'>Contact number
</span><span class='line'>
</span><span class='line'>PS: This is a computer generated message and thus bears no signatures.</span></code></pre></td></tr></table></div></figure>


<p></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>To: "Anna Jones" 
</span><span class='line'>Cc: All Staff
</span><span class='line'>From: "James Brown" jamesbrown@abcd.com
</span><span class='line'>Subject: Welcome to our Hive!
</span><span class='line'>
</span><span class='line'>Dear Anna,
</span><span class='line'>
</span><span class='line'>Welcome to our Hive!
</span><span class='line'>
</span><span class='line'>It is a pleasure to welcome you to the team of ___________. We are excited to have you join our team, and we hope that you will enjoy working with our company.
</span><span class='line'>
</span><span class='line'>On the last Saturday of each month we hold a special staff party to welcome any new employees. Please be sure to come next week to meet all of our senior staff and any other new staff members who have joined ___________ this month. You will receive an e-mail regarding the same with further details.
</span><span class='line'>
</span><span class='line'>If you have any questions during your training period, please do not hesitate to contact me. You can reach me at my email address or on my office line at 000-0001.
</span><span class='line'>
</span><span class='line'>Warm regards,
</span><span class='line'>James
</span><span class='line'>
</span><span class='line'>Jackie Brown, Manager, Staff
</span><span class='line'>jamesbrown@abcd.com
</span><span class='line'>Tel: 000-0001
</span><span class='line'>Read more at Buzzle: http://www.buzzle.com/articles/business-email-format.html</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Stay Hungry, Stay Foolish]]></title>
    <link href="http://www.aprilzephyr.com/blog/04082014/stay-hungry/"/>
    <updated>2014-04-08T14:43:38+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/04082014/stay-hungry</id>
    <content type="html"><![CDATA[<p><img src="http://www.aprilzephyr.com/images/stayhsf.png"><br/>
<strong>&ldquo;Stay Hungry, Stay Foolish.&rdquo;</strong> Such resounding words delivered by Steve Jobs in 2005 Stanford Commencement Address which, was actually not the topic today. The quote is just about some reflections of a movie <a href="http://www.imdb.com/title/tt0107048/"><em>Groundhog Day</em></a>.<!--more--></p>

<p><strong>&ldquo;What would you do if you were stuck in one place and every day was exactly the same, and nothing that you did mattered?&rdquo;</strong></p>

<p>Phil Connors, the hero in that movie, an arrogant and egocentric Pittsburgh TV weatherman who, during a disgusted assignment covering the annual Groundhog Day event in Punxsutawney, finds himself in a time loop, repeating the same day over and over and over again. After indulging in periods of hedonism, dismay, bitterness, despair then numerous suicide attempts, he begins to re-examine his life and tries to change &mdash; improving and enriching himself through learning new skills and helping people.</p>

<p>Some plots are interesting that when Phil tries harder and harder to cater to someone he is interested, either terrible consequences(such as slaps on his face) come or void&rsquo;s arising even he succeeds. It might be because Phil attempts to alter the original himself which he actually couldn&rsquo;t. Such alternation would not last long even though he makes it for a flash. Only when Phil accepts the circumstances calmly, patiently and ready to do some &ldquo;changes&rdquo; would he handle the &ldquo;magic&rdquo; to break such time loop and win his queen&rsquo;s heart.</p>

<p>And so is the story telling us.</p>

<p>In real life, things are so similar that few ones are satisfied with their presents living roughly the same days over and over and over again. Senses of helplessness and so far as abomination towards their own never vanish. Sorrowfully that only fewer ones would like or dare to make a change as to be sluggish, revolted and desperate dying finally.</p>

<p>Staying hungry and foolish, is only for adequate constant advances for the nature of oneself could not be changed but the substance. There would be one and the only way to get rid of such suck life rhythm is to get cultured. Never scared, even if looked like deserted weeds temporarily. Just endeavor, struggle, enrich oneself, waiting patiently for the moment handling that fabulous magic to break one&rsquo;s own &ldquo;time loop&rdquo;.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python with語句(轉)]]></title>
    <link href="http://www.aprilzephyr.com/blog/04062014/python-with-yu-ju/"/>
    <updated>2014-04-06T16:37:46+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/04062014/python-with-yu-ju</id>
    <content type="html"><![CDATA[<p><strong>1. With 語句是什麼</strong><br/>
Python’s with statement provides a very convenient way of dealing with the situation where you have to do a setup and teardown to make something happen. A very good example for this is the situation where you want to gain a handler to a file, read data from the file and the close the file handler.<br/>
有一些任務，可能事先需要設置，事後做清理工作。對於這種場景，Python的with語句提供了一種非常方便的處理方式。一個很好的例子是文件處理，你需要獲取一個文件句柄，從文件中讀取數據，然後關閉文件句柄。<!--more--></p>

<p>Without the with statement, one would write something along the lines of:<br/>
如果不用with語句，代碼如下：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="nb">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">&quot;/tmp/foo.txt&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">data</span> <span class="o">=</span> <span class="nb">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span><span class='line'><span class="nb">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>
There are two annoying things here. First, you end up forgetting to close the file handler. The second is how to handle exceptions that may occur once the file handler has been obtained. One could write something like this to get around this:<br/>
這裏有兩個問題。一是可能忘記關閉文件句柄；二是文件讀取數據發生異常，沒有進行任何處理。下面是處理異常的加強版本：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="nb">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">&quot;/tmp/foo.txt&quot;</span><span class="p">)</span>
</span><span class='line'><span class="k">try</span><span class="p">:</span>
</span><span class='line'>    <span class="n">data</span> <span class="o">=</span> <span class="nb">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span><span class='line'><span class="k">finally</span><span class="p">:</span>
</span><span class='line'>    <span class="nb">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>
While this works well, it is unnecessarily verbose. This is where with is useful. The good thing about with apart from the better syntax is that it is very good handling exceptions. The above code would look like this, when using with:<br/>
雖然這段代碼運行良好，但是太冗長了。這時候就是with一展身手的時候了。除了有更優雅的語法，with還可以很好的處理上下文環境產生的異常。下面是with版本的代碼：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">&quot;/tmp/foo.txt&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
</span><span class='line'>    <span class="n">data</span> <span class="o">=</span> <span class="nb">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p><strong>2. with如何工作</strong><br/>
while this might look like magic, the way Python handles with is more clever than magic. The basic idea is that the statement after with has to evaluate an object that responds to an __enter__() as well as an __exit__() function.<br/>
這看起來充滿魔法，但不僅僅是魔法，Python對with的處理還很聰明。基本思想是with所求值的對象必須有一個__enter__()方法，一個__exit__()方法。</p>

<p>After the statement that follows with is evaluated, the __enter__() function on the resulting object is called. The value returned by this function is assigned to the variable following as. After every statement in the block is evaluated, the __exit__() function is called.<br/>
緊跟with後面的語句被求值後，返回對象的__enter__()方法被調用，這個方法的返回值將被賦值給as後面的變量。當with後面的代碼塊全部被執行完之後，將調用前面返回對象的__exit__()方法。</p>

<p>This can be demonstrated with the following example:<br/>
下面例子可以具體說明with如何工作：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#!/usr/bin/env python</span>
</span><span class='line'><span class="c"># with_example01.py</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">Sample</span><span class="p">:</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>        <span class="k">print</span> <span class="s">&quot;In __enter__()&quot;</span>
</span><span class='line'>        <span class="k">return</span> <span class="s">&quot;Foo&quot;</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">type</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">trace</span><span class="p">):</span>
</span><span class='line'>        <span class="k">print</span> <span class="s">&quot;In __exit__()&quot;</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">get_sample</span><span class="p">():</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">Sample</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">with</span> <span class="n">get_sample</span><span class="p">()</span> <span class="k">as</span> <span class="n">sample</span><span class="p">:</span>
</span><span class='line'>    <span class="k">print</span> <span class="s">&quot;sample:&quot;</span><span class="p">,</span> <span class="n">sample</span>
</span></code></pre></td></tr></table></div></figure>


<p>
When executed, this will result in:<br/>
運行代碼，輸出如下</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">bash</span><span class="o">-</span><span class="mf">3.2</span><span class="err">$</span> <span class="o">./</span><span class="n">with_example01</span><span class="o">.</span><span class="n">py</span>
</span><span class='line'><span class="n">In</span> <span class="n">__enter__</span><span class="p">()</span>
</span><span class='line'><span class="n">sample</span><span class="p">:</span> <span class="n">Foo</span>
</span><span class='line'><span class="n">In</span> <span class="n">__exit__</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>
As you can see,<br/>
The __enter__() function is executed<br/>
The value returned by it &ndash; in this case &ldquo;Foo&rdquo; is assigned to sample<br/>
The body of the block is executed, thereby printing the value of sample ie. &ldquo;Foo&#8221;<br/>
The __exit__() function is called.<br/>
What makes with really powerful is the fact that it can handle exceptions. You would have noticed that the __exit__() function for Sample takes three arguments &ndash; val, type and trace. These are useful in exception handling. Let’s see how this works by modifying the above example.<br/>
正如你看到的，<br/>
1) __enter__()方法被執行<br/>
2) __enter__()方法返回的值 &ndash; 這個例子中是&#8221;Foo&#8221;，賦值給變量&#8217;sample&#8217;<br/>
3) 執行代碼塊，打印變量&#8221;sample&#8221;的值為 &#8220;Foo&#8221;<br/>
4) __exit__()方法被調用<br/>
with真正強大之處是它可以處理異常。可能你已經註意到Sample類的__exit()__方法有三個參數- val, type 和 trace。 這些參數在異常處理中相當有用。我們來改一下代碼，看看具體如何工作的。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#!/usr/bin/env python</span>
</span><span class='line'><span class="c"># with_example02.py</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">Sample</span><span class="p">:</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>        <span class="k">return</span> <span class="bp">self</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">type</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">trace</span><span class="p">):</span>
</span><span class='line'>        <span class="k">print</span> <span class="s">&quot;type:&quot;</span><span class="p">,</span> <span class="nb">type</span>
</span><span class='line'>        <span class="k">print</span> <span class="s">&quot;value:&quot;</span><span class="p">,</span> <span class="n">value</span>
</span><span class='line'>        <span class="k">print</span> <span class="s">&quot;trace:&quot;</span><span class="p">,</span> <span class="n">trace</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">do_something</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>        <span class="n">bar</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">0</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">bar</span> <span class="o">+</span> <span class="mi">10</span>
</span><span class='line'>
</span><span class='line'><span class="k">with</span> <span class="n">Sample</span><span class="p">()</span> <span class="k">as</span> <span class="n">sample</span><span class="p">:</span>
</span><span class='line'>    <span class="n">sample</span><span class="o">.</span><span class="n">do_something</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>
Notice how in this example, instead of get_sample(), with takes Sample(). It does not matter, as long as the statement that follows with evaluates to an object that has an __enter__() and __exit__() functions. In this case, Sample()’s __enter__() returns the newly created instance of Sample and that is what gets passed to sample.<br/>
這個例子中，with後面的get_sample()變成了Sample()。這沒有任何關系，只要緊跟with後面的語句所返回的對象有__enter__()和__exit__()方法即可。此例中，Sample()的__enter__()方法返回新創建的Sample對象，並賦值給變量sample。</p>

<p>When executed:<br/>
代碼執行後：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">bash</span><span class="o">-</span><span class="mf">3.2</span><span class="err">$</span> <span class="o">./</span><span class="n">with_example02</span><span class="o">.</span><span class="n">py</span>
</span><span class='line'><span class="nb">type</span><span class="p">:</span> <span class="o">&lt;</span><span class="nb">type</span> <span class="s">&#39;exceptions.ZeroDivisionError&#39;</span><span class="o">&gt;</span>
</span><span class='line'><span class="n">value</span><span class="p">:</span> <span class="n">integer</span> <span class="n">division</span> <span class="ow">or</span> <span class="n">modulo</span> <span class="n">by</span> <span class="n">zero</span>
</span><span class='line'><span class="n">trace</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">traceback</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x1004a8128</span><span class="o">&gt;</span>
</span><span class='line'><span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">):</span>
</span><span class='line'>  <span class="n">File</span> <span class="s">&quot;./with_example02.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">19</span><span class="p">,</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
</span><span class='line'>    <span class="n">sample</span><span class="o">.</span><span class="n">do_something</span><span class="p">()</span>
</span><span class='line'>  <span class="n">File</span> <span class="s">&quot;./with_example02.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">15</span><span class="p">,</span> <span class="ow">in</span> <span class="n">do_something</span>
</span><span class='line'>    <span class="n">bar</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">0</span>
</span><span class='line'><span class="ne">ZeroDivisionError</span><span class="p">:</span> <span class="n">integer</span> <span class="n">division</span> <span class="ow">or</span> <span class="n">modulo</span> <span class="n">by</span> <span class="n">zero</span>
</span></code></pre></td></tr></table></div></figure>


<p>
Essentially, if there are exceptions being thrown from anywhere inside the block, the __exit__() function for the object is called. As you can see, the type, value and the stack trace associated with the exception thrown is passed to this function. In this case, you can see that there was a ZeroDivisionError exception being thrown. People implementing libraries can write code that clean up resources, close files etc. in their __exit__() functions.<br/>
實際上，在with後面的代碼塊拋出任何異常時，__exit__()方法被執行。正如例子所示，異常拋出時，與之關聯的type，value和stack trace傳給__exit__()方法，因此拋出的ZeroDivisionError異常被打印出來了。開發庫時，清理資源，關閉文件等等操作，都可以放在__exit__方法當中。</p>

<p>Thus, Python’s with is a nifty construct that makes code a little less verbose and makes cleaning up during exceptions a bit easier.<br/>
因此，Python的with語句是提供一個有效的機制，讓代碼更簡練，同時在異常產生時，清理工作更簡單。</p>

<p>I have put the code examples given here on <a href="https://github.com/sdqali/python_dojo/tree/master/with">Github</a>.<br/>
示例代碼可以在<a href="https://github.com/sdqali/python_dojo/tree/master/with">Github</a>上面找到。</p>

<p>譯註：本文原文見<a href="http://blog.sdqali.in/blog/2012/07/09/understanding-pythons-with/">Understanding Python&rsquo;s &ldquo;With&rdquo; Statement</a></p>

<p><a href="http://python.42qu.com/11155501">Origin</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fading away]]></title>
    <link href="http://www.aprilzephyr.com/blog/04022014/fading-away/"/>
    <updated>2014-04-02T20:21:50+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/04022014/fading-away</id>
    <content type="html"><![CDATA[<p><img src="http://www.aprilzephyr.com/images/fallingleaves.png"></p>

<p>Leaves sway down in sough late autumn winds, desolately, fading away, without one single sign.<!--more--></p>

<p>Fortunately trees&#8217; remaining vigor, notwithstanding in months&#8217; hibernation, new shoots would be pushing out after austere winters eventually.</p>

<p>Be hopeful and persistent, even through quite tough time, leastways&mdash;an opportunity to blossom.</p>

<p>&hellip;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python 動態類型(轉)]]></title>
    <link href="http://www.aprilzephyr.com/blog/04022014/python-dong-tai-lei-xing/"/>
    <updated>2014-04-02T15:15:39+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/04022014/python-dong-tai-lei-xing</id>
    <content type="html"><![CDATA[<p>Python中只有一個賦值模型</p>

<h4>1. 缺少類型聲明語句的情況</h4>

<p>在Python中，類型是在運行過程中自動決定的，而不是通過代碼聲明。這意味著沒有必要事聲明變量。只要記住，這個概念實質上對變量，對象和它們之間的關系都適用。那麽這個概念也容易理解並掌握。</p>

<p><strong>A 變量，對象和引用</strong><br/>
變量創建：一個變量，當代碼第一次給它賦值時它就被創建了。之後的賦值將會改變已創建的變量名的值。Python在代碼運行之前先檢測變量名，可以當成是最初的賦值創建變量。<!--more--><br/>
變量類型：變量永遠不會有任何的它關聯的類型信息或約束。類型的概念是存在於對象中而不是變量中。變量原本是通用的。它只是在一個特定的時間點，簡單地引用了一個特定的對像而已。<br/>
變量的使用：當變量出現在表達式中時，它會馬上被當前引用的對像所代替，無論這個對象是什麽類型。<br/>
此外，所有的變量都必須在其使用前明確地賦值。使用未賦值的變量會產生錯誤。<br/>
<code>&gt;&gt;&gt;a=3</code></p>

<p>在概念上說，Python將執行三個不同的步驟去完成這個請求。<br/>
1) 創建一個對象來代表值3<br/>
2) 創建一個變量a，如果它還沒有創建的話<br/>
3) 將變量與新的對象3連接</p>

<p>在python中從變量到對象的連接稱作引用。引用是一種關系，以內存中的指針形式實現。<br/>
* 變量 是一個系統表的元素，擁有指向對象的連接空間。<br/>
* 對象 是被分配的一塊內存，有足夠的空間去表現它們所代表的值。<br/>
* 引用 是自動形成的從變量到對象的指針。</p>

<p>每一個對象都用兩個標準的頭部信息：一個類型標誌符去標識這個對象的類型，以及一個引用的計數器，用來決定是不是可以回收這個對象。</p>

<p><strong>B 類型屬於對象，而不是變量</strong><br/>
Python中的類型是與對象相關聯的，而不是和變量關聯。<br/>
變量沒有類型，變量指向對象。對象有類型，知道自己的類型，每個對象都包含了一個頭部信息，其中標記了這個對象的類型。</p>

<p><strong>C 對象的垃圾收集</strong><br/>
對象生命結束時發生了什麽變化？<br/>
每當一個變量名被賦與了一個新的對象，之前的那個對象占用的空間就會被收回（如果它沒有被其他變量名和對象所引用).這種自動回收對象空間的技術稱作垃圾收集。<br/>
在內部，Python是通過保持用每個對象中的計數器記錄引用指到這個對象上的次數來完成這一功能。一旦（並精確在同一時間）這個計數器被設置為零，這個對象的內存空間就會自動收回。垃圾收集最直接的，可感受到的好處就是這意味著可以在腳本中任意使用對象而不需要考慮釋放內存空間。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt;&gt;&gt; x=42
</span><span class='line'>&gt;&gt;&gt; id(x)
</span><span class='line'>674748828
</span><span class='line'>&gt;&gt;&gt; x="cli"
</span><span class='line'>&gt;&gt;&gt; id(x)    
</span><span class='line'>676367648</span></code></pre></td></tr></table></div></figure>


<p></p>

<h4>2. 共享引用</h4>

<p>上面所講都是單個變量被賦值引用了多個對象的情況。現在，在交互模式下，引入另一個變量，並看一下變量名和對象的變化。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt;&gt;&gt; a=10
</span><span class='line'>&gt;&gt;&gt; b=a 
</span><span class='line'>&gt;&gt;&gt; id(a)
</span><span class='line'>674749212
</span><span class='line'>&gt;&gt;&gt; id(b)
</span><span class='line'>674749212</span></code></pre></td></tr></table></div></figure>


<p>
第二行會使用python創建變量b。使用的是變量a,並且它在這裏沒有被賦值，所以它被替換成其應用的對象10，從而b也成為這個對象的一個引用。實際效果就是變量a和b都引用相同的對象（也就是說指向了相同的內存空間。在Python中稱作是共享引用&mdash;多個變量名應用了同一個對象。)</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt;&gt;&gt; a=10 
</span><span class='line'>&gt;&gt;&gt; b=a  
</span><span class='line'>&gt;&gt;&gt; a='cli'
</span><span class='line'>&gt;&gt;&gt; id(a) 
</span><span class='line'>676367648
</span><span class='line'>&gt;&gt;&gt; id(b)
</span><span class='line'>674749212</span></code></pre></td></tr></table></div></figure>


<p>
變量a改變了，但是不影響變量b.這完全可以說明變量b是指向對象10內存空間的。</p>

<p>在ptyhon中，變量總是一個指向對象的指針，而不是可以改變的內存區域的標簽。給一變量賦一個新的值，並不是替換了原始的對象，而是讓這個變量去引用完全不同的一個對象。實際的效果就是對一個變量賦值，僅僅會影響那個被賦值的變量。</p>

<p><strong>A 共享引用和在原處修改</strong><br/>
有一些對象和類型確實會在實地改變對象。例如，在一個列表中對一個偏移進行賦值確實會改變這個列表對象，而不是生成一個新的列表對象。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt;&gt;&gt; T1=[11,12,13]
</span><span class='line'>&gt;&gt;&gt; T2=T1
</span><span class='line'>&gt;&gt;&gt; T1
</span><span class='line'>[11, 12, 13]
</span><span class='line'>&gt;&gt;&gt; T2
</span><span class='line'>[11, 12, 13]
</span><span class='line'>&gt;&gt;&gt; T1=22
</span><span class='line'>&gt;&gt;&gt; T1
</span><span class='line'>22
</span><span class='line'>&gt;&gt;&gt; T2
</span><span class='line'>[11, 12, 13]</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>這個和先前一樣T1改變了T2沒有改變，T2改變也不影響T1</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt;&gt;&gt; T1=[11,12,13]
</span><span class='line'>&gt;&gt;&gt; T2=T1
</span><span class='line'>&gt;&gt;&gt; T1
</span><span class='line'>[11, 12, 13]
</span><span class='line'>&gt;&gt;&gt; T2
</span><span class='line'>[11, 12, 13]
</span><span class='line'>&gt;&gt;&gt; T2[1]=33     
</span><span class='line'>&gt;&gt;&gt; T1
</span><span class='line'>[33, 12, 13]
</span><span class='line'>&gt;&gt;&gt; T2
</span><span class='line'>[33, 12, 13]</span></code></pre></td></tr></table></div></figure>


<p>
發現T2改變了，T1也跟這改變了<br/>
同樣T1改變了，T2也改變了</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt;&gt;&gt; T1[1]=99  
</span><span class='line'>&gt;&gt;&gt; T2
</span><span class='line'>[33, 99, 13]
</span><span class='line'>&gt;&gt;&gt; T1
</span><span class='line'>[33, 99, 13]</span></code></pre></td></tr></table></div></figure>


<p>
這裏T1沒有改變，改變了T1所引用對象的一個元素。這類修改會覆蓋列表對象中的某部分。因為這個列表對象是與其他對象共享的（被其他對象引用），那麽一個像這樣在原處的改變不僅僅會對T1有影響。必須意識到當做了這樣的修改，它會影響程序的其他部分。</p>

<p>如果不想要這樣的現象發生，需要Python拷貝對象，而不是創建引用。方法包括內置列表函數以及標準庫的copy模塊，最常用的辦法就是從頭到尾的分片T1[:]</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt;&gt;&gt; T1=[11,12,13]
</span><span class='line'>&gt;&gt;&gt; T2=T1[:]
</span><span class='line'>&gt;&gt;&gt; T1
</span><span class='line'>[11, 12, 13]
</span><span class='line'>&gt;&gt;&gt; T2
</span><span class='line'>[11, 12, 13]
</span><span class='line'>&gt;&gt;&gt; T1[0]=99
</span><span class='line'>&gt;&gt;&gt; T1
</span><span class='line'>[99, 12, 13]
</span><span class='line'>&gt;&gt;&gt; T2
</span><span class='line'>[11, 12, 13]
</span><span class='line'>&gt;&gt;&gt; id(T1)
</span><span class='line'>676366604
</span><span class='line'>&gt;&gt;&gt; id(T2)
</span><span class='line'>675542060</span></code></pre></td></tr></table></div></figure>


<p>
T1和T2指向不同的對象，所以不會相互影響。<br/>
註意：這種分片技術不會引用在其他的可變的核心類型上（字典，因為它們不是序列），對字典應該使用D.copy（）方法.而且，註意標準庫中的copy模塊有一個通用的拷貝任意對象的調用，也有一個拷貝嵌套對象的結構的調用.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt;&gt;&gt; X={'name':'cli','age':27}  
</span><span class='line'>&gt;&gt;&gt; import copy
</span><span class='line'>&gt;&gt;&gt; Y=copy.copy(X)
</span><span class='line'>&gt;&gt;&gt; X
</span><span class='line'>{'age': 27, 'name': 'cli'}
</span><span class='line'>&gt;&gt;&gt; Y
</span><span class='line'>{'age': 27, 'name': 'cli'}
</span><span class='line'>&gt;&gt;&gt; id(X)
</span><span class='line'>676370468
</span><span class='line'>&gt;&gt;&gt; id(Y)
</span><span class='line'>676414436
</span><span class='line'>&gt;&gt;&gt; X={'name':{'FirstName':'cli','LastName':'cli'},'age':27}    
</span><span class='line'>&gt;&gt;&gt; X
</span><span class='line'>{'age': 27, 'name': {'LastName': 'cli', 'FirstName': 'cli'}}
</span><span class='line'>&gt;&gt;&gt; Y=copy.copy(X)
</span><span class='line'>&gt;&gt;&gt; Y
</span><span class='line'>{'age': 27, 'name': {'LastName': 'cli', 'FirstName': 'cli'}}
</span><span class='line'>&gt;&gt;&gt; Z=copy.deepcopy(X) 
</span><span class='line'>&gt;&gt;&gt; Z
</span><span class='line'>{'age': 27, 'name': {'LastName': 'cli', 'FirstName': 'cli'}}</span></code></pre></td></tr></table></div></figure>


<p></p>

<p><strong>B 共享引用和相等</strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt;&gt;&gt; x=33
</span><span class='line'>&gt;&gt;&gt; x='cli'</span></code></pre></td></tr></table></div></figure>


<p>
因為Python緩存並復用了小的整數和小的字符串，就像前文提到的那樣，這裏對象33也許不像前期所說的被收回，相反，它將可能仍保持在一個系統表中，等待下一次你的代碼生成另一個33來利用。盡快如此，大多數種類的對象都會在不再引用時馬上回收。對於那些不會被回收的，緩沖機制與代碼並沒有什麽關系。</p>

<p>判斷是否相等</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt;&gt;&gt; L=[1,2,3]
</span><span class='line'>&gt;&gt;&gt; M=L
</span><span class='line'>&gt;&gt;&gt; L==M
</span><span class='line'>True
</span><span class='line'>&gt;&gt;&gt; L is M
</span><span class='line'>True</span></code></pre></td></tr></table></div></figure>


<p>
==檢查對象是否有相同的值。 is操作符，檢查對象的同一性。如果兩個變量名精準地指向同一個對象，它會返回True。所以這是一種更嚴格的相等測試。<br/>
實際上,is只是比較現實引用的指針。所以如果必要的話是代碼中檢測共享引用的一種方法。如果變量名引用值相等。但是為不同的對象，它的返回值將是False.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt;&gt;&gt; L=[1,2,3]
</span><span class='line'>&gt;&gt;&gt; M=[1,2,3]
</span><span class='line'>&gt;&gt;&gt; L==M
</span><span class='line'>True
</span><span class='line'>&gt;&gt;&gt; L is M
</span><span class='line'>False
</span><span class='line'>&gt;&gt;&gt; id(L)
</span><span class='line'>676367788
</span><span class='line'>&gt;&gt;&gt; id(M)
</span><span class='line'>676367724</span></code></pre></td></tr></table></div></figure>


<p>
通過id()函數可以看到兩個變量指向不同的對象。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt;&gt;&gt; X=33
</span><span class='line'>&gt;&gt;&gt; Y=33
</span><span class='line'>&gt;&gt;&gt; X==Y
</span><span class='line'>True
</span><span class='line'>&gt;&gt;&gt; X is Y
</span><span class='line'>True
</span><span class='line'>&gt;&gt;&gt; id(X)
</span><span class='line'>674748936
</span><span class='line'>&gt;&gt;&gt; id(Y)
</span><span class='line'>674748936</span></code></pre></td></tr></table></div></figure>


<p>
這個is測試返回True因為小的整數和字符串被緩存被復用了。
如果想更進一步了解，可以向Python查詢一個對象應用的次數：在sys模塊中的getrefcount函數返回對象應用的次數。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt;&gt;&gt; import sys
</span><span class='line'>&gt;&gt;&gt; sys.getrefcount(33)
</span><span class='line'>13
</span><span class='line'>&gt;&gt;&gt; sys.getrefcount(1) 
</span><span class='line'>427
</span><span class='line'>&gt;&gt;&gt; sys.getrefcount(00)
</span><span class='line'>296
</span><span class='line'>&gt;&gt;&gt; sys.getrefcount(99)
</span><span class='line'>6</span></code></pre></td></tr></table></div></figure>


<p></p>

<p><a href="http://ipseek.blog.51cto.com/1041109/786518">Origin</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[網頁重定向的方法(轉)]]></title>
    <link href="http://www.aprilzephyr.com/blog/04022014/wang-ye-zhong-ding-xiang-de-fang-fa/"/>
    <updated>2014-04-02T10:58:43+08:00</updated>
    <id>http://www.aprilzephyr.com/blog/04022014/wang-ye-zhong-ding-xiang-de-fang-fa</id>
    <content type="html"><![CDATA[<h4>1. 使用HTTP通訊協定301 Moved Permanently來完成轉導網址(永久轉址)</h4>

<p><em>建議使用，不會對SEO有不良影響</em></p>

<h5>PHP程式範例:</h5>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="o">&lt;?</span><span class="nx">php</span>
</span><span class='line'>    <span class="nx">header</span><span class="p">(</span><span class="err">“</span><span class="nx">HTTP</span><span class="o">/</span><span class="mf">1.1</span> <span class="mi">301</span> <span class="nx">Moved</span> <span class="nx">Permanently</span><span class="s2">&quot;);</span>
</span><span class='line'><span class="s2">    header(“Location: http://www.new-url.com/&quot;</span><span class="p">);</span>
</span><span class='line'><span class="cp">?&gt;</span><span class="x"></span>
</span><span class='line'><span class="x">&lt;p&gt;The document has moved &lt;a href=&quot;http://www.new-url.com/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>  <!--more-->
註<br/>
1) 使用者的瀏覽器必須根據HTTP header的Location欄位值(稱做URI)來轉導網址。<br/>
2) 除非Request Method是HEAD，不然伺服器端回覆的訊息內必須包含一短的新網址的連結(hyperlink)資訊。</p>

<h5>ASP程式範例:</h5>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="o">&lt;%@</span> <span class="nx">Language</span><span class="o">=</span><span class="nx">VBScript</span> <span class="o">%&gt;</span>
</span><span class='line'><span class="o">&lt;%</span>
</span><span class='line'>    <span class="nx">Response</span><span class="o">.</span><span class="nx">Status</span><span class="o">=</span><span class="s2">&quot;301 Moved Permanently&quot;</span>
</span><span class='line'>    <span class="nx">Response</span><span class="o">.</span><span class="nx">AddHeader</span> <span class="err">“</span><span class="nx">Location</span><span class="s2">&quot;, &quot;</span> <span class="nx">http</span><span class="o">://</span><span class="nx">www</span><span class="o">.</span><span class="k">new</span><span class="o">-</span><span class="nx">url</span><span class="o">.</span><span class="nx">com</span><span class="o">/</span><span class="s2">&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="s2">    Response.End</span>
</span><span class='line'><span class="s2">%&gt;</span>
</span><span class='line'><span class="s2">&lt;p&gt;The document has moved &lt;a href=&quot;</span><span class="nx">http</span><span class="o">://</span><span class="nx">www</span><span class="o">.</span><span class="k">new</span><span class="o">-</span><span class="nx">url</span><span class="o">.</span><span class="nx">com</span><span class="o">/</span><span class="s2">&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<h5>ASP.NET程式範例:</h5>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="o">&lt;</span><span class="nx">script</span> <span class="nx">runat</span><span class="o">=</span><span class="s2">&quot;server&quot;</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="k">private</span> <span class="nx">void</span> <span class="nx">Page_Load</span><span class="p">(</span><span class="nx">object</span> <span class="nx">sender</span><span class="p">,</span> <span class="nx">System</span><span class="o">.</span><span class="nx">EventArgs</span> <span class="nx">e</span><span class="p">)</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="nx">Response</span><span class="o">.</span><span class="nx">Status</span> <span class="o">=</span> <span class="err">“</span><span class="mi">301</span> <span class="nx">Moved</span> <span class="nx">Permanently</span><span class="s2">&quot;;</span>
</span><span class='line'><span class="s2">    Response.AddHeader(“Location&quot;</span><span class="p">,</span><span class="s2">&quot;http://www.new-url.com/&quot;</span><span class="p">);</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'><span class="o">&lt;/</span><span class="nx">script</span><span class="o">&gt;</span>
</span><span class='line'><span class="o">&lt;</span><span class="nx">p</span><span class="o">&gt;</span><span class="nx">The</span> <span class="nx">document</span> <span class="nx">has</span> <span class="nx">moved</span> <span class="o">&lt;</span><span class="nx">a</span> <span class="nx">href</span><span class="o">=</span><span class="s2">&quot;http://www.new-url.com/&quot;</span><span class="o">&gt;</span><span class="nx">here</span><span class="o">&lt;/</span><span class="nx">a</span><span class="o">&gt;.&lt;/</span><span class="nx">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<h5>在 .htaccess/httpd.conf檔案中設定—轉整domain</h5>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="nx">Options</span> <span class="o">+</span><span class="nx">FollowSymLinks</span>
</span><span class='line'><span class="nx">RewriteEngine</span> <span class="nx">on</span>
</span><span class='line'><span class="nx">RewriteRule</span> <span class="o">^</span><span class="p">(</span><span class="o">.*</span><span class="p">)</span> <span class="nx">http</span><span class="o">://</span><span class="nx">www</span><span class="o">.</span><span class="k">new</span><span class="o">-</span><span class="nx">domain</span><span class="o">.</span><span class="nx">com</span><span class="o">/</span><span class="err">$</span><span class="mi">1</span> <span class="p">[</span><span class="nx">R</span><span class="o">=</span><span class="mi">301</span><span class="p">,</span><span class="nx">L</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<h5>在 .htaccess/httpd.conf檔案中設定—轉到新的www.</h5>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="nx">Options</span> <span class="o">+</span><span class="nx">FollowSymlinks</span>
</span><span class='line'><span class="nx">RewriteEngine</span> <span class="nx">on</span>
</span><span class='line'><span class="nx">RewriteCond</span> <span class="o">%</span><span class="p">{</span><span class="nx">http_host</span><span class="p">}</span> <span class="o">^</span><span class="nx">old</span><span class="o">-</span><span class="nx">domain</span><span class="o">.</span><span class="nx">com</span> <span class="p">[</span><span class="nx">NC</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'><span class="nx">RewriteRule</span> <span class="o">^</span><span class="p">(</span><span class="o">.*</span><span class="p">)</span><span class="err">$</span> <span class="nx">http</span><span class="o">://</span><span class="nx">www</span><span class="o">.</span><span class="k">new</span><span class="o">-</span><span class="nx">domain</span><span class="o">.</span><span class="nx">com</span><span class="o">/</span><span class="err">$</span><span class="mi">1</span> <span class="p">[</span><span class="nx">R</span><span class="o">=</span><span class="mi">301</span><span class="p">,</span><span class="nx">NC</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<h4>2. 使用HTTP/1.1通訊協定302 Found來完成轉導網址</h4>

<p><em>不建議使用，會對新網站SEO有不良影響</em></p>

<h5>PHP程式範例:</h5>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="o">&lt;?</span><span class="nx">php</span>
</span><span class='line'>    <span class="nx">header</span><span class="p">(</span><span class="err">“</span><span class="nx">HTTP</span><span class="o">/</span><span class="mf">1.1</span> <span class="mi">302</span> <span class="nx">Found</span><span class="s2">&quot;);</span>
</span><span class='line'>
</span><span class='line'><span class="s2">    header(“Location: http://www.new-url.com/&quot;</span><span class="p">);</span>
</span><span class='line'><span class="cp">?&gt;</span><span class="x"></span>
</span><span class='line'><span class="x">&lt;p&gt;The document has moved &lt;a href=&quot;http://www.new-url.com/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>(…其他ASP, ASP.NET程式及設定.htaccess/httpd.conf方法，此處略…)</p>

<p>註<br/>
1) 302，在HTTP/1.0是『Moved Temporarily』；HTTP/1.1是『Found』，會根據HTTP header的Location欄位值(稱做URI)來轉導網址。但是很多網路上的文章會直接稱302是Moved Temporatily。<br/>
2) 除非Request Method是HEAD，不然伺服器端回覆的訊息內必須包含一短的新網址的連結(hyperlink)資訊。<br/>
3) HTTP 1.1中增訂了『307 Temporary Redirect』，307碼時只會根據GET Request轉導網址。<br/>
4) 更多的HTTP 302細節和307會被再增訂出來的原因<a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html">請參考</a>。</p>

<h4>3. HTML的refresh meta tag來轉導網址</h4>

<p><em>非常不建議使用，會對新網站SEO有不良影響。有些文章寫說要用時最好秒數設定大於10秒以避免對頁面的SEO不利。</em></p>

<h5>在HTML檔案的HEAD中，範例:</h5>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='html'><span class='line'><span class="nt">&lt;html&gt;</span>
</span><span class='line'><span class="nt">&lt;head&gt;</span>
</span><span class='line'>    <span class="nt">&lt;meta</span> <span class="na">http-equiv=</span><span class="s">&quot;refresh&quot;</span> <span class="na">content=</span><span class="s">&quot;0;url=http://www.new-url.com/&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'><span class="nt">&lt;/head&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<h4>4. 用JavaScript來達到轉導網址(放在 HTML的<head>…</head>或<body>…<body>中</h4>

<p><em>因為搜尋引擎的bot一般都不理會JavaScript，所以做什麼動作不會被檢查。這意味著要實做『點擊計算(click counting)後再轉導到目的網址的話，用這個方法比較好(302或refresh都是不好的方法)』。如果使用者按瀏覽器的『上一頁』按鈕，不會跳回轉導頁面。</em></p>

<h5>直接在HTML的HEAD中用轉導網址JavaScript範例:</h5>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='html'><span class='line'><span class="nt">&lt;html&gt;</span>
</span><span class='line'><span class="nt">&lt;head&gt;</span>
</span><span class='line'><span class="nt">&lt;script </span><span class="na">language=</span><span class="s">&quot;JavaScript&quot;</span><span class="nt">&gt;</span>
</span><span class='line'><span class="o">&lt;!</span><span class="err">–</span>
</span><span class='line'>    <span class="nb">window</span><span class="p">.</span><span class="nx">location</span><span class="p">.</span><span class="nx">replace</span><span class="p">(</span><span class="err">“</span><span class="nx">http</span><span class="o">:</span><span class="c1">//www.new-url.com&quot;);</span>
</span><span class='line'>
</span><span class='line'><span class="c1">//–&gt;</span>
</span><span class='line'><span class="nt">&lt;/script&gt;</span>
</span><span class='line'><span class="nt">&lt;/head&gt;</span>
</span><span class='line'><span class="nt">&lt;/html&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<h5>JavaScript內容同上例，但是把它放到外部的一個 .js 檔案，然後<head>…</head>中只要寫:</h5>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='html'><span class='line'><span class="nt">&lt;html&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="nt">&lt;head&gt;</span>
</span><span class='line'>    <span class="nt">&lt;script </span><span class="na">language=</span><span class="s">&quot;JavaScript&quot;</span> <span class="na">src=</span><span class="s">&quot;redirect.js&quot;</span><span class="nt">&gt;&lt;/script&gt;</span>
</span><span class='line'><span class="nt">&lt;/head&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<h5>也是使用JavaScript，但是額外透過『表單』來完成:</h5>

<p><em>因為搜尋引擎的bot一般都不理會『表單』，所以做什麼動作不會被檢查。</em></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='html'><span class='line'><span class="nt">&lt;script </span><span class="na">language=</span><span class="s">&quot;JavaScript&quot;</span><span class="nt">&gt;</span>
</span><span class='line'><span class="o">&lt;!</span><span class="err">–</span>
</span><span class='line'>
</span><span class='line'>    <span class="nb">document</span><span class="p">.</span><span class="nx">myform</span><span class="p">.</span><span class="nx">submit</span><span class="p">();</span>
</span><span class='line'><span class="c1">//–&gt;</span>
</span><span class='line'><span class="nt">&lt;/script&gt;</span>
</span><span class='line'><span class="nt">&lt;form</span> <span class="na">name=</span><span class="s">&quot;myform&quot;</span> <span class="na">action=</span><span class="s">&quot;http://www.new-url.com/&quot;</span> <span class="na">method=</span><span class="s">&quot;get&quot;</span><span class="nt">&gt;&lt;/form&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<h4>額外討論:</h4>

<ol>
<li>301/302有時會被一些人用作旁門走道方法，在玩『PR劫持』(如<a href="http://www.seozac.com/google/pr-hijack/">這篇文章</a>所述)，更多的一些手法討論請看<a href="http://www.loriswebs.com/hijacking_web_pages.html">這篇文章</a>或用 hijack 當 KeyWord 去查查。</li>
<li>302在之前會造成bot誤以為是轉導到的網站在惡搞，而將轉導到的網站從索引中除名。所以會變得無法防止別人以此方法攻擊自己的 URL。現或許已更正。(詳情請看<a href="http://www.tonyspencer.com/2004/12/10/tracker2php-pagejacking-via-http-302-redirect-google-bug/">這裡</a>)</li>
<li>當然，refresh也能如上述302一樣去惡搞別人的網站。</li>
</ol>


<p><a href="http://rental.zhupiter.com/postshow_184_1_1.html">Origin</a></p>
]]></content>
  </entry>
  
</feed>
